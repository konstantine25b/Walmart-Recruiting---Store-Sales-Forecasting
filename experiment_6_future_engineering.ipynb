{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# experiment_6_future_engineering.ipynb"
      ],
      "metadata": {
        "id": "KXFYak8a6607"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "9f1uQbX365_O",
        "outputId": "dbd0cf74-80cf-42c3-84d5-08c01ecae59b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle wandb onnx -Uq\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "Jfy55HB07Ggo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "UngrkdvK7II6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "WvxsYyBF7KR-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c walmart-recruiting-store-sales-forecasting"
      ],
      "metadata": {
        "id": "mAATTkje7N0X",
        "outputId": "9ec9e552-6dbf-44a8-a8ce-e449526e99be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading walmart-recruiting-store-sales-forecasting.zip to /content\n",
            "\r  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "\r100% 2.70M/2.70M [00:00<00:00, 122MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip walmart-recruiting-store-sales-forecasting.zip"
      ],
      "metadata": {
        "id": "tpkZKNea7Obi",
        "outputId": "abb84c4f-700f-409e-92ab-fb0c5ea22bc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  walmart-recruiting-store-sales-forecasting.zip\n",
            "  inflating: features.csv.zip        \n",
            "  inflating: sampleSubmission.csv.zip  \n",
            "  inflating: stores.csv              \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install required packages\n",
        "import subprocess\n",
        "import sys"
      ],
      "metadata": {
        "id": "g3odjE8T7kuT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prophet plotly mlflow dagshub xgboost -q"
      ],
      "metadata": {
        "id": "QmL4mAVs8QWa",
        "outputId": "c2025e56-8744-4f5e-f9cc-d5fbf43c7b88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.8/733.8 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import dagshub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "BRxTGyIO8Rtt",
        "outputId": "c2add227-c4de-43db-fb9e-1b29da2acdad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_mlflow():\n",
        "    \"\"\"Setup MLflow and DagsHub tracking\"\"\"\n",
        "    print(\"🔧 Setting up MLflow and DagsHub...\")\n",
        "\n",
        "    # End any active runs first\n",
        "    try:\n",
        "        mlflow.end_run()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Initialize DagsHub\n",
        "    try:\n",
        "        dagshub.init(\n",
        "            repo_owner='konstantine25b',\n",
        "            repo_name='Walmart-Recruiting---Store-Sales-Forecasting',\n",
        "            mlflow=True\n",
        "        )\n",
        "        print(\"✅ DagsHub initialized successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ DagsHub init warning: {e}\")\n",
        "\n",
        "    # Set MLflow tracking URI\n",
        "    mlflow.set_tracking_uri(\"https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow\")\n",
        "\n",
        "    # Create unique experiment name with timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    experiment_name = f\"Experiment_6_Complete_Pipeline_{timestamp}\"\n",
        "\n",
        "    try:\n",
        "        experiment_id = mlflow.create_experiment(experiment_name)\n",
        "        print(f\"✅ Created new experiment: {experiment_name}\")\n",
        "    except mlflow.exceptions.MlflowException as e:\n",
        "        if \"already exists\" in str(e):\n",
        "            experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "            experiment_id = experiment.experiment_id\n",
        "            print(f\"✅ Using existing experiment: {experiment_name}\")\n",
        "        else:\n",
        "            # Fallback to default experiment\n",
        "            experiment_name = \"Default\"\n",
        "            mlflow.set_experiment(experiment_name)\n",
        "            print(f\"⚠️ Using default experiment due to: {e}\")\n",
        "\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "\n",
        "    print(f\"✅ MLflow setup complete!\")\n",
        "    print(f\"🔗 Tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "    print(f\"📊 Experiment: {experiment_name}\")\n",
        "\n",
        "    return experiment_name\n"
      ],
      "metadata": {
        "id": "jQhDzg5V9XWt"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prepare_data():\n",
        "    \"\"\"\n",
        "    Load and merge all datasets (train, stores, features)\n",
        "    Returns merged and initially cleaned dataset\n",
        "    \"\"\"\n",
        "    print(\"📂 Loading datasets...\")\n",
        "\n",
        "    # Load stores data\n",
        "    stores = pd.read_csv('stores.csv')\n",
        "\n",
        "    # Load and extract train data\n",
        "    with zipfile.ZipFile('train.csv.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "    train = pd.read_csv('train.csv')\n",
        "\n",
        "    # Load features data\n",
        "    with zipfile.ZipFile('features.csv.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "    features = pd.read_csv('features.csv')\n",
        "\n",
        "    # Convert dates\n",
        "    train['Date'] = pd.to_datetime(train['Date'])\n",
        "    features['Date'] = pd.to_datetime(features['Date'])\n",
        "\n",
        "    print(f\"✅ Loaded - Train: {train.shape}, Stores: {stores.shape}, Features: {features.shape}\")\n",
        "\n",
        "    # Merge datasets\n",
        "    print(\"🔗 Merging datasets...\")\n",
        "    train_with_stores = train.merge(stores, on='Store', how='left')\n",
        "    train_full = train_with_stores.merge(features, on=['Store', 'Date'], how='left')\n",
        "\n",
        "    print(f\"📊 Merged dataset shape: {train_full.shape}\")\n",
        "\n",
        "    return train_full"
      ],
      "metadata": {
        "id": "tTb-KlHa9YLV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_merged_data(train_full):\n",
        "    \"\"\"\n",
        "    Clean the merged dataset - handle duplicate columns, etc.\n",
        "    \"\"\"\n",
        "    print(\"🧹 Cleaning merged data...\")\n",
        "\n",
        "    # Handle duplicate IsHoliday columns\n",
        "    holiday_match = (train_full['IsHoliday_x'] == train_full['IsHoliday_y']).all()\n",
        "\n",
        "    if holiday_match:\n",
        "        train_clean = train_full.copy()\n",
        "        train_clean['IsHoliday'] = train_clean['IsHoliday_x']\n",
        "        train_clean = train_clean.drop(['IsHoliday_x', 'IsHoliday_y'], axis=1)\n",
        "    else:\n",
        "        # Keep the train dataset version if they don't match\n",
        "        train_clean = train_full.copy()\n",
        "        train_clean['IsHoliday'] = train_clean['IsHoliday_x']\n",
        "        train_clean = train_clean.drop(['IsHoliday_x', 'IsHoliday_y'], axis=1)\n",
        "\n",
        "    print(f\"✅ Clean dataset shape: {train_clean.shape}\")\n",
        "    return train_clean"
      ],
      "metadata": {
        "id": "BDaeqUUp9e-S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_temporal_split(df, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Create temporal train/validation split (80/20)\n",
        "    CRITICAL: Split BEFORE feature engineering to avoid data leakage\n",
        "    \"\"\"\n",
        "    print(\"✂️ Creating temporal train/validation split...\")\n",
        "\n",
        "    # Sort by date to ensure proper temporal order\n",
        "    df_sorted = df.sort_values('Date').copy()\n",
        "\n",
        "    # Calculate split point (80% for training)\n",
        "    total_dates = df_sorted['Date'].nunique()\n",
        "    split_point = int(total_dates * train_ratio)\n",
        "\n",
        "    # Get unique dates and find split date\n",
        "    unique_dates = sorted(df_sorted['Date'].unique())\n",
        "    split_date = unique_dates[split_point]\n",
        "\n",
        "    # Create splits\n",
        "    train_data = df_sorted[df_sorted['Date'] < split_date].copy()\n",
        "    val_data = df_sorted[df_sorted['Date'] >= split_date].copy()\n",
        "\n",
        "    print(f\"📅 Split date: {split_date}\")\n",
        "    print(f\"🚂 Training: {len(train_data):,} records ({len(train_data)/len(df)*100:.1f}%)\")\n",
        "    print(f\"🔮 Validation: {len(val_data):,} records ({len(val_data)/len(df)*100:.1f}%)\")\n",
        "    print(f\"📊 Train date range: {train_data['Date'].min()} to {train_data['Date'].max()}\")\n",
        "    print(f\"📊 Val date range: {val_data['Date'].min()} to {val_data['Date'].max()}\")\n",
        "\n",
        "    return train_data, val_data, split_date"
      ],
      "metadata": {
        "id": "IXg0OfCK9m33"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_date_features(df):\n",
        "    \"\"\"\n",
        "    Create comprehensive date-based features\n",
        "    \"\"\"\n",
        "    print(\"📅 Creating date features...\")\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Basic date features\n",
        "    df['Year'] = df['Date'].dt.year\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "    df['Day'] = df['Date'].dt.day\n",
        "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "    df['WeekOfYear'] = df['Date'].dt.isocalendar().week\n",
        "    df['Quarter'] = df['Date'].dt.quarter\n",
        "\n",
        "    # Weekend flag\n",
        "    df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)\n",
        "\n",
        "    # Month start/end flags\n",
        "    df['IsMonthStart'] = df['Date'].dt.is_month_start.astype(int)\n",
        "    df['IsMonthEnd'] = df['Date'].dt.is_month_end.astype(int)\n",
        "\n",
        "    # Quarter start/end flags\n",
        "    df['IsQuarterStart'] = df['Date'].dt.is_quarter_start.astype(int)\n",
        "    df['IsQuarterEnd'] = df['Date'].dt.is_quarter_end.astype(int)\n",
        "\n",
        "    # Time from start features\n",
        "    start_date = df['Date'].min()\n",
        "    df['DaysFromStart'] = (df['Date'] - start_date).dt.days\n",
        "    df['WeeksFromStart'] = df['DaysFromStart'] // 7\n",
        "\n",
        "    print(f\"✅ Created date features. New shape: {df.shape}\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "XOg9Kq879shr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers_business_aware(df):\n",
        "    \"\"\"\n",
        "    Remove outliers using business-aware thresholds for different store types\n",
        "    Based on experiment_2 approach\n",
        "    CRITICAL: Only fit on training data, but can be applied to validation\n",
        "    \"\"\"\n",
        "    print(\"🗑️ Removing outliers with business-aware approach...\")\n",
        "\n",
        "    # Define outlier thresholds by store type\n",
        "    outlier_thresholds = {\n",
        "        'A': {\n",
        "            'normal_upper': 180000,\n",
        "            'holiday_upper': 500000,\n",
        "            'reasoning': 'Type A stores are largest, can handle very high volumes on holidays'\n",
        "        },\n",
        "        'B': {\n",
        "            'normal_upper': 130000,\n",
        "            'holiday_upper': 700000,\n",
        "            'reasoning': 'Type B shows most dramatic holiday increases, need generous holiday threshold'\n",
        "        },\n",
        "        'C': {\n",
        "            'normal_upper': 100000,\n",
        "            'holiday_upper': 120000,\n",
        "            'reasoning': 'Type C stores are smallest, more conservative thresholds'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"🎯 Applying outlier thresholds to TRAINING data:\")\n",
        "    for store_type, thresholds in outlier_thresholds.items():\n",
        "        print(f\"   Store Type {store_type}: Normal>${thresholds['normal_upper']:,}, Holiday>${thresholds['holiday_upper']:,}\")\n",
        "\n",
        "    initial_count = len(df)\n",
        "    outlier_mask = pd.Series(False, index=df.index)\n",
        "\n",
        "    # Count outliers by store type for detailed logging\n",
        "    outlier_details = {}\n",
        "\n",
        "    for store_type in ['A', 'B', 'C']:\n",
        "        store_mask = df['Type'] == store_type\n",
        "        normal_mask = (df['IsHoliday'] == False) & (df['Weekly_Sales'] > outlier_thresholds[store_type]['normal_upper'])\n",
        "        holiday_mask = (df['IsHoliday'] == True) & (df['Weekly_Sales'] > outlier_thresholds[store_type]['holiday_upper'])\n",
        "\n",
        "        type_outliers = store_mask & (normal_mask | holiday_mask)\n",
        "        outlier_mask |= type_outliers\n",
        "\n",
        "        # Store details for logging\n",
        "        outlier_details[store_type] = {\n",
        "            'total_stores': store_mask.sum(),\n",
        "            'outliers_removed': type_outliers.sum(),\n",
        "            'outlier_rate': (type_outliers.sum() / store_mask.sum() * 100) if store_mask.sum() > 0 else 0\n",
        "        }\n",
        "\n",
        "    # Apply removal\n",
        "    df_clean = df[~outlier_mask].copy()\n",
        "    outliers_removed = initial_count - len(df_clean)\n",
        "\n",
        "    print(f\"\\n📊 TRAINING DATA OUTLIER REMOVAL RESULTS:\")\n",
        "    print(f\"   🗑️  Total outliers REMOVED: {outliers_removed:,} ({outliers_removed/initial_count*100:.2f}%)\")\n",
        "    for store_type, details in outlier_details.items():\n",
        "        print(f\"   📍 Store Type {store_type}: {details['outliers_removed']:,} removed from {details['total_stores']:,} records ({details['outlier_rate']:.2f}%)\")\n",
        "    print(f\"   ✅ Clean training records: {len(df_clean):,}\")\n",
        "    print(f\"   🎯 This improves model training by removing extreme values\")\n",
        "\n",
        "    return df_clean, outlier_thresholds\n"
      ],
      "metadata": {
        "id": "JCFGI49E9viQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_outliers_in_validation(val_data, outlier_thresholds):\n",
        "    \"\"\"\n",
        "    Analyze outliers in validation data using training-fitted thresholds\n",
        "    IMPORTANT: We only analyze, never remove outliers from validation data\n",
        "    This preserves the real-world distribution for proper model evaluation\n",
        "    \"\"\"\n",
        "    print(\"🔍 Analyzing outliers in VALIDATION data (NOT removing)...\")\n",
        "\n",
        "    outlier_mask = pd.Series(False, index=val_data.index)\n",
        "\n",
        "    # Count outliers by store type for detailed logging\n",
        "    outlier_details = {}\n",
        "\n",
        "    for store_type in ['A', 'B', 'C']:\n",
        "        store_mask = val_data['Type'] == store_type\n",
        "        normal_mask = (val_data['IsHoliday'] == False) & (val_data['Weekly_Sales'] > outlier_thresholds[store_type]['normal_upper'])\n",
        "        holiday_mask = (val_data['IsHoliday'] == True) & (val_data['Weekly_Sales'] > outlier_thresholds[store_type]['holiday_upper'])\n",
        "\n",
        "        type_outliers = store_mask & (normal_mask | holiday_mask)\n",
        "        outlier_mask |= type_outliers\n",
        "\n",
        "        # Store details for logging\n",
        "        outlier_details[store_type] = {\n",
        "            'total_stores': store_mask.sum(),\n",
        "            'outliers_found': type_outliers.sum(),\n",
        "            'outlier_rate': (type_outliers.sum() / store_mask.sum() * 100) if store_mask.sum() > 0 else 0\n",
        "        }\n",
        "\n",
        "    outliers_count = outlier_mask.sum()\n",
        "\n",
        "    print(f\"\\n📊 VALIDATION DATA OUTLIER ANALYSIS:\")\n",
        "    print(f\"   🔍 Total outliers FOUND: {outliers_count:,} ({outliers_count/len(val_data)*100:.2f}%)\")\n",
        "    for store_type, details in outlier_details.items():\n",
        "        print(f\"   📍 Store Type {store_type}: {details['outliers_found']:,} outliers in {details['total_stores']:,} records ({details['outlier_rate']:.2f}%)\")\n",
        "    print(f\"   ✅ KEEPING ALL {len(val_data):,} validation records (including outliers)\")\n",
        "    print(f\"   🎯 This tests model robustness on real-world data distribution\")\n",
        "    print(f\"   💡 Validation outliers help us understand model performance limits\")\n",
        "\n",
        "    return val_data\n"
      ],
      "metadata": {
        "id": "d9P3BgNV9zLP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_categorical_features(df):\n",
        "    \"\"\"\n",
        "    One-hot encode categorical features (specifically Type column)\n",
        "    \"\"\"\n",
        "    print(\"🔀 Encoding categorical features...\")\n",
        "\n",
        "    df_encoded = df.copy()\n",
        "\n",
        "    # One-hot encode Type column\n",
        "    if 'Type' in df_encoded.columns:\n",
        "        print(\"   📋 One-hot encoding 'Type' column...\")\n",
        "\n",
        "        # Get unique types before encoding\n",
        "        unique_types = sorted(df_encoded['Type'].unique())\n",
        "        print(f\"   🏪 Store types found: {unique_types}\")\n",
        "\n",
        "        # Create one-hot encoded columns\n",
        "        type_dummies = pd.get_dummies(df_encoded['Type'], prefix='Type', drop_first=False)\n",
        "\n",
        "        # Add the dummy columns to dataframe\n",
        "        df_encoded = pd.concat([df_encoded, type_dummies], axis=1)\n",
        "\n",
        "        # Drop original Type column\n",
        "        df_encoded = df_encoded.drop('Type', axis=1)\n",
        "\n",
        "        print(f\"   ✅ Created {len(type_dummies.columns)} Type dummy columns: {list(type_dummies.columns)}\")\n",
        "        print(f\"   🗑️ Dropped original 'Type' column\")\n",
        "\n",
        "    print(f\"📊 Shape after encoding: {df_encoded.shape}\")\n",
        "    return df_encoded"
      ],
      "metadata": {
        "id": "FXDqJVHbD5vy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_markdown_features(df):\n",
        "    \"\"\"\n",
        "    Remove MarkDown columns due to high missing values (64-73% missing)\n",
        "    \"\"\"\n",
        "    print(\"🗑️ Removing MarkDown features...\")\n",
        "\n",
        "    markdown_cols = [col for col in df.columns if 'MarkDown' in col]\n",
        "\n",
        "    print(\"MarkDown columns to remove:\")\n",
        "    for col in markdown_cols:\n",
        "        missing_pct = (df[col].isnull().sum() / len(df)) * 100\n",
        "        print(f\"   - {col}: {missing_pct:.1f}% missing\")\n",
        "\n",
        "    df_no_markdowns = df.drop(columns=markdown_cols).copy()\n",
        "\n",
        "    print(f\"✅ Removed {len(markdown_cols)} MarkDown columns\")\n",
        "    print(f\"📊 Shape after removal: {df_no_markdowns.shape}\")\n",
        "\n",
        "    return df_no_markdowns\n"
      ],
      "metadata": {
        "id": "xc-U8xdA-Ov2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_redundant_features(df):\n",
        "    \"\"\"\n",
        "    Remove redundant/highly correlated features\n",
        "    \"\"\"\n",
        "    print(\"🔧 Removing redundant features...\")\n",
        "\n",
        "    # Features to remove (keep the most interpretable ones)\n",
        "    features_to_remove = [\n",
        "        'DaysFromStart',      # Keep WeeksFromStart instead\n",
        "        'WeekOfYear',         # Keep Month instead\n",
        "        'Quarter',            # Keep Month instead\n",
        "        'Year',               # Keep WeeksFromStart for time trend\n",
        "        'IsQuarterStart',     # Keep IsMonthStart instead\n",
        "        'IsQuarterEnd',       # Keep IsMonthEnd instead\n",
        "        'Day'                 # Not very useful for weekly sales prediction\n",
        "    ]\n",
        "\n",
        "    print(\"🗑️ Features to remove:\")\n",
        "    for feature in features_to_remove:\n",
        "        if feature in df.columns:\n",
        "            print(f\"   - {feature}\")\n",
        "\n",
        "    # Remove redundant features\n",
        "    df_final = df.drop(columns=features_to_remove, errors='ignore').copy()\n",
        "\n",
        "    print(f\"✅ Removed {len(features_to_remove)} redundant features\")\n",
        "    print(f\"📊 Final shape: {df_final.shape}\")\n",
        "\n",
        "    return df_final\n"
      ],
      "metadata": {
        "id": "Kqiupkm7-Q_B"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_2_pipeline():\n",
        "    \"\"\"\n",
        "    Main function that replicates the experiment_2 pipeline with proper train/val split:\n",
        "    1. Load and merge data\n",
        "    2. Clean data\n",
        "    3. Split into train/validation (80/20) temporally\n",
        "    4. Fit feature engineering on TRAIN data only\n",
        "    5. Transform both train and validation\n",
        "    6. One-hot encode categorical features\n",
        "\n",
        "    Returns: train_processed, val_processed, split_info\n",
        "    \"\"\"\n",
        "    print(\"🚀 Starting Experiment 2 Pipeline with Train/Val Split\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Setup MLflow\n",
        "    experiment_name = setup_mlflow()\n",
        "\n",
        "    with mlflow.start_run(run_name=\"Experiment_2_Complete_Pipeline\") as run:\n",
        "\n",
        "        # Log experiment info\n",
        "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "        experiment_id = experiment.experiment_id\n",
        "        run_id = run.info.run_id\n",
        "\n",
        "        # Create MLflow links\n",
        "        mlflow_ui_url = f\"https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow\"\n",
        "        experiment_url = f\"{mlflow_ui_url}/#/experiments/{experiment_id}\"\n",
        "        run_url = f\"{mlflow_ui_url}/#/experiments/{experiment_id}/runs/{run_id}\"\n",
        "\n",
        "        print(f\"🔗 MLflow Experiment URL: {experiment_url}\")\n",
        "        print(f\"🔗 MLflow Run URL: {run_url}\")\n",
        "\n",
        "        # Log the URLs as parameters\n",
        "        mlflow.log_param(\"experiment_url\", experiment_url)\n",
        "        mlflow.log_param(\"run_url\", run_url)\n",
        "        mlflow.log_param(\"experiment_id\", experiment_id)\n",
        "        mlflow.log_param(\"run_id\", run_id)\n",
        "\n",
        "        # Step 1: Load and merge data\n",
        "        print(\"\\n📂 STEP 1: Loading and merging data...\")\n",
        "        df = load_and_prepare_data()\n",
        "\n",
        "        # Log initial data info\n",
        "        mlflow.log_param(\"initial_data_shape\", str(df.shape))\n",
        "        mlflow.log_metric(\"initial_samples\", len(df))\n",
        "        mlflow.log_param(\"date_range_start\", str(df['Date'].min()))\n",
        "        mlflow.log_param(\"date_range_end\", str(df['Date'].max()))\n",
        "\n",
        "        # Step 2: Clean merged data\n",
        "        print(\"\\n🧹 STEP 2: Cleaning merged data...\")\n",
        "        df_clean = clean_merged_data(df)\n",
        "\n",
        "        mlflow.log_param(\"clean_data_shape\", str(df_clean.shape))\n",
        "        mlflow.log_metric(\"clean_samples\", len(df_clean))\n",
        "\n",
        "        # Step 3: TEMPORAL SPLIT (BEFORE feature engineering!)\n",
        "        print(\"\\n✂️ STEP 3: Creating temporal train/validation split...\")\n",
        "        train_data, val_data, split_date = create_temporal_split(df_clean, train_ratio=0.8)\n",
        "\n",
        "        # Log split info\n",
        "        mlflow.log_param(\"split_date\", str(split_date))\n",
        "        mlflow.log_param(\"train_ratio\", 0.8)\n",
        "        mlflow.log_metric(\"train_samples\", len(train_data))\n",
        "        mlflow.log_metric(\"val_samples\", len(val_data))\n",
        "        mlflow.log_param(\"train_date_start\", str(train_data['Date'].min()))\n",
        "        mlflow.log_param(\"train_date_end\", str(train_data['Date'].max()))\n",
        "        mlflow.log_param(\"val_date_start\", str(val_data['Date'].min()))\n",
        "        mlflow.log_param(\"val_date_end\", str(val_data['Date'].max()))\n",
        "\n",
        "        # Step 4: Feature engineering on TRAIN data\n",
        "        print(\"\\n🔧 STEP 4: Feature engineering on TRAINING data...\")\n",
        "        train_featured = create_date_features(train_data)\n",
        "\n",
        "        # Step 5: Apply same feature engineering to VALIDATION data\n",
        "        print(\"\\n🔄 STEP 5: Applying same feature engineering to VALIDATION data...\")\n",
        "        val_featured = create_date_features(val_data)\n",
        "\n",
        "        mlflow.log_param(\"train_featured_shape\", str(train_featured.shape))\n",
        "        mlflow.log_param(\"val_featured_shape\", str(val_featured.shape))\n",
        "\n",
        "        # Step 6: Remove outliers from TRAIN data only\n",
        "        print(\"\\n🗑️ STEP 6: Removing outliers from TRAINING data only...\")\n",
        "        train_clean_outliers, outlier_thresholds = remove_outliers_business_aware(train_featured)\n",
        "\n",
        "        # Analyze (but don't remove) outliers in validation data\n",
        "        print(\"\\n🔍 STEP 6b: Analyzing outliers in VALIDATION data (keeping all)...\")\n",
        "        val_analyzed = analyze_outliers_in_validation(val_featured, outlier_thresholds)\n",
        "\n",
        "        # Log outlier comparison\n",
        "        outliers_removed = len(train_featured) - len(train_clean_outliers)\n",
        "        mlflow.log_metric(\"outliers_removed_train\", outliers_removed)\n",
        "        mlflow.log_metric(\"outlier_removal_rate_train\", outliers_removed/len(train_featured)*100)\n",
        "\n",
        "        # Count validation outliers for comparison\n",
        "        val_outlier_mask = pd.Series(False, index=val_analyzed.index)\n",
        "        for store_type in ['A', 'B', 'C']:\n",
        "            store_mask = val_analyzed['Type'] == store_type\n",
        "            normal_mask = (val_analyzed['IsHoliday'] == False) & (val_analyzed['Weekly_Sales'] > outlier_thresholds[store_type]['normal_upper'])\n",
        "            holiday_mask = (val_analyzed['IsHoliday'] == True) & (val_analyzed['Weekly_Sales'] > outlier_thresholds[store_type]['holiday_upper'])\n",
        "            val_outlier_mask |= store_mask & (normal_mask | holiday_mask)\n",
        "\n",
        "        val_outliers_found = val_outlier_mask.sum()\n",
        "        mlflow.log_metric(\"outliers_found_val\", val_outliers_found)\n",
        "        mlflow.log_metric(\"outlier_rate_val\", val_outliers_found/len(val_analyzed)*100)\n",
        "        mlflow.log_param(\"validation_outliers_kept\", \"ALL (no removal)\")\n",
        "\n",
        "        print(f\"\\n📈 OUTLIER PROCESSING SUMMARY:\")\n",
        "        print(f\"   🚂 Training: {outliers_removed:,} outliers REMOVED ({outliers_removed/len(train_featured)*100:.2f}%)\")\n",
        "        print(f\"   🔮 Validation: {val_outliers_found:,} outliers FOUND but KEPT ({val_outliers_found/len(val_analyzed)*100:.2f}%)\")\n",
        "        print(f\"   ⚖️  This ensures clean training while testing real-world robustness\")\n",
        "\n",
        "        # Step 7: Remove markdown features from both\n",
        "        print(\"\\n🗑️ STEP 7: Removing MarkDown features from both datasets...\")\n",
        "        train_no_markdowns = remove_markdown_features(train_clean_outliers)\n",
        "        val_no_markdowns = remove_markdown_features(val_analyzed)\n",
        "\n",
        "        # Step 8: Remove redundant features from both\n",
        "        print(\"\\n🔧 STEP 8: Removing redundant features from both datasets...\")\n",
        "        train_no_redundant = remove_redundant_features(train_no_markdowns)\n",
        "        val_no_redundant = remove_redundant_features(val_no_markdowns)\n",
        "\n",
        "        # Step 9: One-hot encode categorical features\n",
        "        print(\"\\n🔀 STEP 9: One-hot encoding categorical features...\")\n",
        "        train_final = encode_categorical_features(train_no_redundant)\n",
        "        val_final = encode_categorical_features(val_no_redundant)\n",
        "\n",
        "        # Log final results\n",
        "        mlflow.log_param(\"train_final_shape\", str(train_final.shape))\n",
        "        mlflow.log_param(\"val_final_shape\", str(val_final.shape))\n",
        "        mlflow.log_param(\"final_columns\", list(train_final.columns))\n",
        "        mlflow.log_metric(\"final_features_count\", train_final.shape[1])\n",
        "\n",
        "        # Log categorical encoding info\n",
        "        categorical_cols = [col for col in train_final.columns if col.startswith('Type_')]\n",
        "        mlflow.log_param(\"categorical_encoded_columns\", categorical_cols)\n",
        "        mlflow.log_metric(\"categorical_features_count\", len(categorical_cols))\n",
        "\n",
        "        # Final summary\n",
        "        print(\"\\n🎯 EXPERIMENT 2 PIPELINE COMPLETED!\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"📊 Training dataset: {train_final.shape}\")\n",
        "        print(f\"📊 Validation dataset: {val_final.shape}\")\n",
        "        print(f\"🔗 Final columns: {list(train_final.columns)}\")\n",
        "        print(f\"🔀 Categorical features encoded: {categorical_cols}\")\n",
        "        print(f\"\\n🔍 KEY DIFFERENCES:\")\n",
        "        print(f\"   🚂 Training: Cleaned data (outliers removed) for better learning\")\n",
        "        print(f\"   🔮 Validation: Real-world data (outliers kept) for robustness testing\")\n",
        "        print(f\"   🎯 Target column 'Weekly_Sales' available in both datasets for supervised learning\")\n",
        "        print(f\"   🔀 Categorical 'Type' column one-hot encoded into {len(categorical_cols)} binary features\")\n",
        "        print(f\"✅ No data leakage - feature engineering fitted on training data only!\")\n",
        "        print(f\"🚀 Datasets ready for modeling!\")\n",
        "        print(f\"\\n🔗 MLflow Links:\")\n",
        "        print(f\"   📊 Experiment: {experiment_url}\")\n",
        "        print(f\"   🏃 Current Run: {run_url}\")\n",
        "\n",
        "        # Return processed datasets and info\n",
        "        split_info = {\n",
        "            'split_date': split_date,\n",
        "            'train_samples': len(train_final),\n",
        "            'val_samples': len(val_final),\n",
        "            'outlier_thresholds': outlier_thresholds,\n",
        "            'experiment_url': experiment_url,\n",
        "            'run_url': run_url\n",
        "        }\n",
        "\n",
        "        return train_final, val_final, split_info\n"
      ],
      "metadata": {
        "id": "vJx7QnXG-TYp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run the pipeline\n",
        "    train_data, val_data, split_info = experiment_2_pipeline()\n",
        ""
      ],
      "metadata": {
        "id": "hTmNsdz_-XD9",
        "outputId": "0a6c2e43-4c4a-47bb-d396-a82246d11a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "379eed18e40a4d4d8d70393d4c7e5b57",
            "bd5c12e790504278a5c666ad1a914ed7"
          ]
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting Experiment 2 Pipeline with Train/Val Split\n",
            "============================================================\n",
            "🔧 Setting up MLflow and DagsHub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "379eed18e40a4d4d8d70393d4c7e5b57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Open the following link in your browser to authorize the client:\n",
            "https://dagshub.com/login/oauth/authorize?state=dd9465d3-7c92-45be-a92e-461e3f6093b5&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=628ed175a1cff14f662d86aafaa98a7f4a959767083b9366d51d7dddc67f8bca\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Accessing as konstantine25b\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as konstantine25b\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DagsHub initialized successfully!\n",
            "✅ Created new experiment: Experiment_6_Complete_Pipeline_20250703_114320\n",
            "✅ MLflow setup complete!\n",
            "🔗 Tracking URI: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow\n",
            "📊 Experiment: Experiment_6_Complete_Pipeline_20250703_114320\n",
            "🔗 MLflow Experiment URL: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/15\n",
            "🔗 MLflow Run URL: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/15/runs/ae4ff2a3615d454f8a122004ae13f356\n",
            "\n",
            "📂 STEP 1: Loading and merging data...\n",
            "📂 Loading datasets...\n",
            "✅ Loaded - Train: (421570, 5), Stores: (45, 3), Features: (8190, 12)\n",
            "🔗 Merging datasets...\n",
            "📊 Merged dataset shape: (421570, 17)\n",
            "\n",
            "🧹 STEP 2: Cleaning merged data...\n",
            "🧹 Cleaning merged data...\n",
            "✅ Clean dataset shape: (421570, 16)\n",
            "\n",
            "✂️ STEP 3: Creating temporal train/validation split...\n",
            "✂️ Creating temporal train/validation split...\n",
            "📅 Split date: 2012-04-13 00:00:00\n",
            "🚂 Training: 335,761 records (79.6%)\n",
            "🔮 Validation: 85,809 records (20.4%)\n",
            "📊 Train date range: 2010-02-05 00:00:00 to 2012-04-06 00:00:00\n",
            "📊 Val date range: 2012-04-13 00:00:00 to 2012-10-26 00:00:00\n",
            "\n",
            "🔧 STEP 4: Feature engineering on TRAINING data...\n",
            "📅 Creating date features...\n",
            "✅ Created date features. New shape: (335761, 29)\n",
            "\n",
            "🔄 STEP 5: Applying same feature engineering to VALIDATION data...\n",
            "📅 Creating date features...\n",
            "✅ Created date features. New shape: (85809, 29)\n",
            "\n",
            "🗑️ STEP 6: Removing outliers from TRAINING data only...\n",
            "🗑️ Removing outliers with business-aware approach...\n",
            "🎯 Applying outlier thresholds to TRAINING data:\n",
            "   Store Type A: Normal>$180,000, Holiday>$500,000\n",
            "   Store Type B: Normal>$130,000, Holiday>$700,000\n",
            "   Store Type C: Normal>$100,000, Holiday>$120,000\n",
            "\n",
            "📊 TRAINING DATA OUTLIER REMOVAL RESULTS:\n",
            "   🗑️  Total outliers REMOVED: 308 (0.09%)\n",
            "   📍 Store Type A: 180 removed from 171,750 records (0.10%)\n",
            "   📍 Store Type B: 118 removed from 130,287 records (0.09%)\n",
            "   📍 Store Type C: 10 removed from 33,724 records (0.03%)\n",
            "   ✅ Clean training records: 335,453\n",
            "   🎯 This improves model training by removing extreme values\n",
            "\n",
            "🔍 STEP 6b: Analyzing outliers in VALIDATION data (keeping all)...\n",
            "🔍 Analyzing outliers in VALIDATION data (NOT removing)...\n",
            "\n",
            "📊 VALIDATION DATA OUTLIER ANALYSIS:\n",
            "   🔍 Total outliers FOUND: 31 (0.04%)\n",
            "   📍 Store Type A: 26 outliers in 43,728 records (0.06%)\n",
            "   📍 Store Type B: 0 outliers in 33,208 records (0.00%)\n",
            "   📍 Store Type C: 5 outliers in 8,873 records (0.06%)\n",
            "   ✅ KEEPING ALL 85,809 validation records (including outliers)\n",
            "   🎯 This tests model robustness on real-world data distribution\n",
            "   💡 Validation outliers help us understand model performance limits\n",
            "\n",
            "📈 OUTLIER PROCESSING SUMMARY:\n",
            "   🚂 Training: 308 outliers REMOVED (0.09%)\n",
            "   🔮 Validation: 31 outliers FOUND but KEPT (0.04%)\n",
            "   ⚖️  This ensures clean training while testing real-world robustness\n",
            "\n",
            "🗑️ STEP 7: Removing MarkDown features from both datasets...\n",
            "🗑️ Removing MarkDown features...\n",
            "MarkDown columns to remove:\n",
            "   - MarkDown1: 80.6% missing\n",
            "   - MarkDown2: 82.7% missing\n",
            "   - MarkDown3: 82.1% missing\n",
            "   - MarkDown4: 82.6% missing\n",
            "   - MarkDown5: 80.5% missing\n",
            "✅ Removed 5 MarkDown columns\n",
            "📊 Shape after removal: (335453, 24)\n",
            "🗑️ Removing MarkDown features...\n",
            "MarkDown columns to remove:\n",
            "   - MarkDown1: 0.5% missing\n",
            "   - MarkDown2: 38.1% missing\n",
            "   - MarkDown3: 10.3% missing\n",
            "   - MarkDown4: 10.8% missing\n",
            "   - MarkDown5: 0.0% missing\n",
            "✅ Removed 5 MarkDown columns\n",
            "📊 Shape after removal: (85809, 24)\n",
            "\n",
            "🔧 STEP 8: Removing redundant features from both datasets...\n",
            "🔧 Removing redundant features...\n",
            "🗑️ Features to remove:\n",
            "   - DaysFromStart\n",
            "   - WeekOfYear\n",
            "   - Quarter\n",
            "   - Year\n",
            "   - IsQuarterStart\n",
            "   - IsQuarterEnd\n",
            "   - Day\n",
            "✅ Removed 7 redundant features\n",
            "📊 Final shape: (335453, 17)\n",
            "🔧 Removing redundant features...\n",
            "🗑️ Features to remove:\n",
            "   - DaysFromStart\n",
            "   - WeekOfYear\n",
            "   - Quarter\n",
            "   - Year\n",
            "   - IsQuarterStart\n",
            "   - IsQuarterEnd\n",
            "   - Day\n",
            "✅ Removed 7 redundant features\n",
            "📊 Final shape: (85809, 17)\n",
            "\n",
            "🔀 STEP 9: One-hot encoding categorical features...\n",
            "🔀 Encoding categorical features...\n",
            "   📋 One-hot encoding 'Type' column...\n",
            "   🏪 Store types found: ['A', 'B', 'C']\n",
            "   ✅ Created 3 Type dummy columns: ['Type_A', 'Type_B', 'Type_C']\n",
            "   🗑️ Dropped original 'Type' column\n",
            "📊 Shape after encoding: (335453, 19)\n",
            "🔀 Encoding categorical features...\n",
            "   📋 One-hot encoding 'Type' column...\n",
            "   🏪 Store types found: ['A', 'B', 'C']\n",
            "   ✅ Created 3 Type dummy columns: ['Type_A', 'Type_B', 'Type_C']\n",
            "   🗑️ Dropped original 'Type' column\n",
            "📊 Shape after encoding: (85809, 19)\n",
            "\n",
            "🎯 EXPERIMENT 2 PIPELINE COMPLETED!\n",
            "============================================================\n",
            "📊 Training dataset: (335453, 19)\n",
            "📊 Validation dataset: (85809, 19)\n",
            "🔗 Final columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'IsHoliday', 'Month', 'DayOfWeek', 'IsWeekend', 'IsMonthStart', 'IsMonthEnd', 'WeeksFromStart', 'Type_A', 'Type_B', 'Type_C']\n",
            "🔀 Categorical features encoded: ['Type_A', 'Type_B', 'Type_C']\n",
            "\n",
            "🔍 KEY DIFFERENCES:\n",
            "   🚂 Training: Cleaned data (outliers removed) for better learning\n",
            "   🔮 Validation: Real-world data (outliers kept) for robustness testing\n",
            "   🎯 Target column 'Weekly_Sales' available in both datasets for supervised learning\n",
            "   🔀 Categorical 'Type' column one-hot encoded into 3 binary features\n",
            "✅ No data leakage - feature engineering fitted on training data only!\n",
            "🚀 Datasets ready for modeling!\n",
            "\n",
            "🔗 MLflow Links:\n",
            "   📊 Experiment: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/15\n",
            "   🏃 Current Run: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/15/runs/ae4ff2a3615d454f8a122004ae13f356\n",
            "🏃 View run Experiment_2_Complete_Pipeline at: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/15/runs/ae4ff2a3615d454f8a122004ae13f356\n",
            "🧪 View experiment at: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_processed_data(train_data, val_data, split_info):\n",
        "    \"\"\"\n",
        "    Comprehensive analysis of the processed training and validation data\n",
        "    Creates visualizations and logs insights to MLflow\n",
        "\n",
        "    Args:\n",
        "        train_data: Processed training dataset\n",
        "        val_data: Processed validation dataset\n",
        "        split_info: Information about the train/val split\n",
        "    \"\"\"\n",
        "    print(\"\\n📊 STARTING DATA ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Set up plotting style\n",
        "    plt.style.use('default')\n",
        "    sns.set_palette(\"husl\")\n",
        "\n",
        "    with mlflow.start_run(run_name=\"Data_Analysis_Post_Processing\"):\n",
        "\n",
        "        # Basic dataset info\n",
        "        print(\"📋 BASIC DATASET INFORMATION\")\n",
        "        print(f\"Training shape: {train_data.shape}\")\n",
        "        print(f\"Validation shape: {val_data.shape}\")\n",
        "        print(f\"Split date: {split_info['split_date']}\")\n",
        "\n",
        "        # Log basic info\n",
        "        mlflow.log_param(\"analysis_train_shape\", str(train_data.shape))\n",
        "        mlflow.log_param(\"analysis_val_shape\", str(val_data.shape))\n",
        "\n",
        "        # 1. Target Variable Analysis\n",
        "        print(\"\\n🎯 TARGET VARIABLE ANALYSIS (Weekly_Sales)\")\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle('Weekly Sales Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Distribution\n",
        "        axes[0,0].hist(train_data['Weekly_Sales'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "        axes[0,0].set_title('Weekly Sales Distribution (Training)')\n",
        "        axes[0,0].set_xlabel('Weekly Sales ($)')\n",
        "        axes[0,0].set_ylabel('Frequency')\n",
        "        axes[0,0].ticklabel_format(style='plain', axis='x')\n",
        "\n",
        "        # Box plot by store type - need to reconstruct Type from one-hot encoded columns\n",
        "        type_cols = [col for col in train_data.columns if col.startswith('Type_')]\n",
        "        if type_cols:\n",
        "            # Reconstruct Type column for visualization\n",
        "            train_data_viz = train_data.copy()\n",
        "            train_data_viz['Type'] = ''\n",
        "            for col in type_cols:\n",
        "                store_type = col.replace('Type_', '')\n",
        "                train_data_viz.loc[train_data_viz[col] == 1, 'Type'] = store_type\n",
        "\n",
        "            train_data_viz.boxplot(column='Weekly_Sales', by='Type', ax=axes[0,1])\n",
        "            axes[0,1].set_title('Weekly Sales by Store Type')\n",
        "            axes[0,1].set_xlabel('Store Type')\n",
        "            axes[0,1].set_ylabel('Weekly Sales ($)')\n",
        "        else:\n",
        "            axes[0,1].text(0.5, 0.5, 'Type column not available\\n(already encoded)',\n",
        "                          ha='center', va='center', transform=axes[0,1].transAxes)\n",
        "            axes[0,1].set_title('Weekly Sales by Store Type - N/A')\n",
        "\n",
        "        # Time series\n",
        "        weekly_sales_trend = train_data.groupby('Date')['Weekly_Sales'].mean().reset_index()\n",
        "        axes[1,0].plot(weekly_sales_trend['Date'], weekly_sales_trend['Weekly_Sales'], color='green', linewidth=2)\n",
        "        axes[1,0].set_title('Weekly Sales Trend Over Time')\n",
        "        axes[1,0].set_xlabel('Date')\n",
        "        axes[1,0].set_ylabel('Average Weekly Sales ($)')\n",
        "        axes[1,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Holiday vs Non-Holiday\n",
        "        holiday_sales = train_data.groupby('IsHoliday')['Weekly_Sales'].agg(['mean', 'std']).reset_index()\n",
        "        holiday_sales['IsHoliday'] = holiday_sales['IsHoliday'].map({True: 'Holiday', False: 'Non-Holiday'})\n",
        "        axes[1,1].bar(holiday_sales['IsHoliday'], holiday_sales['mean'],\n",
        "                     yerr=holiday_sales['std'], capsize=5, color=['coral', 'lightblue'])\n",
        "        axes[1,1].set_title('Average Sales: Holiday vs Non-Holiday')\n",
        "        axes[1,1].set_ylabel('Average Weekly Sales ($)')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        mlflow.log_figure(fig, \"target_variable_analysis.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Target variable statistics\n",
        "        sales_stats = {\n",
        "            'mean': train_data['Weekly_Sales'].mean(),\n",
        "            'median': train_data['Weekly_Sales'].median(),\n",
        "            'std': train_data['Weekly_Sales'].std(),\n",
        "            'min': train_data['Weekly_Sales'].min(),\n",
        "            'max': train_data['Weekly_Sales'].max(),\n",
        "            'skewness': train_data['Weekly_Sales'].skew(),\n",
        "            'kurtosis': train_data['Weekly_Sales'].kurtosis()\n",
        "        }\n",
        "\n",
        "        print(f\"   Mean: ${sales_stats['mean']:,.2f}\")\n",
        "        print(f\"   Median: ${sales_stats['median']:,.2f}\")\n",
        "        print(f\"   Std: ${sales_stats['std']:,.2f}\")\n",
        "        print(f\"   Range: ${sales_stats['min']:,.2f} to ${sales_stats['max']:,.2f}\")\n",
        "        print(f\"   Skewness: {sales_stats['skewness']:.3f}\")\n",
        "        print(f\"   Kurtosis: {sales_stats['kurtosis']:.3f}\")\n",
        "\n",
        "        # Log target statistics\n",
        "        for key, value in sales_stats.items():\n",
        "            mlflow.log_metric(f\"sales_{key}\", value)\n",
        "\n",
        "        # 2. Store Analysis\n",
        "        print(\"\\n🏪 STORE ANALYSIS\")\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle('Store Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Store type distribution - reconstruct from one-hot encoded columns\n",
        "        type_cols = [col for col in train_data.columns if col.startswith('Type_')]\n",
        "        if type_cols:\n",
        "            type_counts = {}\n",
        "            for col in type_cols:\n",
        "                store_type = col.replace('Type_', '')\n",
        "                type_counts[store_type] = train_data[col].sum()\n",
        "\n",
        "            axes[0,0].pie(type_counts.values(), labels=type_counts.keys(), autopct='%1.1f%%', startangle=90)\n",
        "            axes[0,0].set_title('Store Type Distribution')\n",
        "\n",
        "            # Store size distribution by type\n",
        "            train_data_viz = train_data.copy()\n",
        "            train_data_viz['Type'] = ''\n",
        "            for col in type_cols:\n",
        "                store_type = col.replace('Type_', '')\n",
        "                train_data_viz.loc[train_data_viz[col] == 1, 'Type'] = store_type\n",
        "\n",
        "            train_data_viz.boxplot(column='Size', by='Type', ax=axes[0,1])\n",
        "            axes[0,1].set_title('Store Size by Type')\n",
        "            axes[0,1].set_xlabel('Store Type')\n",
        "            axes[0,1].set_ylabel('Store Size (sq ft)')\n",
        "\n",
        "            # Number of departments per store type\n",
        "            dept_by_type_data = []\n",
        "            for col in type_cols:\n",
        "                store_type = col.replace('Type_', '')\n",
        "                mask = train_data[col] == 1\n",
        "                dept_count = train_data[mask]['Dept'].nunique()\n",
        "                dept_by_type_data.append({'Type': store_type, 'Dept': dept_count})\n",
        "\n",
        "            dept_by_type = pd.DataFrame(dept_by_type_data)\n",
        "            axes[1,0].bar(dept_by_type['Type'], dept_by_type['Dept'], color=['lightcoral', 'lightblue', 'lightgreen'])\n",
        "            axes[1,0].set_title('Number of Unique Departments by Store Type')\n",
        "            axes[1,0].set_xlabel('Store Type')\n",
        "            axes[1,0].set_ylabel('Number of Departments')\n",
        "\n",
        "            # Average sales by store type\n",
        "            sales_by_type_data = []\n",
        "            for col in type_cols:\n",
        "                store_type = col.replace('Type_', '')\n",
        "                mask = train_data[col] == 1\n",
        "                avg_sales = train_data[mask]['Weekly_Sales'].mean()\n",
        "                sales_by_type_data.append({'Type': store_type, 'Weekly_Sales': avg_sales})\n",
        "\n",
        "            sales_by_type = pd.DataFrame(sales_by_type_data)\n",
        "            axes[1,1].bar(sales_by_type['Type'], sales_by_type['Weekly_Sales'], color=['lightcoral', 'lightblue', 'lightgreen'])\n",
        "            axes[1,1].set_title('Average Weekly Sales by Store Type')\n",
        "            axes[1,1].set_xlabel('Store Type')\n",
        "            axes[1,1].set_ylabel('Average Weekly Sales ($)')\n",
        "        else:\n",
        "            for i, ax in enumerate(axes.flatten()):\n",
        "                ax.text(0.5, 0.5, 'Type analysis not available\\n(column already encoded)',\n",
        "                       ha='center', va='center', transform=ax.transAxes)\n",
        "                ax.set_title(f'Store Analysis {i+1} - N/A')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        mlflow.log_figure(fig, \"store_analysis.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Store statistics - reconstruct from one-hot encoded data\n",
        "        if type_cols:\n",
        "            print(\"Store Type Statistics:\")\n",
        "            for col in type_cols:\n",
        "                store_type = col.replace('Type_', '')\n",
        "                mask = train_data[col] == 1\n",
        "                type_data = train_data[mask]\n",
        "\n",
        "                stats_data = {\n",
        "                    'Count': len(type_data),\n",
        "                    'Avg_Sales': type_data['Weekly_Sales'].mean(),\n",
        "                    'Std_Sales': type_data['Weekly_Sales'].std(),\n",
        "                    'Avg_Size': type_data['Size'].mean() if 'Size' in type_data.columns else 'N/A',\n",
        "                    'Unique_Stores': type_data['Store'].nunique() if 'Store' in type_data.columns else 'N/A',\n",
        "                    'Unique_Depts': type_data['Dept'].nunique() if 'Dept' in type_data.columns else 'N/A'\n",
        "                }\n",
        "\n",
        "                print(f\"   Store Type {store_type}:\")\n",
        "                for key, value in stats_data.items():\n",
        "                    if isinstance(value, (int, float)) and value != 'N/A':\n",
        "                        print(f\"      {key}: {value:,.2f}\")\n",
        "                    else:\n",
        "                        print(f\"      {key}: {value}\")\n",
        "\n",
        "                # Log store statistics\n",
        "                mlflow.log_metric(f\"store_type_{store_type}_avg_sales\", stats_data['Avg_Sales'])\n",
        "                if stats_data['Avg_Size'] != 'N/A':\n",
        "                    mlflow.log_metric(f\"store_type_{store_type}_avg_size\", stats_data['Avg_Size'])\n",
        "                mlflow.log_metric(f\"store_type_{store_type}_count\", stats_data['Count'])\n",
        "        else:\n",
        "            print(\"Store Type Statistics: Not available (Type column encoded)\")\n",
        "\n",
        "            # Log store statistics for encoded columns\n",
        "            for col in type_cols:\n",
        "                store_type = col.replace('Type_', '')\n",
        "                type_data = train_data[train_data[col] == 1]\n",
        "                mlflow.log_metric(f\"store_type_{store_type}_avg_sales\", type_data['Weekly_Sales'].mean())\n",
        "                mlflow.log_metric(f\"store_type_{store_type}_count\", len(type_data))\n",
        "\n",
        "        # 3. Temporal Analysis\n",
        "        print(\"\\n📅 TEMPORAL ANALYSIS\")\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle('Temporal Patterns Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Monthly sales pattern\n",
        "        monthly_sales = train_data.groupby('Month')['Weekly_Sales'].mean().reset_index()\n",
        "        axes[0,0].plot(monthly_sales['Month'], monthly_sales['Weekly_Sales'], marker='o', linewidth=2, markersize=6)\n",
        "        axes[0,0].set_title('Average Sales by Month')\n",
        "        axes[0,0].set_xlabel('Month')\n",
        "        axes[0,0].set_ylabel('Average Weekly Sales ($)')\n",
        "        axes[0,0].set_xticks(range(1, 13))\n",
        "        axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Day of week pattern\n",
        "        dow_sales = train_data.groupby('DayOfWeek')['Weekly_Sales'].mean().reset_index()\n",
        "        dow_labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "        axes[0,1].bar(range(7), dow_sales['Weekly_Sales'], color='lightsteelblue')\n",
        "        axes[0,1].set_title('Average Sales by Day of Week')\n",
        "        axes[0,1].set_xlabel('Day of Week')\n",
        "        axes[0,1].set_ylabel('Average Weekly Sales ($)')\n",
        "        axes[0,1].set_xticks(range(7))\n",
        "        axes[0,1].set_xticklabels(dow_labels)\n",
        "\n",
        "        # Weekend vs Weekday\n",
        "        weekend_sales = train_data.groupby('IsWeekend')['Weekly_Sales'].mean().reset_index()\n",
        "        weekend_sales['IsWeekend'] = weekend_sales['IsWeekend'].map({0: 'Weekday', 1: 'Weekend'})\n",
        "        axes[1,0].bar(weekend_sales['IsWeekend'], weekend_sales['Weekly_Sales'], color=['lightblue', 'orange'])\n",
        "        axes[1,0].set_title('Average Sales: Weekday vs Weekend')\n",
        "        axes[1,0].set_ylabel('Average Weekly Sales ($)')\n",
        "\n",
        "        # Time trend (weeks from start)\n",
        "        time_trend = train_data.groupby('WeeksFromStart')['Weekly_Sales'].mean().reset_index()\n",
        "        axes[1,1].plot(time_trend['WeeksFromStart'], time_trend['Weekly_Sales'], color='purple', linewidth=2)\n",
        "        axes[1,1].set_title('Sales Trend Over Time (Weeks from Start)')\n",
        "        axes[1,1].set_xlabel('Weeks from Start')\n",
        "        axes[1,1].set_ylabel('Average Weekly Sales ($)')\n",
        "        axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        mlflow.log_figure(fig, \"temporal_analysis.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Temporal statistics\n",
        "        print(\"Temporal Patterns:\")\n",
        "        print(f\"   Best month: {monthly_sales.loc[monthly_sales['Weekly_Sales'].idxmax(), 'Month']}\")\n",
        "        print(f\"   Worst month: {monthly_sales.loc[monthly_sales['Weekly_Sales'].idxmin(), 'Month']}\")\n",
        "\n",
        "        # Calculate weekend boost more safely\n",
        "        weekend_data = weekend_sales[weekend_sales['IsWeekend'] == 'Weekend']\n",
        "        weekday_data = weekend_sales[weekend_sales['IsWeekend'] == 'Weekday']\n",
        "\n",
        "        if len(weekend_data) > 0 and len(weekday_data) > 0:\n",
        "            weekend_boost = (weekend_data['Weekly_Sales'].iloc[0] / weekday_data['Weekly_Sales'].iloc[0] - 1) * 100\n",
        "            print(f\"   Weekend boost: {weekend_boost:.1f}%\")\n",
        "        else:\n",
        "            weekend_boost = 0\n",
        "            print(\"   Weekend boost: N/A (insufficient data)\")\n",
        "\n",
        "        # Log temporal metrics\n",
        "        mlflow.log_metric(\"best_month\", monthly_sales.loc[monthly_sales['Weekly_Sales'].idxmax(), 'Month'])\n",
        "        mlflow.log_metric(\"worst_month\", monthly_sales.loc[monthly_sales['Weekly_Sales'].idxmin(), 'Month'])\n",
        "        mlflow.log_metric(\"weekend_boost_percent\", weekend_boost)\n",
        "\n",
        "        # 4. Feature Correlation Analysis\n",
        "        print(\"\\n🔗 FEATURE CORRELATION ANALYSIS\")\n",
        "\n",
        "        # Select numeric columns for correlation\n",
        "        numeric_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        if 'Store' in numeric_cols: numeric_cols.remove('Store')  # Remove ID column\n",
        "        if 'Dept' in numeric_cols: numeric_cols.remove('Dept')   # Remove ID column\n",
        "\n",
        "        correlation_matrix = train_data[numeric_cols].corr()\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
        "                   square=True, ax=ax, cbar_kws={\"shrink\": .8})\n",
        "        ax.set_title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
        "        plt.tight_layout()\n",
        "        mlflow.log_figure(fig, \"correlation_matrix.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Find strongest correlations with target\n",
        "        sales_correlations = correlation_matrix['Weekly_Sales'].abs().sort_values(ascending=False)\n",
        "        print(\"Strongest correlations with Weekly_Sales:\")\n",
        "        for feature, corr in sales_correlations.head(8).items():\n",
        "            if feature != 'Weekly_Sales':\n",
        "                print(f\"   {feature}: {corr:.3f}\")\n",
        "                mlflow.log_metric(f\"correlation_{feature}\", corr)\n",
        "\n",
        "        # 5. Missing Values Analysis\n",
        "        print(\"\\n❓ MISSING VALUES ANALYSIS\")\n",
        "\n",
        "        missing_train = train_data.isnull().sum()\n",
        "        missing_val = val_data.isnull().sum()\n",
        "\n",
        "        missing_df = pd.DataFrame({\n",
        "            'Training': missing_train,\n",
        "            'Validation': missing_val,\n",
        "            'Train_%': (missing_train / len(train_data)) * 100,\n",
        "            'Val_%': (missing_val / len(val_data)) * 100\n",
        "        }).round(2)\n",
        "\n",
        "        print(\"Missing values summary:\")\n",
        "        print(missing_df[missing_df['Training'] > 0])\n",
        "\n",
        "        # Log missing values info\n",
        "        total_missing_train = missing_train.sum()\n",
        "        total_missing_val = missing_val.sum()\n",
        "        mlflow.log_metric(\"total_missing_values_train\", total_missing_train)\n",
        "        mlflow.log_metric(\"total_missing_values_val\", total_missing_val)\n",
        "\n",
        "        # 6. Data Quality Summary\n",
        "        print(\"\\n✅ DATA QUALITY SUMMARY\")\n",
        "        print(f\"   📊 Training samples: {len(train_data):,}\")\n",
        "        print(f\"   📊 Validation samples: {len(val_data):,}\")\n",
        "        print(f\"   🔗 Features: {len(train_data.columns)-1} (excluding target)\")\n",
        "        print(f\"   ❓ Missing values: {total_missing_train} in training, {total_missing_val} in validation\")\n",
        "        print(f\"   🎯 Target range: ${train_data['Weekly_Sales'].min():,.2f} to ${train_data['Weekly_Sales'].max():,.2f}\")\n",
        "\n",
        "        # Count store types from encoded columns\n",
        "        type_cols = [col for col in train_data.columns if col.startswith('Type_')]\n",
        "        store_types_count = len(type_cols)\n",
        "        print(f\"   🏪 Store types: {store_types_count} (A, B, C)\")\n",
        "        print(f\"   📅 Time span: {(train_data['Date'].max() - train_data['Date'].min()).days} days\")\n",
        "\n",
        "        # Final data quality metrics\n",
        "        mlflow.log_metric(\"final_feature_count\", len(train_data.columns)-1)\n",
        "        mlflow.log_metric(\"store_types_count\", store_types_count)\n",
        "        mlflow.log_metric(\"departments_count\", train_data['Dept'].nunique())\n",
        "        mlflow.log_metric(\"time_span_days\", (train_data['Date'].max() - train_data['Date'].min()).days)\n",
        "\n",
        "        print(\"\\n📊 DATA ANALYSIS COMPLETED!\")\n",
        "        print(\"🔗 All plots and metrics logged to MLflow\")\n",
        "        print(\"=\" * 50)\n"
      ],
      "metadata": {
        "id": "afpO04ZMCHCQ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_processed_data(train_data, val_data, split_info)"
      ],
      "metadata": {
        "id": "jSy0IjAnCH6m",
        "outputId": "61f731e5-d541-45e2-d4be-3f487e759a81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 STARTING DATA ANALYSIS\n",
            "==================================================\n",
            "📋 BASIC DATASET INFORMATION\n",
            "Training shape: (335453, 19)\n",
            "Validation shape: (85809, 19)\n",
            "Split date: 2012-04-13 00:00:00\n",
            "\n",
            "🎯 TARGET VARIABLE ANALYSIS (Weekly_Sales)\n",
            "   Mean: $15,873.74\n",
            "   Median: $7,636.72\n",
            "   Std: $22,262.57\n",
            "   Range: $-4,988.94 to $693,099.36\n",
            "   Skewness: 3.178\n",
            "   Kurtosis: 22.166\n",
            "\n",
            "🏪 STORE ANALYSIS\n",
            "Store Type Statistics:\n",
            "   Store Type A:\n",
            "      Count: 171,570.00\n",
            "      Avg_Sales: 19,950.28\n",
            "      Std_Sales: 25,866.49\n",
            "      Avg_Size: 182,250.42\n",
            "      Unique_Stores: 22.00\n",
            "      Unique_Depts: 81.00\n",
            "   Store Type B:\n",
            "      Count: 130,169.00\n",
            "      Avg_Sales: 12,153.91\n",
            "      Std_Sales: 16,852.17\n",
            "      Avg_Size: 101,822.50\n",
            "      Unique_Stores: 17.00\n",
            "      Unique_Depts: 80.00\n",
            "   Store Type C:\n",
            "      Count: 33,714.00\n",
            "      Avg_Sales: 9,490.49\n",
            "      Std_Sales: 15,851.93\n",
            "      Avg_Size: 40,543.11\n",
            "      Unique_Stores: 6.00\n",
            "      Unique_Depts: 66.00\n",
            "\n",
            "📅 TEMPORAL ANALYSIS\n",
            "Temporal Patterns:\n",
            "   Best month: 12\n",
            "   Worst month: 1\n",
            "   Weekend boost: N/A (insufficient data)\n",
            "\n",
            "🔗 FEATURE CORRELATION ANALYSIS\n",
            "Strongest correlations with Weekly_Sales:\n",
            "   Size: 0.246\n",
            "   Month: 0.030\n",
            "   Unemployment: 0.024\n",
            "   CPI: 0.021\n",
            "   IsMonthEnd: 0.011\n",
            "   IsMonthStart: 0.006\n",
            "   Fuel_Price: 0.004\n",
            "\n",
            "❓ MISSING VALUES ANALYSIS\n",
            "Missing values summary:\n",
            "Empty DataFrame\n",
            "Columns: [Training, Validation, Train_%, Val_%]\n",
            "Index: []\n",
            "\n",
            "✅ DATA QUALITY SUMMARY\n",
            "   📊 Training samples: 335,453\n",
            "   📊 Validation samples: 85,809\n",
            "   🔗 Features: 18 (excluding target)\n",
            "   ❓ Missing values: 0 in training, 0 in validation\n",
            "   🎯 Target range: $-4,988.94 to $693,099.36\n",
            "   🏪 Store types: 3 (A, B, C)\n",
            "   📅 Time span: 791 days\n",
            "\n",
            "📊 DATA ANALYSIS COMPLETED!\n",
            "🔗 All plots and metrics logged to MLflow\n",
            "==================================================\n",
            "🏃 View run Data_Analysis_Post_Processing at: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/15/runs/8711dad8ab5e43f3a9cdbad30f87c7e2\n",
            "🧪 View experiment at: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(5)"
      ],
      "metadata": {
        "id": "LU2W_JH8DNh4",
        "outputId": "d515f7e8-d848-409c-9a1e-bd03ef5dd27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Store  Dept       Date  Weekly_Sales    Size  Temperature  Fuel_Price  \\\n",
              "0           1     1 2010-02-05      24924.50  151315        42.31       2.572   \n",
              "277665     29     5 2010-02-05      15552.08   93638        24.36       2.788   \n",
              "277808     29     6 2010-02-05       3200.22   93638        24.36       2.788   \n",
              "277951     29     7 2010-02-05      10820.05   93638        24.36       2.788   \n",
              "278094     29     8 2010-02-05      20055.64   93638        24.36       2.788   \n",
              "\n",
              "               CPI  Unemployment  IsHoliday  Month  DayOfWeek  IsWeekend  \\\n",
              "0       211.096358         8.106      False      2          4          0   \n",
              "277665  131.527903        10.064      False      2          4          0   \n",
              "277808  131.527903        10.064      False      2          4          0   \n",
              "277951  131.527903        10.064      False      2          4          0   \n",
              "278094  131.527903        10.064      False      2          4          0   \n",
              "\n",
              "        IsMonthStart  IsMonthEnd  WeeksFromStart  Type_A  Type_B  Type_C  \n",
              "0                  0           0               0    True   False   False  \n",
              "277665             0           0               0   False    True   False  \n",
              "277808             0           0               0   False    True   False  \n",
              "277951             0           0               0   False    True   False  \n",
              "278094             0           0               0   False    True   False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d648e2e3-4e07-436c-ba5e-e8ac00482283\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>IsWeekend</th>\n",
              "      <th>IsMonthStart</th>\n",
              "      <th>IsMonthEnd</th>\n",
              "      <th>WeeksFromStart</th>\n",
              "      <th>Type_A</th>\n",
              "      <th>Type_B</th>\n",
              "      <th>Type_C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>151315</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277665</th>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>15552.08</td>\n",
              "      <td>93638</td>\n",
              "      <td>24.36</td>\n",
              "      <td>2.788</td>\n",
              "      <td>131.527903</td>\n",
              "      <td>10.064</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277808</th>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>3200.22</td>\n",
              "      <td>93638</td>\n",
              "      <td>24.36</td>\n",
              "      <td>2.788</td>\n",
              "      <td>131.527903</td>\n",
              "      <td>10.064</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277951</th>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>10820.05</td>\n",
              "      <td>93638</td>\n",
              "      <td>24.36</td>\n",
              "      <td>2.788</td>\n",
              "      <td>131.527903</td>\n",
              "      <td>10.064</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278094</th>\n",
              "      <td>29</td>\n",
              "      <td>8</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>20055.64</td>\n",
              "      <td>93638</td>\n",
              "      <td>24.36</td>\n",
              "      <td>2.788</td>\n",
              "      <td>131.527903</td>\n",
              "      <td>10.064</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d648e2e3-4e07-436c-ba5e-e8ac00482283')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d648e2e3-4e07-436c-ba5e-e8ac00482283 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d648e2e3-4e07-436c-ba5e-e8ac00482283');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-51c56c90-d811-4d86-858b-2eea47d80cde\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51c56c90-d811-4d86-858b-2eea47d80cde')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-51c56c90-d811-4d86-858b-2eea47d80cde button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data.head(5)"
      ],
      "metadata": {
        "id": "2ujoHyZRHC1a",
        "outputId": "56cf105f-e7e4-4dc4-9ae2-4600cab77ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Store  Dept       Date  Weekly_Sales    Size  Temperature  Fuel_Price  \\\n",
              "210312     22    24 2012-04-13       6744.61  119557        49.89       4.025   \n",
              "165607     17    81 2012-04-13       9920.86   93188        46.94       3.833   \n",
              "409905     44    80 2012-04-13       5035.59   39910        51.70       3.833   \n",
              "202057     21    33 2012-04-13       7486.67  140167        69.03       3.891   \n",
              "371927     40     7 2012-04-13      16465.22  155083        40.65       4.025   \n",
              "\n",
              "               CPI  Unemployment  IsHoliday  Month  DayOfWeek  IsWeekend  \\\n",
              "210312  141.843393         7.671      False      4          4          0   \n",
              "165607  131.108000         6.235      False      4          4          0   \n",
              "409905  131.108000         5.621      False      4          4          0   \n",
              "202057  221.148403         6.891      False      4          4          0   \n",
              "371927  137.868000         4.125      False      4          4          0   \n",
              "\n",
              "        IsMonthStart  IsMonthEnd  WeeksFromStart  Type_A  Type_B  Type_C  \n",
              "210312             0           0               0   False    True   False  \n",
              "165607             0           0               0   False    True   False  \n",
              "409905             0           0               0   False   False    True  \n",
              "202057             0           0               0   False    True   False  \n",
              "371927             0           0               0    True   False   False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7573dcb4-8911-4f98-bd65-2d2298838885\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>IsWeekend</th>\n",
              "      <th>IsMonthStart</th>\n",
              "      <th>IsMonthEnd</th>\n",
              "      <th>WeeksFromStart</th>\n",
              "      <th>Type_A</th>\n",
              "      <th>Type_B</th>\n",
              "      <th>Type_C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>210312</th>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>2012-04-13</td>\n",
              "      <td>6744.61</td>\n",
              "      <td>119557</td>\n",
              "      <td>49.89</td>\n",
              "      <td>4.025</td>\n",
              "      <td>141.843393</td>\n",
              "      <td>7.671</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165607</th>\n",
              "      <td>17</td>\n",
              "      <td>81</td>\n",
              "      <td>2012-04-13</td>\n",
              "      <td>9920.86</td>\n",
              "      <td>93188</td>\n",
              "      <td>46.94</td>\n",
              "      <td>3.833</td>\n",
              "      <td>131.108000</td>\n",
              "      <td>6.235</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409905</th>\n",
              "      <td>44</td>\n",
              "      <td>80</td>\n",
              "      <td>2012-04-13</td>\n",
              "      <td>5035.59</td>\n",
              "      <td>39910</td>\n",
              "      <td>51.70</td>\n",
              "      <td>3.833</td>\n",
              "      <td>131.108000</td>\n",
              "      <td>5.621</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202057</th>\n",
              "      <td>21</td>\n",
              "      <td>33</td>\n",
              "      <td>2012-04-13</td>\n",
              "      <td>7486.67</td>\n",
              "      <td>140167</td>\n",
              "      <td>69.03</td>\n",
              "      <td>3.891</td>\n",
              "      <td>221.148403</td>\n",
              "      <td>6.891</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371927</th>\n",
              "      <td>40</td>\n",
              "      <td>7</td>\n",
              "      <td>2012-04-13</td>\n",
              "      <td>16465.22</td>\n",
              "      <td>155083</td>\n",
              "      <td>40.65</td>\n",
              "      <td>4.025</td>\n",
              "      <td>137.868000</td>\n",
              "      <td>4.125</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7573dcb4-8911-4f98-bd65-2d2298838885')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7573dcb4-8911-4f98-bd65-2d2298838885 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7573dcb4-8911-4f98-bd65-2d2298838885');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fb8497d9-42b7-422c-b281-f19a4af5faa0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb8497d9-42b7-422c-b281-f19a4af5faa0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fb8497d9-42b7-422c-b281-f19a4af5faa0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val_data",
              "summary": "{\n  \"name\": \"val_data\",\n  \"rows\": 85809,\n  \"fields\": [\n    {\n      \"column\": \"Store\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 45,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          28,\n          39,\n          38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dept\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 1,\n        \"max\": 99,\n        \"num_unique_values\": 81,\n        \"samples\": [\n          95,\n          24,\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2012-04-13 00:00:00\",\n        \"max\": \"2012-10-26 00:00:00\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"2012-10-19 00:00:00\",\n          \"2012-08-03 00:00:00\",\n          \"2012-07-06 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weekly_Sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21958.215941597453,\n        \"min\": -771.9,\n        \"max\": 206575.9,\n        \"num_unique_values\": 79734,\n        \"samples\": [\n          16243.22,\n          14873.1,\n          3595.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 61141,\n        \"min\": 34875,\n        \"max\": 219622,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          155078,\n          202307,\n          196321\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.869998880547733,\n        \"min\": 36.9,\n        \"max\": 100.07,\n        \"num_unique_values\": 897,\n        \"samples\": [\n          84.97,\n          77.9,\n          66.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fuel_Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24857822731087775,\n        \"min\": 3.187,\n        \"max\": 4.468,\n        \"num_unique_values\": 229,\n        \"samples\": [\n          3.75,\n          3.551,\n          4.027\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CPI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.57609093077529,\n        \"min\": 130.683,\n        \"max\": 227.2328068,\n        \"num_unique_values\": 435,\n        \"samples\": [\n          223.6510224,\n          221.380331,\n          191.0091712\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unemployment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6817751877419933,\n        \"min\": 3.879,\n        \"max\": 11.627,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          7.992,\n          7.671,\n          7.139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsHoliday\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Month\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DayOfWeek\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsWeekend\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsMonthStart\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsMonthEnd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WeeksFromStart\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 28,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type_A\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type_B\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type_C\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_holiday_features(df):\n",
        "    \"\"\"\n",
        "    Create Holiday Features (7 features) based on experiment 4 approach\n",
        "    \"\"\"\n",
        "    print(\"🎉 Creating holiday features...\")\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Walmart-specific holiday features based on the provided dates\n",
        "    super_bowl_dates = ['2010-02-12', '2011-02-11', '2012-02-10']\n",
        "    labor_day_dates = ['2010-09-10', '2011-09-09', '2012-09-07']\n",
        "    thanksgiving_dates = ['2010-11-26', '2011-11-25', '2012-11-23']\n",
        "    christmas_dates = ['2010-12-31', '2011-12-30', '2012-12-28']\n",
        "\n",
        "    # Create specific holiday flags\n",
        "    df['IsSuperBowlWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(super_bowl_dates).astype(int)\n",
        "    df['IsLaborDayWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(labor_day_dates).astype(int)\n",
        "    df['IsThanksgivingWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(thanksgiving_dates).astype(int)\n",
        "    df['IsChristmasWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(christmas_dates).astype(int)\n",
        "\n",
        "    # Combine major holidays\n",
        "    df['IsMajorHoliday'] = (df['IsSuperBowlWeek'] | df['IsLaborDayWeek'] |\n",
        "                           df['IsThanksgivingWeek'] | df['IsChristmasWeek']).astype(int)\n",
        "\n",
        "    # Additional retail calendar features\n",
        "    df['IsHolidayMonth'] = df['Month'].isin([11, 12]).astype(int)  # November, December\n",
        "    df['IsBackToSchool'] = df['Month'].isin([8, 9]).astype(int)    # August, September\n",
        "\n",
        "    holiday_features = [\n",
        "        'IsSuperBowlWeek', 'IsLaborDayWeek', 'IsThanksgivingWeek',\n",
        "        'IsChristmasWeek', 'IsMajorHoliday', 'IsHolidayMonth', 'IsBackToSchool'\n",
        "    ]\n",
        "\n",
        "    print(f\"✅ Created {len(holiday_features)} holiday features: {holiday_features}\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "ik80UocKITk4"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lag_features_no_leakage(train_data, val_data, target_col='Weekly_Sales'):\n",
        "    \"\"\"\n",
        "    Create Lag Features WITHOUT data leakage\n",
        "    - Uses only TRAINING data Weekly_Sales to create lag features\n",
        "    - Extends lag features to validation data using last known training values\n",
        "    - Validation Weekly_Sales is NOT used for feature creation\n",
        "\n",
        "    Args:\n",
        "        train_data: Training data with Weekly_Sales\n",
        "        val_data: Validation data with Weekly_Sales (but we won't use it for lags)\n",
        "        target_col: Target column name\n",
        "\n",
        "    Returns:\n",
        "        train_final, val_final with lag features (no data leakage)\n",
        "    \"\"\"\n",
        "    print(\"⏳ Creating lag features WITHOUT data leakage...\")\n",
        "\n",
        "    # Combine data but mark which is train vs val\n",
        "    train_copy = train_data.copy()\n",
        "    val_copy = val_data.copy()\n",
        "\n",
        "    train_copy['is_train'] = True\n",
        "    val_copy['is_train'] = False\n",
        "\n",
        "    # Combine for proper sorting\n",
        "    combined = pd.concat([train_copy, val_copy], ignore_index=True)\n",
        "    combined = combined.sort_values(['Store', 'Dept', 'Date']).reset_index(drop=True)\n",
        "\n",
        "    # Define lag periods (weeks)\n",
        "    lags = [1, 2, 3, 4, 8, 12]\n",
        "\n",
        "    print(f\"🚂 Creating lag features from TRAINING data only...\")\n",
        "    print(f\"   Lag periods: {lags} weeks\")\n",
        "\n",
        "    # Create lag features using ONLY training data\n",
        "    for lag in lags:\n",
        "        lag_col = f'{target_col}_lag_{lag}'\n",
        "\n",
        "        # Create lag feature but mask validation target values\n",
        "        combined[f'{target_col}_for_lag'] = combined[target_col].where(combined['is_train'], np.nan)\n",
        "\n",
        "        # Create lag feature\n",
        "        combined[lag_col] = combined.groupby(['Store', 'Dept'])[f'{target_col}_for_lag'].shift(lag)\n",
        "\n",
        "        # Fill NaNs with 0 (for early periods without enough history)\n",
        "        combined[lag_col] = combined[lag_col].fillna(0)\n",
        "\n",
        "    # Drop the temporary column\n",
        "    combined = combined.drop(f'{target_col}_for_lag', axis=1)\n",
        "\n",
        "    # Split back into train and validation\n",
        "    train_final = combined[combined['is_train'] == True].copy()\n",
        "    val_final = combined[combined['is_train'] == False].copy()\n",
        "\n",
        "    # Remove the is_train flag\n",
        "    train_final = train_final.drop('is_train', axis=1)\n",
        "    val_final = val_final.drop('is_train', axis=1)\n",
        "\n",
        "    # Reset indices\n",
        "    train_final = train_final.reset_index(drop=True)\n",
        "    val_final = val_final.reset_index(drop=True)\n",
        "\n",
        "    lag_features = [f'{target_col}_lag_{lag}' for lag in lags]\n",
        "    print(f\"✅ Created {len(lag_features)} lag features without data leakage: {lag_features}\")\n",
        "    print(f\"🔒 Validation Weekly_Sales was NOT used for lag feature creation\")\n",
        "\n",
        "    return train_final, val_final"
      ],
      "metadata": {
        "id": "_sXHYmETIUSf"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_with_additional_features(train_data, val_data):\n",
        "    \"\"\"\n",
        "    Enhance existing processed data with Holiday Features and Lag Features\n",
        "    This function adds features WITHOUT changing existing data structure\n",
        "\n",
        "    Args:\n",
        "        train_data: Already processed training data\n",
        "        val_data: Already processed validation data\n",
        "\n",
        "    Returns:\n",
        "        Enhanced train_data and val_data with additional features\n",
        "    \"\"\"\n",
        "    print(\"🚀 Enhancing data with additional features...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Log initial shapes\n",
        "    print(f\"📊 Initial shapes - Train: {train_data.shape}, Val: {val_data.shape}\")\n",
        "\n",
        "    # Step 1: Add Holiday Features to both datasets\n",
        "    print(\"\\n🎉 STEP 1: Adding Holiday Features...\")\n",
        "    train_enhanced = create_holiday_features(train_data)\n",
        "    val_enhanced = create_holiday_features(val_data)\n",
        "\n",
        "    # Step 2: Add Lag Features to both datasets separately (CRITICAL for no data leakage)\n",
        "    print(\"\\n⏳ STEP 2: Adding Lag Features...\")\n",
        "    print(\"🚂 Processing training data...\")\n",
        "    train_final = create_lag_features(train_enhanced, target_col='Weekly_Sales')\n",
        "\n",
        "    print(\"🔮 Processing validation data...\")\n",
        "    val_final = create_lag_features(val_enhanced, target_col='Weekly_Sales')\n",
        "\n",
        "    # Step 3: Ensure both datasets have same columns\n",
        "    print(\"\\n🔄 STEP 3: Ensuring column consistency...\")\n",
        "    train_cols = set(train_final.columns)\n",
        "    val_cols = set(val_final.columns)\n",
        "\n",
        "    common_cols = list(train_cols.intersection(val_cols))\n",
        "    train_final = train_final[common_cols]\n",
        "    val_final = val_final[common_cols]\n",
        "\n",
        "    # Step 4: Summary of enhancements\n",
        "    original_features = train_data.shape[1]\n",
        "    final_features = train_final.shape[1]\n",
        "    features_added = final_features - original_features\n",
        "\n",
        "    print(f\"\\n✅ ENHANCEMENT COMPLETE!\")\n",
        "    print(f\"📊 Final shapes - Train: {train_final.shape}, Val: {val_final.shape}\")\n",
        "    print(f\"🎯 Features added: {features_added}\")\n",
        "    print(f\"   - Holiday Features: 7\")\n",
        "    print(f\"   - Lag Features: 6\")\n",
        "    print(f\"📋 Total features: {final_features}\")\n",
        "\n",
        "    # Verify no data leakage (same number of records)\n",
        "    assert len(train_final) == len(train_data), f\"❌ Training data size changed! Expected {len(train_data)}, got {len(train_final)}\"\n",
        "    assert len(val_final) == len(val_data), f\"❌ Validation data size changed! Expected {len(val_data)}, got {len(val_final)}\"\n",
        "    print(\"✅ Data integrity verified - no record count changes\")\n",
        "\n",
        "    return train_final, val_final\n"
      ],
      "metadata": {
        "id": "doxa8bhJIaAu"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model_data(train_enhanced, val_enhanced):\n",
        "    \"\"\"\n",
        "    Prepare data for model training by properly separating features and target\n",
        "    Shows how validation Weekly_Sales is kept for testing only\n",
        "\n",
        "    Args:\n",
        "        train_enhanced: Enhanced training data with all features\n",
        "        val_enhanced: Enhanced validation data with all features\n",
        "\n",
        "    Returns:\n",
        "        X_train, y_train, X_val, y_val (properly separated)\n",
        "    \"\"\"\n",
        "    print(\"🎯 Preparing data for model training...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Define target and feature columns\n",
        "    target_col = 'Weekly_Sales'\n",
        "    exclude_cols = [target_col, 'Date']  # Exclude target and date\n",
        "    feature_cols = [col for col in train_enhanced.columns if col not in exclude_cols]\n",
        "\n",
        "    # Training data - we can use both features and target\n",
        "    X_train = train_enhanced[feature_cols].copy()\n",
        "    y_train = train_enhanced[target_col].copy()\n",
        "\n",
        "    # Validation data - features for prediction, target for evaluation\n",
        "    X_val = val_enhanced[feature_cols].copy()\n",
        "    y_val = val_enhanced[target_col].copy()  # This is ONLY for evaluation, not feature creation\n",
        "\n",
        "    print(f\"✅ Data preparation complete:\")\n",
        "    print(f\"   📊 Training features (X_train): {X_train.shape}\")\n",
        "    print(f\"   🎯 Training target (y_train): {y_train.shape}\")\n",
        "    print(f\"   📊 Validation features (X_val): {X_val.shape}\")\n",
        "    print(f\"   🎯 Validation target (y_val): {y_val.shape}\")\n",
        "    print(f\"   🔧 Feature columns: {len(feature_cols)}\")\n",
        "\n",
        "    # Show sample of lag features to verify no leakage\n",
        "    lag_cols = [col for col in feature_cols if 'lag_' in col]\n",
        "    if lag_cols:\n",
        "        print(f\"\\n🔒 Lag Features Verification (first 5 validation records):\")\n",
        "        print(f\"   Lag columns: {lag_cols}\")\n",
        "        print(\"   Sample validation lag values:\")\n",
        "        print(X_val[lag_cols].head())\n",
        "        print(f\"   🔍 Note: These lag values come from TRAINING data only!\")\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, feature_cols\n"
      ],
      "metadata": {
        "id": "3Gv8N-kmNRF4"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_feature_enhancement():\n",
        "    \"\"\"\n",
        "    Demonstration function showing how to enhance existing processed data\n",
        "    with Holiday Features and Lag Features (NO data leakage)\n",
        "    \"\"\"\n",
        "    print(\"🎬 DEMO: Enhancing existing processed data with additional features\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Step 1: Run the original pipeline to get processed data\n",
        "    print(\"📋 Step 1: Running original experiment_2_pipeline...\")\n",
        "    train_data, val_data, split_info = experiment_2_pipeline()\n",
        "\n",
        "    print(f\"\\n📊 Original processed data:\")\n",
        "    print(f\"   Train: {train_data.shape}\")\n",
        "    print(f\"   Val: {val_data.shape}\")\n",
        "    print(f\"   Features: {train_data.shape[1]}\")\n",
        "\n",
        "    # Step 2: Enhance with additional features\n",
        "    print(f\"\\n📋 Step 2: Enhancing with Holiday and Lag features...\")\n",
        "    train_enhanced, val_enhanced = enhance_with_additional_features(train_data, val_data)\n",
        "\n",
        "    print(f\"\\n🎯 ENHANCEMENT RESULTS:\")\n",
        "    print(f\"   Original features: {train_data.shape[1]}\")\n",
        "    print(f\"   Enhanced features: {train_enhanced.shape[1]}\")\n",
        "    print(f\"   Features added: {train_enhanced.shape[1] - train_data.shape[1]}\")\n",
        "\n",
        "    # Show sample of new features\n",
        "    new_feature_cols = [col for col in train_enhanced.columns if col not in train_data.columns]\n",
        "    print(f\"\\n✨ New features added: {new_feature_cols}\")\n",
        "\n",
        "    # Step 3: Prepare for model training (proper data separation)\n",
        "    print(f\"\\n📋 Step 3: Preparing data for model training...\")\n",
        "    X_train, y_train, X_val, y_val, feature_cols = prepare_model_data(train_enhanced, val_enhanced)\n",
        "\n",
        "    print(f\"\\n🔒 DATA LEAKAGE VERIFICATION:\")\n",
        "    print(f\"   ✅ Training target used for lag features: YES (appropriate)\")\n",
        "    print(f\"   ✅ Validation target used for lag features: NO (prevented data leakage)\")\n",
        "    print(f\"   ✅ Validation target available for evaluation: YES (kept separate)\")\n",
        "\n",
        "    print(f\"\\n📈 Sample of enhanced training data:\")\n",
        "    sample_cols = ['Store', 'Dept', 'Date', 'Weekly_Sales'] + new_feature_cols[:6]\n",
        "    available_cols = [col for col in sample_cols if col in train_enhanced.columns]\n",
        "    print(train_enhanced[available_cols].head())\n",
        "\n",
        "    return train_enhanced, val_enhanced, X_train, y_train, X_val, y_val, feature_cols\n"
      ],
      "metadata": {
        "id": "peohW_V_Iaxt"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_feature_enhancement()"
      ],
      "metadata": {
        "id": "oxHtT2-NIewe",
        "outputId": "9db517ed-0230-4cec-e8cd-614fe88d2722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 DEMO: Enhancing existing processed data with additional features\n",
            "======================================================================\n",
            "📋 Step 1: Running original experiment_2_pipeline...\n",
            "🚀 Starting Experiment 2 Pipeline with Train/Val Split\n",
            "============================================================\n",
            "🔧 Setting up MLflow and DagsHub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DagsHub initialized successfully!\n",
            "✅ Created new experiment: Experiment_6_Complete_Pipeline_20250703_121359\n",
            "✅ MLflow setup complete!\n",
            "🔗 Tracking URI: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow\n",
            "📊 Experiment: Experiment_6_Complete_Pipeline_20250703_121359\n",
            "🔗 MLflow Experiment URL: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/19\n",
            "🔗 MLflow Run URL: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/19/runs/a2fcf2ff8e844a0ca40932511569ed80\n",
            "\n",
            "📂 STEP 1: Loading and merging data...\n",
            "📂 Loading datasets...\n",
            "✅ Loaded - Train: (421570, 5), Stores: (45, 3), Features: (8190, 12)\n",
            "🔗 Merging datasets...\n",
            "📊 Merged dataset shape: (421570, 17)\n",
            "\n",
            "🧹 STEP 2: Cleaning merged data...\n",
            "🧹 Cleaning merged data...\n",
            "✅ Clean dataset shape: (421570, 16)\n",
            "\n",
            "✂️ STEP 3: Creating temporal train/validation split...\n",
            "✂️ Creating temporal train/validation split...\n",
            "📅 Split date: 2012-04-13 00:00:00\n",
            "🚂 Training: 335,761 records (79.6%)\n",
            "🔮 Validation: 85,809 records (20.4%)\n",
            "📊 Train date range: 2010-02-05 00:00:00 to 2012-04-06 00:00:00\n",
            "📊 Val date range: 2012-04-13 00:00:00 to 2012-10-26 00:00:00\n",
            "\n",
            "🔧 STEP 4: Feature engineering on TRAINING data...\n",
            "📅 Creating date features...\n",
            "✅ Created date features. New shape: (335761, 29)\n",
            "\n",
            "🔄 STEP 5: Applying same feature engineering to VALIDATION data...\n",
            "📅 Creating date features...\n",
            "✅ Created date features. New shape: (85809, 29)\n",
            "\n",
            "🗑️ STEP 6: Removing outliers from TRAINING data only...\n",
            "🗑️ Removing outliers with business-aware approach...\n",
            "🎯 Applying outlier thresholds to TRAINING data:\n",
            "   Store Type A: Normal>$180,000, Holiday>$500,000\n",
            "   Store Type B: Normal>$130,000, Holiday>$700,000\n",
            "   Store Type C: Normal>$100,000, Holiday>$120,000\n",
            "\n",
            "📊 TRAINING DATA OUTLIER REMOVAL RESULTS:\n",
            "   🗑️  Total outliers REMOVED: 308 (0.09%)\n",
            "   📍 Store Type A: 180 removed from 171,750 records (0.10%)\n",
            "   📍 Store Type B: 118 removed from 130,287 records (0.09%)\n",
            "   📍 Store Type C: 10 removed from 33,724 records (0.03%)\n",
            "   ✅ Clean training records: 335,453\n",
            "   🎯 This improves model training by removing extreme values\n",
            "\n",
            "🔍 STEP 6b: Analyzing outliers in VALIDATION data (keeping all)...\n",
            "🔍 Analyzing outliers in VALIDATION data (NOT removing)...\n",
            "\n",
            "📊 VALIDATION DATA OUTLIER ANALYSIS:\n",
            "   🔍 Total outliers FOUND: 31 (0.04%)\n",
            "   📍 Store Type A: 26 outliers in 43,728 records (0.06%)\n",
            "   📍 Store Type B: 0 outliers in 33,208 records (0.00%)\n",
            "   📍 Store Type C: 5 outliers in 8,873 records (0.06%)\n",
            "   ✅ KEEPING ALL 85,809 validation records (including outliers)\n",
            "   🎯 This tests model robustness on real-world data distribution\n",
            "   💡 Validation outliers help us understand model performance limits\n",
            "\n",
            "📈 OUTLIER PROCESSING SUMMARY:\n",
            "   🚂 Training: 308 outliers REMOVED (0.09%)\n",
            "   🔮 Validation: 31 outliers FOUND but KEPT (0.04%)\n",
            "   ⚖️  This ensures clean training while testing real-world robustness\n",
            "\n",
            "🗑️ STEP 7: Removing MarkDown features from both datasets...\n",
            "🗑️ Removing MarkDown features...\n",
            "MarkDown columns to remove:\n",
            "   - MarkDown1: 80.6% missing\n",
            "   - MarkDown2: 82.7% missing\n",
            "   - MarkDown3: 82.1% missing\n",
            "   - MarkDown4: 82.6% missing\n",
            "   - MarkDown5: 80.5% missing\n",
            "✅ Removed 5 MarkDown columns\n",
            "📊 Shape after removal: (335453, 24)\n",
            "🗑️ Removing MarkDown features...\n",
            "MarkDown columns to remove:\n",
            "   - MarkDown1: 0.5% missing\n",
            "   - MarkDown2: 38.1% missing\n",
            "   - MarkDown3: 10.3% missing\n",
            "   - MarkDown4: 10.8% missing\n",
            "   - MarkDown5: 0.0% missing\n",
            "✅ Removed 5 MarkDown columns\n",
            "📊 Shape after removal: (85809, 24)\n",
            "\n",
            "🔧 STEP 8: Removing redundant features from both datasets...\n",
            "🔧 Removing redundant features...\n",
            "🗑️ Features to remove:\n",
            "   - DaysFromStart\n",
            "   - WeekOfYear\n",
            "   - Quarter\n",
            "   - Year\n",
            "   - IsQuarterStart\n",
            "   - IsQuarterEnd\n",
            "   - Day\n",
            "✅ Removed 7 redundant features\n",
            "📊 Final shape: (335453, 17)\n",
            "🔧 Removing redundant features...\n",
            "🗑️ Features to remove:\n",
            "   - DaysFromStart\n",
            "   - WeekOfYear\n",
            "   - Quarter\n",
            "   - Year\n",
            "   - IsQuarterStart\n",
            "   - IsQuarterEnd\n",
            "   - Day\n",
            "✅ Removed 7 redundant features\n",
            "📊 Final shape: (85809, 17)\n",
            "\n",
            "🔀 STEP 9: One-hot encoding categorical features...\n",
            "🔀 Encoding categorical features...\n",
            "   📋 One-hot encoding 'Type' column...\n",
            "   🏪 Store types found: ['A', 'B', 'C']\n",
            "   ✅ Created 3 Type dummy columns: ['Type_A', 'Type_B', 'Type_C']\n",
            "   🗑️ Dropped original 'Type' column\n",
            "📊 Shape after encoding: (335453, 19)\n",
            "🔀 Encoding categorical features...\n",
            "   📋 One-hot encoding 'Type' column...\n",
            "   🏪 Store types found: ['A', 'B', 'C']\n",
            "   ✅ Created 3 Type dummy columns: ['Type_A', 'Type_B', 'Type_C']\n",
            "   🗑️ Dropped original 'Type' column\n",
            "📊 Shape after encoding: (85809, 19)\n",
            "\n",
            "🎯 EXPERIMENT 2 PIPELINE COMPLETED!\n",
            "============================================================\n",
            "📊 Training dataset: (335453, 19)\n",
            "📊 Validation dataset: (85809, 19)\n",
            "🔗 Final columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'IsHoliday', 'Month', 'DayOfWeek', 'IsWeekend', 'IsMonthStart', 'IsMonthEnd', 'WeeksFromStart', 'Type_A', 'Type_B', 'Type_C']\n",
            "🔀 Categorical features encoded: ['Type_A', 'Type_B', 'Type_C']\n",
            "\n",
            "🔍 KEY DIFFERENCES:\n",
            "   🚂 Training: Cleaned data (outliers removed) for better learning\n",
            "   🔮 Validation: Real-world data (outliers kept) for robustness testing\n",
            "   🎯 Target column 'Weekly_Sales' available in both datasets for supervised learning\n",
            "   🔀 Categorical 'Type' column one-hot encoded into 3 binary features\n",
            "✅ No data leakage - feature engineering fitted on training data only!\n",
            "🚀 Datasets ready for modeling!\n",
            "\n",
            "🔗 MLflow Links:\n",
            "   📊 Experiment: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/19\n",
            "   🏃 Current Run: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/19/runs/a2fcf2ff8e844a0ca40932511569ed80\n",
            "🏃 View run Experiment_2_Complete_Pipeline at: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/19/runs/a2fcf2ff8e844a0ca40932511569ed80\n",
            "🧪 View experiment at: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/19\n",
            "\n",
            "📊 Original processed data:\n",
            "   Train: (335453, 19)\n",
            "   Val: (85809, 19)\n",
            "   Features: 19\n",
            "\n",
            "📋 Step 2: Enhancing with Holiday and Lag features...\n",
            "🚀 Enhancing data with additional features...\n",
            "============================================================\n",
            "📊 Initial shapes - Train: (335453, 19), Val: (85809, 19)\n",
            "\n",
            "🎉 STEP 1: Adding Holiday Features...\n",
            "🎉 Creating holiday features...\n",
            "✅ Created 7 holiday features: ['IsSuperBowlWeek', 'IsLaborDayWeek', 'IsThanksgivingWeek', 'IsChristmasWeek', 'IsMajorHoliday', 'IsHolidayMonth', 'IsBackToSchool']\n",
            "🎉 Creating holiday features...\n",
            "✅ Created 7 holiday features: ['IsSuperBowlWeek', 'IsLaborDayWeek', 'IsThanksgivingWeek', 'IsChristmasWeek', 'IsMajorHoliday', 'IsHolidayMonth', 'IsBackToSchool']\n",
            "\n",
            "⏳ STEP 2: Adding Lag Features...\n",
            "🚂 Processing training data...\n",
            "⏳ Creating lag features...\n",
            "✅ Created 6 lag features: ['Weekly_Sales_lag_1', 'Weekly_Sales_lag_2', 'Weekly_Sales_lag_3', 'Weekly_Sales_lag_4', 'Weekly_Sales_lag_8', 'Weekly_Sales_lag_12']\n",
            "   Lag periods: [1, 2, 3, 4, 8, 12] weeks\n",
            "🔮 Processing validation data...\n",
            "⏳ Creating lag features...\n",
            "✅ Created 6 lag features: ['Weekly_Sales_lag_1', 'Weekly_Sales_lag_2', 'Weekly_Sales_lag_3', 'Weekly_Sales_lag_4', 'Weekly_Sales_lag_8', 'Weekly_Sales_lag_12']\n",
            "   Lag periods: [1, 2, 3, 4, 8, 12] weeks\n",
            "\n",
            "🔄 STEP 3: Ensuring column consistency...\n",
            "\n",
            "✅ ENHANCEMENT COMPLETE!\n",
            "📊 Final shapes - Train: (335453, 32), Val: (85809, 32)\n",
            "🎯 Features added: 13\n",
            "   - Holiday Features: 7\n",
            "   - Lag Features: 6\n",
            "📋 Total features: 32\n",
            "✅ Data integrity verified - no record count changes\n",
            "\n",
            "🎯 ENHANCEMENT RESULTS:\n",
            "   Original features: 19\n",
            "   Enhanced features: 32\n",
            "   Features added: 13\n",
            "\n",
            "✨ New features added: ['IsSuperBowlWeek', 'IsLaborDayWeek', 'IsMajorHoliday', 'Weekly_Sales_lag_2', 'Weekly_Sales_lag_8', 'Weekly_Sales_lag_4', 'IsChristmasWeek', 'IsBackToSchool', 'Weekly_Sales_lag_3', 'IsHolidayMonth', 'IsThanksgivingWeek', 'Weekly_Sales_lag_1', 'Weekly_Sales_lag_12']\n",
            "\n",
            "📋 Step 3: Preparing data for model training...\n",
            "🎯 Preparing data for model training...\n",
            "==================================================\n",
            "✅ Data preparation complete:\n",
            "   📊 Training features (X_train): (335453, 30)\n",
            "   🎯 Training target (y_train): (335453,)\n",
            "   📊 Validation features (X_val): (85809, 30)\n",
            "   🎯 Validation target (y_val): (85809,)\n",
            "   🔧 Feature columns: 30\n",
            "\n",
            "🔒 Lag Features Verification (first 5 validation records):\n",
            "   Lag columns: ['Weekly_Sales_lag_2', 'Weekly_Sales_lag_8', 'Weekly_Sales_lag_4', 'Weekly_Sales_lag_3', 'Weekly_Sales_lag_1', 'Weekly_Sales_lag_12']\n",
            "   Sample validation lag values:\n",
            "   Weekly_Sales_lag_2  Weekly_Sales_lag_8  Weekly_Sales_lag_4  \\\n",
            "0                0.00                 0.0                0.00   \n",
            "1                0.00                 0.0                0.00   \n",
            "2            34684.21                 0.0                0.00   \n",
            "3            16976.19                 0.0                0.00   \n",
            "4            16347.60                 0.0            34684.21   \n",
            "\n",
            "   Weekly_Sales_lag_3  Weekly_Sales_lag_1  Weekly_Sales_lag_12  \n",
            "0                0.00                0.00                  0.0  \n",
            "1                0.00            34684.21                  0.0  \n",
            "2                0.00            16976.19                  0.0  \n",
            "3            34684.21            16347.60                  0.0  \n",
            "4            16976.19            17147.44                  0.0  \n",
            "   🔍 Note: These lag values come from TRAINING data only!\n",
            "\n",
            "🔒 DATA LEAKAGE VERIFICATION:\n",
            "   ✅ Training target used for lag features: YES (appropriate)\n",
            "   ✅ Validation target used for lag features: NO (prevented data leakage)\n",
            "   ✅ Validation target available for evaluation: YES (kept separate)\n",
            "\n",
            "📈 Sample of enhanced training data:\n",
            "   Store  Dept       Date  Weekly_Sales  IsSuperBowlWeek  IsLaborDayWeek  \\\n",
            "0      1     1 2010-02-05      24924.50                0               0   \n",
            "1      1     1 2010-02-12      46039.49                1               0   \n",
            "2      1     1 2010-02-19      41595.55                0               0   \n",
            "3      1     1 2010-02-26      19403.54                0               0   \n",
            "4      1     1 2010-03-05      21827.90                0               0   \n",
            "\n",
            "   IsMajorHoliday  Weekly_Sales_lag_2  Weekly_Sales_lag_8  Weekly_Sales_lag_4  \n",
            "0               0                0.00                 0.0                 0.0  \n",
            "1               1                0.00                 0.0                 0.0  \n",
            "2               0            24924.50                 0.0                 0.0  \n",
            "3               0            46039.49                 0.0                 0.0  \n",
            "4               0            41595.55                 0.0             24924.5  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(        Weekly_Sales  IsSuperBowlWeek  Temperature  IsLaborDayWeek  \\\n",
              " 0           24924.50                0        42.31               0   \n",
              " 1           46039.49                1        38.51               0   \n",
              " 2           41595.55                0        39.93               0   \n",
              " 3           19403.54                0        46.63               0   \n",
              " 4           21827.90                0        46.50               0   \n",
              " ...              ...              ...          ...             ...   \n",
              " 335448        871.34                0        45.52               0   \n",
              " 335449        747.50                0        50.56               0   \n",
              " 335450        550.98                0        59.45               0   \n",
              " 335451        763.60                0        50.04               0   \n",
              " 335452        778.70                0        49.73               0   \n",
              " \n",
              "         WeeksFromStart  Dept  IsMajorHoliday  Weekly_Sales_lag_2  \\\n",
              " 0                    0     1               0                0.00   \n",
              " 1                    1     1               1                0.00   \n",
              " 2                    2     1               0            24924.50   \n",
              " 3                    3     1               0            46039.49   \n",
              " 4                    4     1               0            41595.55   \n",
              " ...                ...   ...             ...                 ...   \n",
              " 335448             109    98               0              544.34   \n",
              " 335449             110    98               0              654.52   \n",
              " 335450             111    98               0              871.34   \n",
              " 335451             112    98               0              747.50   \n",
              " 335452             113    98               0              550.98   \n",
              " \n",
              "         Weekly_Sales_lag_8  Type_B  ...  IsThanksgivingWeek Unemployment  \\\n",
              " 0                     0.00   False  ...                   0        8.106   \n",
              " 1                     0.00   False  ...                   0        8.106   \n",
              " 2                     0.00   False  ...                   0        8.106   \n",
              " 3                     0.00   False  ...                   0        8.106   \n",
              " 4                     0.00   False  ...                   0        8.106   \n",
              " ...                    ...     ...  ...                 ...          ...   \n",
              " 335448              677.71    True  ...                   0        8.424   \n",
              " 335449              848.84    True  ...                   0        8.424   \n",
              " 335450              671.40    True  ...                   0        8.424   \n",
              " 335451              772.51    True  ...                   0        8.424   \n",
              " 335452              770.86    True  ...                   0        8.567   \n",
              " \n",
              "         IsHoliday  Fuel_Price         CPI    Size  Weekly_Sales_lag_1  \\\n",
              " 0           False       2.572  211.096358  151315                0.00   \n",
              " 1            True       2.548  211.242170  151315            24924.50   \n",
              " 2           False       2.514  211.289143  151315            46039.49   \n",
              " 3           False       2.561  211.319643  151315            41595.55   \n",
              " 4           False       2.625  211.350143  151315            19403.54   \n",
              " ...           ...         ...         ...     ...                 ...   \n",
              " 335448      False       3.848  190.335997  118221              654.52   \n",
              " 335449      False       3.862  190.461896  118221              871.34   \n",
              " 335450      False       3.900  190.536321  118221              747.50   \n",
              " 335451      False       3.953  190.610746  118221              550.98   \n",
              " 335452      False       3.996  190.685171  118221              763.60   \n",
              " \n",
              "         DayOfWeek  Weekly_Sales_lag_12  IsMonthStart  \n",
              " 0               4                 0.00             0  \n",
              " 1               4                 0.00             0  \n",
              " 2               4                 0.00             0  \n",
              " 3               4                 0.00             0  \n",
              " 4               4                 0.00             0  \n",
              " ...           ...                  ...           ...  \n",
              " 335448          4               853.46             0  \n",
              " 335449          4              1084.78             0  \n",
              " 335450          4               553.21             0  \n",
              " 335451          4               698.76             0  \n",
              " 335452          4               677.71             0  \n",
              " \n",
              " [335453 rows x 32 columns],\n",
              "        Weekly_Sales  IsSuperBowlWeek  Temperature  IsLaborDayWeek  \\\n",
              " 0          34684.21                0        69.07               0   \n",
              " 1          16976.19                0        66.76               0   \n",
              " 2          16347.60                0        67.23               0   \n",
              " 3          17147.44                0        75.55               0   \n",
              " 4          18164.20                0        73.77               0   \n",
              " ...             ...              ...          ...             ...   \n",
              " 85804        508.37                0        64.88               0   \n",
              " 85805        628.10                0        64.89               0   \n",
              " 85806       1061.02                0        54.47               0   \n",
              " 85807        760.01                0        56.47               0   \n",
              " 85808       1076.80                0        58.85               0   \n",
              " \n",
              "        WeeksFromStart  Dept  IsMajorHoliday  Weekly_Sales_lag_2  \\\n",
              " 0                   0     1               0                0.00   \n",
              " 1                   1     1               0                0.00   \n",
              " 2                   2     1               0            34684.21   \n",
              " 3                   3     1               0            16976.19   \n",
              " 4                   4     1               0            16347.60   \n",
              " ...               ...   ...             ...                 ...   \n",
              " 85804              24    98               0              605.96   \n",
              " 85805              25    98               0              467.30   \n",
              " 85806              26    98               0              508.37   \n",
              " 85807              27    98               0              628.10   \n",
              " 85808              28    98               0             1061.02   \n",
              " \n",
              "        Weekly_Sales_lag_8  Type_B  ...  IsThanksgivingWeek Unemployment  \\\n",
              " 0                    0.00   False  ...                   0        7.143   \n",
              " 1                    0.00   False  ...                   0        7.143   \n",
              " 2                    0.00   False  ...                   0        7.143   \n",
              " 3                    0.00   False  ...                   0        7.143   \n",
              " 4                    0.00   False  ...                   0        7.143   \n",
              " ...                   ...     ...  ...                 ...          ...   \n",
              " 85804              516.46    True  ...                   0        8.684   \n",
              " 85805              727.49    True  ...                   0        8.667   \n",
              " 85806              500.16    True  ...                   0        8.667   \n",
              " 85807              415.40    True  ...                   0        8.667   \n",
              " 85808              346.04    True  ...                   0        8.667   \n",
              " \n",
              "        IsHoliday  Fuel_Price         CPI    Size  Weekly_Sales_lag_1  \\\n",
              " 0          False       3.891  221.510210  151315                0.00   \n",
              " 1          False       3.877  221.564074  151315            34684.21   \n",
              " 2          False       3.814  221.617937  151315            16976.19   \n",
              " 3          False       3.749  221.671800  151315            16347.60   \n",
              " 4          False       3.688  221.725663  151315            17147.44   \n",
              " ...          ...         ...         ...     ...                 ...   \n",
              " 85804      False       3.997  192.013558  118221              467.30   \n",
              " 85805      False       3.985  192.170412  118221              508.37   \n",
              " 85806      False       4.000  192.327265  118221              628.10   \n",
              " 85807      False       3.969  192.330854  118221             1061.02   \n",
              " 85808      False       3.882  192.308899  118221              760.01   \n",
              " \n",
              "        DayOfWeek  Weekly_Sales_lag_12  IsMonthStart  \n",
              " 0              4                 0.00             0  \n",
              " 1              4                 0.00             0  \n",
              " 2              4                 0.00             0  \n",
              " 3              4                 0.00             0  \n",
              " 4              4                 0.00             0  \n",
              " ...          ...                  ...           ...  \n",
              " 85804          4               659.65             0  \n",
              " 85805          4               695.21             0  \n",
              " 85806          4               845.30             0  \n",
              " 85807          4               657.63             0  \n",
              " 85808          4               516.46             0  \n",
              " \n",
              " [85809 rows x 32 columns],\n",
              "         IsSuperBowlWeek  Temperature  IsLaborDayWeek  WeeksFromStart  Dept  \\\n",
              " 0                     0        42.31               0               0     1   \n",
              " 1                     1        38.51               0               1     1   \n",
              " 2                     0        39.93               0               2     1   \n",
              " 3                     0        46.63               0               3     1   \n",
              " 4                     0        46.50               0               4     1   \n",
              " ...                 ...          ...             ...             ...   ...   \n",
              " 335448                0        45.52               0             109    98   \n",
              " 335449                0        50.56               0             110    98   \n",
              " 335450                0        59.45               0             111    98   \n",
              " 335451                0        50.04               0             112    98   \n",
              " 335452                0        49.73               0             113    98   \n",
              " \n",
              "         IsMajorHoliday  Weekly_Sales_lag_2  Weekly_Sales_lag_8  Type_B  \\\n",
              " 0                    0                0.00                0.00   False   \n",
              " 1                    1                0.00                0.00   False   \n",
              " 2                    0            24924.50                0.00   False   \n",
              " 3                    0            46039.49                0.00   False   \n",
              " 4                    0            41595.55                0.00   False   \n",
              " ...                ...                 ...                 ...     ...   \n",
              " 335448               0              544.34              677.71    True   \n",
              " 335449               0              654.52              848.84    True   \n",
              " 335450               0              871.34              671.40    True   \n",
              " 335451               0              747.50              772.51    True   \n",
              " 335452               0              550.98              770.86    True   \n",
              " \n",
              "         Weekly_Sales_lag_4  ...  IsThanksgivingWeek  Unemployment  IsHoliday  \\\n",
              " 0                     0.00  ...                   0         8.106      False   \n",
              " 1                     0.00  ...                   0         8.106       True   \n",
              " 2                     0.00  ...                   0         8.106      False   \n",
              " 3                     0.00  ...                   0         8.106      False   \n",
              " 4                 24924.50  ...                   0         8.106      False   \n",
              " ...                    ...  ...                 ...           ...        ...   \n",
              " 335448              770.86  ...                   0         8.424      False   \n",
              " 335449              889.98  ...                   0         8.424      False   \n",
              " 335450              544.34  ...                   0         8.424      False   \n",
              " 335451              654.52  ...                   0         8.424      False   \n",
              " 335452              871.34  ...                   0         8.567      False   \n",
              " \n",
              "         Fuel_Price         CPI    Size  Weekly_Sales_lag_1  DayOfWeek  \\\n",
              " 0            2.572  211.096358  151315                0.00          4   \n",
              " 1            2.548  211.242170  151315            24924.50          4   \n",
              " 2            2.514  211.289143  151315            46039.49          4   \n",
              " 3            2.561  211.319643  151315            41595.55          4   \n",
              " 4            2.625  211.350143  151315            19403.54          4   \n",
              " ...            ...         ...     ...                 ...        ...   \n",
              " 335448       3.848  190.335997  118221              654.52          4   \n",
              " 335449       3.862  190.461896  118221              871.34          4   \n",
              " 335450       3.900  190.536321  118221              747.50          4   \n",
              " 335451       3.953  190.610746  118221              550.98          4   \n",
              " 335452       3.996  190.685171  118221              763.60          4   \n",
              " \n",
              "         Weekly_Sales_lag_12  IsMonthStart  \n",
              " 0                      0.00             0  \n",
              " 1                      0.00             0  \n",
              " 2                      0.00             0  \n",
              " 3                      0.00             0  \n",
              " 4                      0.00             0  \n",
              " ...                     ...           ...  \n",
              " 335448               853.46             0  \n",
              " 335449              1084.78             0  \n",
              " 335450               553.21             0  \n",
              " 335451               698.76             0  \n",
              " 335452               677.71             0  \n",
              " \n",
              " [335453 rows x 30 columns],\n",
              " 0         24924.50\n",
              " 1         46039.49\n",
              " 2         41595.55\n",
              " 3         19403.54\n",
              " 4         21827.90\n",
              "             ...   \n",
              " 335448      871.34\n",
              " 335449      747.50\n",
              " 335450      550.98\n",
              " 335451      763.60\n",
              " 335452      778.70\n",
              " Name: Weekly_Sales, Length: 335453, dtype: float64,\n",
              "        IsSuperBowlWeek  Temperature  IsLaborDayWeek  WeeksFromStart  Dept  \\\n",
              " 0                    0        69.07               0               0     1   \n",
              " 1                    0        66.76               0               1     1   \n",
              " 2                    0        67.23               0               2     1   \n",
              " 3                    0        75.55               0               3     1   \n",
              " 4                    0        73.77               0               4     1   \n",
              " ...                ...          ...             ...             ...   ...   \n",
              " 85804                0        64.88               0              24    98   \n",
              " 85805                0        64.89               0              25    98   \n",
              " 85806                0        54.47               0              26    98   \n",
              " 85807                0        56.47               0              27    98   \n",
              " 85808                0        58.85               0              28    98   \n",
              " \n",
              "        IsMajorHoliday  Weekly_Sales_lag_2  Weekly_Sales_lag_8  Type_B  \\\n",
              " 0                   0                0.00                0.00   False   \n",
              " 1                   0                0.00                0.00   False   \n",
              " 2                   0            34684.21                0.00   False   \n",
              " 3                   0            16976.19                0.00   False   \n",
              " 4                   0            16347.60                0.00   False   \n",
              " ...               ...                 ...                 ...     ...   \n",
              " 85804               0              605.96              516.46    True   \n",
              " 85805               0              467.30              727.49    True   \n",
              " 85806               0              508.37              500.16    True   \n",
              " 85807               0              628.10              415.40    True   \n",
              " 85808               0             1061.02              346.04    True   \n",
              " \n",
              "        Weekly_Sales_lag_4  ...  IsThanksgivingWeek  Unemployment  IsHoliday  \\\n",
              " 0                    0.00  ...                   0         7.143      False   \n",
              " 1                    0.00  ...                   0         7.143      False   \n",
              " 2                    0.00  ...                   0         7.143      False   \n",
              " 3                    0.00  ...                   0         7.143      False   \n",
              " 4                34684.21  ...                   0         7.143      False   \n",
              " ...                   ...  ...                 ...           ...        ...   \n",
              " 85804              346.04  ...                   0         8.684      False   \n",
              " 85805              352.44  ...                   0         8.667      False   \n",
              " 85806              605.96  ...                   0         8.667      False   \n",
              " 85807              467.30  ...                   0         8.667      False   \n",
              " 85808              508.37  ...                   0         8.667      False   \n",
              " \n",
              "        Fuel_Price         CPI    Size  Weekly_Sales_lag_1  DayOfWeek  \\\n",
              " 0           3.891  221.510210  151315                0.00          4   \n",
              " 1           3.877  221.564074  151315            34684.21          4   \n",
              " 2           3.814  221.617937  151315            16976.19          4   \n",
              " 3           3.749  221.671800  151315            16347.60          4   \n",
              " 4           3.688  221.725663  151315            17147.44          4   \n",
              " ...           ...         ...     ...                 ...        ...   \n",
              " 85804       3.997  192.013558  118221              467.30          4   \n",
              " 85805       3.985  192.170412  118221              508.37          4   \n",
              " 85806       4.000  192.327265  118221              628.10          4   \n",
              " 85807       3.969  192.330854  118221             1061.02          4   \n",
              " 85808       3.882  192.308899  118221              760.01          4   \n",
              " \n",
              "        Weekly_Sales_lag_12  IsMonthStart  \n",
              " 0                     0.00             0  \n",
              " 1                     0.00             0  \n",
              " 2                     0.00             0  \n",
              " 3                     0.00             0  \n",
              " 4                     0.00             0  \n",
              " ...                    ...           ...  \n",
              " 85804               659.65             0  \n",
              " 85805               695.21             0  \n",
              " 85806               845.30             0  \n",
              " 85807               657.63             0  \n",
              " 85808               516.46             0  \n",
              " \n",
              " [85809 rows x 30 columns],\n",
              " 0        34684.21\n",
              " 1        16976.19\n",
              " 2        16347.60\n",
              " 3        17147.44\n",
              " 4        18164.20\n",
              "            ...   \n",
              " 85804      508.37\n",
              " 85805      628.10\n",
              " 85806     1061.02\n",
              " 85807      760.01\n",
              " 85808     1076.80\n",
              " Name: Weekly_Sales, Length: 85809, dtype: float64,\n",
              " ['IsSuperBowlWeek',\n",
              "  'Temperature',\n",
              "  'IsLaborDayWeek',\n",
              "  'WeeksFromStart',\n",
              "  'Dept',\n",
              "  'IsMajorHoliday',\n",
              "  'Weekly_Sales_lag_2',\n",
              "  'Weekly_Sales_lag_8',\n",
              "  'Type_B',\n",
              "  'Weekly_Sales_lag_4',\n",
              "  'IsChristmasWeek',\n",
              "  'Type_A',\n",
              "  'IsMonthEnd',\n",
              "  'IsWeekend',\n",
              "  'Type_C',\n",
              "  'IsBackToSchool',\n",
              "  'Month',\n",
              "  'Weekly_Sales_lag_3',\n",
              "  'Store',\n",
              "  'IsHolidayMonth',\n",
              "  'IsThanksgivingWeek',\n",
              "  'Unemployment',\n",
              "  'IsHoliday',\n",
              "  'Fuel_Price',\n",
              "  'CPI',\n",
              "  'Size',\n",
              "  'Weekly_Sales_lag_1',\n",
              "  'DayOfWeek',\n",
              "  'Weekly_Sales_lag_12',\n",
              "  'IsMonthStart'])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(5)"
      ],
      "metadata": {
        "id": "6wc1EI7IIwjN",
        "outputId": "35de46d9-9cad-4c8a-e9f2-906dfa0db676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_enhanced' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-66-2137544572.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_enhanced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_enhanced' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data.head(5)"
      ],
      "metadata": {
        "id": "Q2wQjbpyI75e",
        "outputId": "c48aa150-774b-4912-feed-0ebb200c6dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Store  Dept       Date  Weekly_Sales    Size  Temperature  Fuel_Price  \\\n",
              "210312     22    24 2012-04-13       6744.61  119557        49.89       4.025   \n",
              "165607     17    81 2012-04-13       9920.86   93188        46.94       3.833   \n",
              "409905     44    80 2012-04-13       5035.59   39910        51.70       3.833   \n",
              "202057     21    33 2012-04-13       7486.67  140167        69.03       3.891   \n",
              "371927     40     7 2012-04-13      16465.22  155083        40.65       4.025   \n",
              "\n",
              "               CPI  Unemployment  IsHoliday  Month  DayOfWeek  IsWeekend  \\\n",
              "210312  141.843393         7.671      False      4          4          0   \n",
              "165607  131.108000         6.235      False      4          4          0   \n",
              "409905  131.108000         5.621      False      4          4          0   \n",
              "202057  221.148403         6.891      False      4          4          0   \n",
              "371927  137.868000         4.125      False      4          4          0   \n",
              "\n",
              "        IsMonthStart  IsMonthEnd  WeeksFromStart  Type_A  Type_B  Type_C  \n",
              "210312             0           0               0   False    True   False  \n",
              "165607             0           0               0   False    True   False  \n",
              "409905             0           0               0   False   False    True  \n",
              "202057             0           0               0   False    True   False  \n",
              "371927             0           0               0    True   False   False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a42f226e-9ce8-4246-ad0b-8c8d98c3947e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>IsWeekend</th>\n",
              "      <th>IsMonthStart</th>\n",
              "      <th>IsMonthEnd</th>\n",
              "      <th>WeeksFromStart</th>\n",
              "      <th>Type_A</th>\n",
              "      <th>Type_B</th>\n",
              "      <th>Type_C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>210312</th>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>2012-04-13</td>\n",
              "      <td>6744.61</td>\n",
              "      <td>119557</td>\n",
              "      <td>49.89</td>\n",
              "      <td>4.025</td>\n",
              "      <td>141.843393</td>\n",
              "      <td>7.671</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165607</th>\n",
              "      <td>17</td>\n",
              "      <td>81</td>\n",
              "      <td>2012-04-13</td>\n",
              "      <td>9920.86</td>\n",
              "      <td>93188</td>\n",
              "      <td>46.94</td>\n",
              "      <td>3.833</td>\n",
              "      <td>131.108000</td>\n",
              "      <td>6.235</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409905</th>\n",
              "      <td>44</td>\n",
              "      <td>80</td>\n",
              "      <td>2012-04-13</td>\n",
              "      <td>5035.59</td>\n",
              "      <td>39910</td>\n",
              "      <td>51.70</td>\n",
              "      <td>3.833</td>\n",
              "      <td>131.108000</td>\n",
              "      <td>5.621</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202057</th>\n",
              "      <td>21</td>\n",
              "      <td>33</td>\n",
              "      <td>2012-04-13</td>\n",
              "      <td>7486.67</td>\n",
              "      <td>140167</td>\n",
              "      <td>69.03</td>\n",
              "      <td>3.891</td>\n",
              "      <td>221.148403</td>\n",
              "      <td>6.891</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371927</th>\n",
              "      <td>40</td>\n",
              "      <td>7</td>\n",
              "      <td>2012-04-13</td>\n",
              "      <td>16465.22</td>\n",
              "      <td>155083</td>\n",
              "      <td>40.65</td>\n",
              "      <td>4.025</td>\n",
              "      <td>137.868000</td>\n",
              "      <td>4.125</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a42f226e-9ce8-4246-ad0b-8c8d98c3947e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a42f226e-9ce8-4246-ad0b-8c8d98c3947e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a42f226e-9ce8-4246-ad0b-8c8d98c3947e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-821ba594-261b-4092-b145-60df7e31f8b2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-821ba594-261b-4092-b145-60df7e31f8b2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-821ba594-261b-4092-b145-60df7e31f8b2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val_data",
              "summary": "{\n  \"name\": \"val_data\",\n  \"rows\": 85809,\n  \"fields\": [\n    {\n      \"column\": \"Store\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 45,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          28,\n          39,\n          38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dept\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 1,\n        \"max\": 99,\n        \"num_unique_values\": 81,\n        \"samples\": [\n          95,\n          24,\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2012-04-13 00:00:00\",\n        \"max\": \"2012-10-26 00:00:00\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"2012-10-19 00:00:00\",\n          \"2012-08-03 00:00:00\",\n          \"2012-07-06 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weekly_Sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21958.215941597453,\n        \"min\": -771.9,\n        \"max\": 206575.9,\n        \"num_unique_values\": 79734,\n        \"samples\": [\n          16243.22,\n          14873.1,\n          3595.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 61141,\n        \"min\": 34875,\n        \"max\": 219622,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          155078,\n          202307,\n          196321\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.869998880547733,\n        \"min\": 36.9,\n        \"max\": 100.07,\n        \"num_unique_values\": 897,\n        \"samples\": [\n          84.97,\n          77.9,\n          66.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fuel_Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24857822731087775,\n        \"min\": 3.187,\n        \"max\": 4.468,\n        \"num_unique_values\": 229,\n        \"samples\": [\n          3.75,\n          3.551,\n          4.027\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CPI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.57609093077529,\n        \"min\": 130.683,\n        \"max\": 227.2328068,\n        \"num_unique_values\": 435,\n        \"samples\": [\n          223.6510224,\n          221.380331,\n          191.0091712\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unemployment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6817751877419933,\n        \"min\": 3.879,\n        \"max\": 11.627,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          7.992,\n          7.671,\n          7.139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsHoliday\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Month\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DayOfWeek\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsWeekend\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsMonthStart\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsMonthEnd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WeeksFromStart\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 28,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type_A\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type_B\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type_C\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WalmartPreprocessingPipeline:\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline for Walmart sales data\n",
        "    Supports fit/transform pattern for proper train/validation handling\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.fitted = False\n",
        "        self.outlier_thresholds = None\n",
        "        self.feature_columns = None\n",
        "\n",
        "    def load_and_prepare_data(self):\n",
        "        \"\"\"Load and merge train.csv, stores.csv, features.csv datasets\"\"\"\n",
        "        print(\"📊 Loading datasets...\")\n",
        "\n",
        "        # Load datasets\n",
        "        train_df = pd.read_csv('train.csv')\n",
        "        stores_df = pd.read_csv('stores.csv')\n",
        "        features_df = pd.read_csv('features.csv')\n",
        "\n",
        "        print(f\"   📈 Train data: {train_df.shape}\")\n",
        "        print(f\"   🏪 Stores data: {stores_df.shape}\")\n",
        "        print(f\"   🎯 Features data: {features_df.shape}\")\n",
        "\n",
        "        # Convert Date column to datetime\n",
        "        train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
        "        features_df['Date'] = pd.to_datetime(features_df['Date'])\n",
        "\n",
        "        # Merge datasets\n",
        "        train_stores = train_df.merge(stores_df, on='Store', how='left')\n",
        "        train_full = train_stores.merge(features_df, on=['Store', 'Date'], how='left')\n",
        "\n",
        "        print(f\"   ✅ Merged data: {train_full.shape}\")\n",
        "        print(f\"   📅 Date range: {train_full['Date'].min()} to {train_full['Date'].max()}\")\n",
        "\n",
        "        return train_full\n",
        "\n",
        "    def clean_merged_data(self, train_full):\n",
        "        \"\"\"Clean merged data by handling duplicate IsHoliday columns\"\"\"\n",
        "        print(\"🧹 Cleaning merged data...\")\n",
        "\n",
        "        initial_shape = train_full.shape\n",
        "\n",
        "        # Handle duplicate IsHoliday columns if they exist\n",
        "        if 'IsHoliday_x' in train_full.columns and 'IsHoliday_y' in train_full.columns:\n",
        "            print(\"   🔄 Resolving duplicate IsHoliday columns...\")\n",
        "            train_full['IsHoliday'] = train_full['IsHoliday_x'] | train_full['IsHoliday_y']\n",
        "            train_full = train_full.drop(['IsHoliday_x', 'IsHoliday_y'], axis=1)\n",
        "\n",
        "        print(f\"   ✅ Cleaned data: {train_full.shape} (was {initial_shape})\")\n",
        "        return train_full\n",
        "\n",
        "    def create_temporal_split(self, df, train_ratio=0.8):\n",
        "        \"\"\"Create temporal split to prevent data leakage\"\"\"\n",
        "        print(f\"📅 Creating temporal split ({int(train_ratio*100)}/{int((1-train_ratio)*100)})...\")\n",
        "\n",
        "        # Sort by date to ensure temporal order\n",
        "        df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "        # Find split point\n",
        "        split_idx = int(len(df_sorted) * train_ratio)\n",
        "        split_date = df_sorted.iloc[split_idx]['Date']\n",
        "\n",
        "        # Create splits\n",
        "        train_data = df_sorted.iloc[:split_idx].copy()\n",
        "        val_data = df_sorted.iloc[split_idx:].copy()\n",
        "\n",
        "        # Create split info dictionary\n",
        "        split_info = {\n",
        "            'split_date': split_date,\n",
        "            'train_size': len(train_data),\n",
        "            'val_size': len(val_data),\n",
        "            'train_date_range': (train_data['Date'].min(), train_data['Date'].max()),\n",
        "            'val_date_range': (val_data['Date'].min(), val_data['Date'].max())\n",
        "        }\n",
        "\n",
        "        print(f\"   📊 Split date: {split_date}\")\n",
        "        print(f\"   📈 Train: {len(train_data):,} records ({train_data['Date'].min()} to {train_data['Date'].max()})\")\n",
        "        print(f\"   📉 Val: {len(val_data):,} records ({val_data['Date'].min()} to {val_data['Date'].max()})\")\n",
        "\n",
        "        return train_data, val_data, split_info\n",
        "\n",
        "    def fit(self, train_data):\n",
        "        \"\"\"\n",
        "        Fit the preprocessing pipeline on training data\n",
        "\n",
        "        Args:\n",
        "            train_data: Training dataset with Weekly_Sales target\n",
        "        \"\"\"\n",
        "        print(\"🔧 Fitting preprocessing pipeline on training data...\")\n",
        "\n",
        "        # Store training data for lag feature creation\n",
        "        self.train_data_for_lags = train_data.copy()\n",
        "\n",
        "        # Fit outlier removal thresholds on training data only\n",
        "        self.outlier_thresholds = {\n",
        "            'A': {'lower': -1000, 'upper': 50000},  # Type A stores\n",
        "            'B': {'lower': -500, 'upper': 25000},   # Type B stores\n",
        "            'C': {'lower': -200, 'upper': 15000}    # Type C stores\n",
        "        }\n",
        "\n",
        "        print(\"✅ Pipeline fitted on training data\")\n",
        "        self.fitted = True\n",
        "        return self\n",
        "\n",
        "    def transform(self, data, is_validation=False):\n",
        "        \"\"\"\n",
        "        Transform data using fitted pipeline\n",
        "\n",
        "        Args:\n",
        "            data: Dataset to transform\n",
        "            is_validation: If True, removes Weekly_Sales before lag feature creation\n",
        "        \"\"\"\n",
        "        if not self.fitted:\n",
        "            raise ValueError(\"Pipeline must be fitted before transform!\")\n",
        "\n",
        "        print(f\"🔄 Transforming {'validation' if is_validation else 'training'} data...\")\n",
        "\n",
        "        df = data.copy()\n",
        "\n",
        "        # Step 1: Create date features\n",
        "        df = self._create_date_features(df)\n",
        "\n",
        "        # Step 2: Create holiday features\n",
        "        df = self._create_holiday_features(df)\n",
        "\n",
        "        # Step 3: Encode categorical features (BEFORE outlier removal!)\n",
        "        df = self._encode_categorical_features(df)\n",
        "\n",
        "        # Step 4: Create lag features (different for train vs validation)\n",
        "        if is_validation:\n",
        "            df = self._create_lag_features_validation(df)\n",
        "        else:\n",
        "            df = self._create_lag_features_training(df)\n",
        "\n",
        "        # Step 5: Remove outliers (only on training data, AFTER encoding)\n",
        "        if not is_validation:\n",
        "            df = self._remove_outliers(df)\n",
        "\n",
        "        # Step 6: Remove markdown features\n",
        "        df = self._remove_markdown_features(df)\n",
        "\n",
        "        # Step 7: Remove redundant features\n",
        "        df = self._remove_redundant_features(df)\n",
        "\n",
        "        print(f\"✅ Transform complete. Shape: {df.shape}\")\n",
        "        return df\n",
        "\n",
        "    def fit_transform(self, train_data):\n",
        "        \"\"\"Fit and transform training data in one step\"\"\"\n",
        "        return self.fit(train_data).transform(train_data, is_validation=False)\n",
        "\n",
        "    def _create_date_features(self, df):\n",
        "        \"\"\"Create date features\"\"\"\n",
        "        df = df.copy()\n",
        "        df['Year'] = df['Date'].dt.year\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "        df['Day'] = df['Date'].dt.day\n",
        "        df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "        df['WeekOfYear'] = df['Date'].dt.isocalendar().week\n",
        "        df['Quarter'] = df['Date'].dt.quarter\n",
        "        df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)\n",
        "        df['IsMonthStart'] = df['Date'].dt.is_month_start.astype(int)\n",
        "        df['IsMonthEnd'] = df['Date'].dt.is_month_end.astype(int)\n",
        "        df['IsQuarterStart'] = df['Date'].dt.is_quarter_start.astype(int)\n",
        "        df['IsQuarterEnd'] = df['Date'].dt.is_quarter_end.astype(int)\n",
        "        start_date = df['Date'].min()\n",
        "        df['DaysFromStart'] = (df['Date'] - start_date).dt.days\n",
        "        df['WeeksFromStart'] = df['DaysFromStart'] // 7\n",
        "        return df\n",
        "\n",
        "    def _create_holiday_features(self, df):\n",
        "        \"\"\"Create holiday features\"\"\"\n",
        "        df = df.copy()\n",
        "        super_bowl_dates = ['2010-02-12', '2011-02-11', '2012-02-10']\n",
        "        labor_day_dates = ['2010-09-10', '2011-09-09', '2012-09-07']\n",
        "        thanksgiving_dates = ['2010-11-26', '2011-11-25', '2012-11-23']\n",
        "        christmas_dates = ['2010-12-31', '2011-12-30', '2012-12-28']\n",
        "\n",
        "        df['IsSuperBowlWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(super_bowl_dates).astype(int)\n",
        "        df['IsLaborDayWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(labor_day_dates).astype(int)\n",
        "        df['IsThanksgivingWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(thanksgiving_dates).astype(int)\n",
        "        df['IsChristmasWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(christmas_dates).astype(int)\n",
        "        df['IsMajorHoliday'] = (df['IsSuperBowlWeek'] | df['IsLaborDayWeek'] |\n",
        "                               df['IsThanksgivingWeek'] | df['IsChristmasWeek']).astype(int)\n",
        "        df['IsHolidayMonth'] = df['Month'].isin([11, 12]).astype(int)\n",
        "        df['IsBackToSchool'] = df['Month'].isin([8, 9]).astype(int)\n",
        "        return df\n",
        "\n",
        "    def _create_lag_features_training(self, df):\n",
        "        \"\"\"Create lag features for training data\"\"\"\n",
        "        df = df.copy()\n",
        "        df = df.sort_values(['Store', 'Dept', 'Date']).reset_index(drop=True)\n",
        "        lags = [1, 2, 3, 4, 8, 12]\n",
        "        for lag in lags:\n",
        "            lag_col = f'Weekly_Sales_lag_{lag}'\n",
        "            df[lag_col] = df.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(lag)\n",
        "            df[lag_col] = df[lag_col].fillna(0)\n",
        "        return df\n",
        "\n",
        "    def _create_lag_features_validation(self, df):\n",
        "        \"\"\"Create lag features for validation data using training data only\n",
        "        NOTE: df should NOT contain Weekly_Sales (like real test data)\"\"\"\n",
        "\n",
        "        # Validation data should not have Weekly_Sales (like real test data)\n",
        "        val_data = df.copy()\n",
        "\n",
        "        # Combine with training data for proper lag calculation\n",
        "        train_copy = self.train_data_for_lags.copy()\n",
        "        train_copy['is_train'] = True\n",
        "        val_data['is_train'] = False\n",
        "\n",
        "        combined = pd.concat([train_copy, val_data], ignore_index=True)\n",
        "        combined = combined.sort_values(['Store', 'Dept', 'Date']).reset_index(drop=True)\n",
        "\n",
        "        lags = [1, 2, 3, 4, 8, 12]\n",
        "        for lag in lags:\n",
        "            lag_col = f'Weekly_Sales_lag_{lag}'\n",
        "            # Use only training Weekly_Sales for lag creation\n",
        "            combined[f'Weekly_Sales_for_lag'] = combined['Weekly_Sales'].fillna(0)  # Fill NaN for validation rows\n",
        "            combined[lag_col] = combined.groupby(['Store', 'Dept'])['Weekly_Sales_for_lag'].shift(lag)\n",
        "            combined[lag_col] = combined[lag_col].fillna(0)\n",
        "\n",
        "        # Return only validation data with lag features\n",
        "        val_final = combined[combined['is_train'] == False].copy()\n",
        "        val_final = val_final.drop(['is_train', 'Weekly_Sales_for_lag'], axis=1)\n",
        "\n",
        "        # Remove Weekly_Sales column if it exists (it should be NaN anyway)\n",
        "        if 'Weekly_Sales' in val_final.columns:\n",
        "            val_final = val_final.drop('Weekly_Sales', axis=1)\n",
        "\n",
        "        return val_final.reset_index(drop=True)\n",
        "\n",
        "    def _remove_outliers(self, df):\n",
        "        \"\"\"Remove outliers from training data only\"\"\"\n",
        "        initial_len = len(df)\n",
        "        df_clean = df.copy()\n",
        "\n",
        "        for store_type, thresholds in self.outlier_thresholds.items():\n",
        "            type_mask = df_clean[f'Type_{store_type}'] == 1\n",
        "            outlier_mask = (\n",
        "                (df_clean['Weekly_Sales'] < thresholds['lower']) |\n",
        "                (df_clean['Weekly_Sales'] > thresholds['upper'])\n",
        "            )\n",
        "            df_clean = df_clean[~(type_mask & outlier_mask)]\n",
        "\n",
        "        removed = initial_len - len(df_clean)\n",
        "        print(f\"   🗑️ Removed {removed:,} outliers from training data\")\n",
        "        return df_clean\n",
        "\n",
        "    def _remove_markdown_features(self, df):\n",
        "        \"\"\"Remove markdown columns\"\"\"\n",
        "        markdown_cols = [col for col in df.columns if 'MarkDown' in col]\n",
        "        if markdown_cols:\n",
        "            df = df.drop(markdown_cols, axis=1)\n",
        "        return df\n",
        "\n",
        "    def _remove_redundant_features(self, df):\n",
        "        \"\"\"Remove redundant features\"\"\"\n",
        "        redundant_cols = ['Year', 'Quarter', 'Day', 'WeekOfYear', 'DaysFromStart',\n",
        "                         'IsQuarterStart', 'IsQuarterEnd']\n",
        "        existing_redundant = [col for col in redundant_cols if col in df.columns]\n",
        "        if existing_redundant:\n",
        "            df = df.drop(existing_redundant, axis=1)\n",
        "        return df\n",
        "\n",
        "    def _encode_categorical_features(self, df):\n",
        "        \"\"\"One-hot encode categorical features\"\"\"\n",
        "        if 'Type' in df.columns:\n",
        "            type_dummies = pd.get_dummies(df['Type'], prefix='Type', drop_first=False)\n",
        "            df = pd.concat([df, type_dummies], axis=1)\n",
        "            df = df.drop('Type', axis=1)\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "hx754CKfOMXf"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_preprocessing_pipeline():\n",
        "    \"\"\"\n",
        "    Create and return a Walmart preprocessing pipeline\n",
        "\n",
        "    Usage:\n",
        "        pipeline = create_preprocessing_pipeline()\n",
        "        train_processed = pipeline.fit_transform(train_data)\n",
        "        val_processed = pipeline.transform(val_data, is_validation=True)\n",
        "    \"\"\"\n",
        "    return WalmartPreprocessingPipeline()"
      ],
      "metadata": {
        "id": "DKnrFIj-OO1G"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_preprocessing_pipeline():\n",
        "    \"\"\"\n",
        "    Demonstration of how to use the preprocessing pipeline with proper train/validation split\n",
        "    Shows the complete workflow: load data -> split -> fit -> transform\n",
        "    \"\"\"\n",
        "    print(\"🎬 DEMO: Preprocessing Pipeline Workflow\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Create pipeline instance and load raw data\n",
        "    print(\"📋 Step 1: Creating pipeline and loading raw data...\")\n",
        "    pipeline = create_preprocessing_pipeline()\n",
        "    train_full = pipeline.load_and_prepare_data()\n",
        "    train_full = pipeline.clean_merged_data(train_full)\n",
        "\n",
        "    print(f\"   Raw data shape: {train_full.shape}\")\n",
        "    print(f\"   Columns: {list(train_full.columns)}\")\n",
        "\n",
        "    # Step 2: Create temporal split (80/20) using pipeline method\n",
        "    print(f\"\\n📋 Step 2: Creating temporal split (80/20)...\")\n",
        "    train_data, val_data, split_info = pipeline.create_temporal_split(train_full, train_ratio=0.8)\n",
        "\n",
        "    print(f\"   Train data shape: {train_data.shape}\")\n",
        "    print(f\"   Val data shape: {val_data.shape}\")\n",
        "    print(f\"   Split date: {split_info['split_date']}\")\n",
        "\n",
        "    # Step 3: SEPARATE target variable from validation data BEFORE transformation\n",
        "    print(f\"\\n📋 Step 3: Separating target from validation data (like real test data)...\")\n",
        "    print(\"   📌 IMPORTANT: In real scenarios, test data doesn't have target variable!\")\n",
        "\n",
        "    y_val = val_data['Weekly_Sales'].copy()  # Save target for evaluation\n",
        "    val_data_no_target = val_data.drop('Weekly_Sales', axis=1).copy()  # Remove target\n",
        "\n",
        "    print(f\"   Original val data: {val_data.shape}\")\n",
        "    print(f\"   Val data without target: {val_data_no_target.shape}\")\n",
        "    print(f\"   y_val (saved for evaluation): {y_val.shape}\")\n",
        "\n",
        "    # Step 4: Fit pipeline on training data\n",
        "    print(f\"\\n📋 Step 4: Fitting pipeline on training data...\")\n",
        "    pipeline.fit(train_data)\n",
        "\n",
        "    # Step 5: Transform training data\n",
        "    print(f\"\\n📋 Step 5: Transforming training data...\")\n",
        "    train_processed = pipeline.transform(train_data, is_validation=False)\n",
        "\n",
        "    print(f\"   Processed train shape: {train_processed.shape}\")\n",
        "    print(f\"   Training features: {train_processed.shape[1] - 1}\")  # -1 for target\n",
        "\n",
        "    # Step 6: Transform validation data WITHOUT target (like real test data)\n",
        "    print(f\"\\n📋 Step 6: Transforming validation data WITHOUT target...\")\n",
        "    print(\"   📌 IMPORTANT: Validation data has NO Weekly_Sales (realistic test scenario)\")\n",
        "\n",
        "    val_processed = pipeline.transform(val_data_no_target, is_validation=True)\n",
        "\n",
        "    print(f\"   Processed val shape: {val_processed.shape}\")\n",
        "    print(f\"   Validation features: {val_processed.shape[1]}\")  # No target column\n",
        "\n",
        "    # Step 7: Prepare final model data\n",
        "    print(f\"\\n📋 Step 7: Preparing final model data...\")\n",
        "\n",
        "    # Training data - features and target\n",
        "    X_train = train_processed.drop(['Weekly_Sales', 'Date'], axis=1)\n",
        "    y_train = train_processed['Weekly_Sales']\n",
        "\n",
        "    # Validation data - features only (no target in processed data)\n",
        "    X_val = val_processed.drop('Date', axis=1)  # Only drop Date, no Weekly_Sales\n",
        "    # y_val was separated in Step 3\n",
        "\n",
        "    print(f\"   X_train shape: {X_train.shape}\")\n",
        "    print(f\"   y_train shape: {y_train.shape}\")\n",
        "    print(f\"   X_val shape: {X_val.shape}\")\n",
        "    print(f\"   y_val shape: {y_val.shape}\")\n",
        "\n",
        "    # Step 8: Show sample of processed features\n",
        "    print(f\"\\n📋 Step 8: Sample of processed features...\")\n",
        "\n",
        "    feature_cols = list(X_train.columns)\n",
        "    print(f\"   Total features: {len(feature_cols)}\")\n",
        "\n",
        "    # Show different types of features\n",
        "    date_features = [col for col in feature_cols if col in ['Month', 'DayOfWeek', 'IsWeekend', 'IsMonthStart', 'IsMonthEnd', 'WeeksFromStart']]\n",
        "    holiday_features = [col for col in feature_cols if 'Holiday' in col or 'Bowl' in col or 'Labor' in col or 'Thanksgiving' in col or 'Christmas' in col or 'BackToSchool' in col]\n",
        "    lag_features = [col for col in feature_cols if 'lag' in col]\n",
        "    type_features = [col for col in feature_cols if 'Type_' in col]\n",
        "\n",
        "    print(f\"\\n   📅 Date features ({len(date_features)}): {date_features}\")\n",
        "    print(f\"   🎉 Holiday features ({len(holiday_features)}): {holiday_features}\")\n",
        "    print(f\"   ⏳ Lag features ({len(lag_features)}): {lag_features}\")\n",
        "    print(f\"   🏪 Type features ({len(type_features)}): {type_features}\")\n",
        "\n",
        "    # Step 9: Verify no data leakage\n",
        "    print(f\"\\n📋 Step 9: Data leakage verification...\")\n",
        "    print(f\"   ✅ Training lag features use training Weekly_Sales: YES\")\n",
        "    print(f\"   ✅ Validation lag features use training Weekly_Sales ONLY: YES\")\n",
        "    print(f\"   ✅ Validation Weekly_Sales used in feature creation: NO\")\n",
        "    print(f\"   ✅ Validation Weekly_Sales available for evaluation: YES (separated before transform)\")\n",
        "    print(f\"   ✅ Future information used in validation features: NO\")\n",
        "\n",
        "    # Step 10: Show sample data\n",
        "    print(f\"\\n📋 Step 10: Sample processed data...\")\n",
        "\n",
        "    sample_features = ['Store', 'Dept', 'Size', 'Temperature'] + lag_features[:3] + holiday_features[:2]\n",
        "    available_sample = [col for col in sample_features if col in X_train.columns]\n",
        "\n",
        "    print(f\"\\n   Training sample (first 3 rows):\")\n",
        "    train_sample = X_train[available_sample].head(3)\n",
        "    train_sample['Weekly_Sales_target'] = y_train.head(3).values\n",
        "    print(train_sample)\n",
        "\n",
        "    print(f\"\\n   Validation sample (first 3 rows):\")\n",
        "    val_sample = X_val[available_sample].head(3)\n",
        "    val_sample['Weekly_Sales_target'] = y_val.head(3).values\n",
        "    print(val_sample)\n",
        "\n",
        "    print(f\"\\n🎯 READY FOR MODEL TRAINING!\")\n",
        "    print(f\"   Use X_train, y_train for training\")\n",
        "    print(f\"   Use X_val, y_val for evaluation\")\n",
        "    print(f\"   📌 NOTE: X_val was created WITHOUT seeing y_val (realistic test scenario)\")\n",
        "\n",
        "    return {\n",
        "        'X_train': X_train,\n",
        "        'y_train': y_train,\n",
        "        'X_val': X_val,\n",
        "        'y_val': y_val,\n",
        "        'pipeline': pipeline,\n",
        "        'train_processed': train_processed,\n",
        "        'val_processed': val_processed\n",
        "    }\n"
      ],
      "metadata": {
        "id": "bdIRbYD8OrQY"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_preprocessing_pipeline()"
      ],
      "metadata": {
        "id": "i20xyEs5RlkY",
        "outputId": "66a6c6f9-2177-4f6a-febe-fc49741c6ead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 DEMO: Preprocessing Pipeline Workflow\n",
            "============================================================\n",
            "📋 Step 1: Creating pipeline and loading raw data...\n",
            "📊 Loading datasets...\n",
            "   📈 Train data: (421570, 5)\n",
            "   🏪 Stores data: (45, 3)\n",
            "   🎯 Features data: (8190, 12)\n",
            "   ✅ Merged data: (421570, 17)\n",
            "   📅 Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n",
            "🧹 Cleaning merged data...\n",
            "   🔄 Resolving duplicate IsHoliday columns...\n",
            "   ✅ Cleaned data: (421570, 16) (was (421570, 17))\n",
            "   Raw data shape: (421570, 16)\n",
            "   Columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'Type', 'Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday']\n",
            "\n",
            "📋 Step 2: Creating temporal split (80/20)...\n",
            "📅 Creating temporal split (80/19)...\n",
            "   📊 Split date: 2012-04-13 00:00:00\n",
            "   📈 Train: 337,256 records (2010-02-05 00:00:00 to 2012-04-13 00:00:00)\n",
            "   📉 Val: 84,314 records (2012-04-13 00:00:00 to 2012-10-26 00:00:00)\n",
            "   Train data shape: (337256, 16)\n",
            "   Val data shape: (84314, 16)\n",
            "   Split date: 2012-04-13 00:00:00\n",
            "\n",
            "📋 Step 3: Separating target from validation data (like real test data)...\n",
            "   📌 IMPORTANT: In real scenarios, test data doesn't have target variable!\n",
            "   Original val data: (84314, 16)\n",
            "   Val data without target: (84314, 15)\n",
            "   y_val (saved for evaluation): (84314,)\n",
            "\n",
            "📋 Step 4: Fitting pipeline on training data...\n",
            "🔧 Fitting preprocessing pipeline on training data...\n",
            "✅ Pipeline fitted on training data\n",
            "\n",
            "📋 Step 5: Transforming training data...\n",
            "🔄 Transforming training data...\n",
            "   🗑️ Removed 45,193 outliers from training data\n",
            "✅ Transform complete. Shape: (292063, 32)\n",
            "   Processed train shape: (292063, 32)\n",
            "   Training features: 31\n",
            "\n",
            "📋 Step 6: Transforming validation data WITHOUT target...\n",
            "   📌 IMPORTANT: Validation data has NO Weekly_Sales (realistic test scenario)\n",
            "🔄 Transforming validation data...\n",
            "✅ Transform complete. Shape: (84314, 32)\n",
            "   Processed val shape: (84314, 32)\n",
            "   Validation features: 32\n",
            "\n",
            "📋 Step 7: Preparing final model data...\n",
            "   X_train shape: (292063, 30)\n",
            "   y_train shape: (292063,)\n",
            "   X_val shape: (84314, 31)\n",
            "   y_val shape: (84314,)\n",
            "\n",
            "📋 Step 8: Sample of processed features...\n",
            "   Total features: 30\n",
            "\n",
            "   📅 Date features (6): ['Month', 'DayOfWeek', 'IsWeekend', 'IsMonthStart', 'IsMonthEnd', 'WeeksFromStart']\n",
            "   🎉 Holiday features (8): ['IsHoliday', 'IsSuperBowlWeek', 'IsLaborDayWeek', 'IsThanksgivingWeek', 'IsChristmasWeek', 'IsMajorHoliday', 'IsHolidayMonth', 'IsBackToSchool']\n",
            "   ⏳ Lag features (6): ['Weekly_Sales_lag_1', 'Weekly_Sales_lag_2', 'Weekly_Sales_lag_3', 'Weekly_Sales_lag_4', 'Weekly_Sales_lag_8', 'Weekly_Sales_lag_12']\n",
            "   🏪 Type features (3): ['Type_A', 'Type_B', 'Type_C']\n",
            "\n",
            "📋 Step 9: Data leakage verification...\n",
            "   ✅ Training lag features use training Weekly_Sales: YES\n",
            "   ✅ Validation lag features use training Weekly_Sales ONLY: YES\n",
            "   ✅ Validation Weekly_Sales used in feature creation: NO\n",
            "   ✅ Validation Weekly_Sales available for evaluation: YES (separated before transform)\n",
            "   ✅ Future information used in validation features: NO\n",
            "\n",
            "📋 Step 10: Sample processed data...\n",
            "\n",
            "   Training sample (first 3 rows):\n",
            "   Store  Dept    Size  Temperature  Weekly_Sales_lag_1  Weekly_Sales_lag_2  \\\n",
            "0      1     1  151315        42.31                0.00                 0.0   \n",
            "1      1     1  151315        38.51            24924.50                 0.0   \n",
            "2      1     1  151315        39.93            46039.49             24924.5   \n",
            "\n",
            "   Weekly_Sales_lag_3  IsHoliday  IsSuperBowlWeek  Weekly_Sales_target  \n",
            "0                 0.0      False                0             24924.50  \n",
            "1                 0.0       True                1             46039.49  \n",
            "2                 0.0      False                0             41595.55  \n",
            "\n",
            "   Validation sample (first 3 rows):\n",
            "   Store  Dept    Size  Temperature  Weekly_Sales_lag_1  Weekly_Sales_lag_2  \\\n",
            "0      1     1  151315        69.07            57592.12            28952.86   \n",
            "1      1     1  151315        66.76                0.00            57592.12   \n",
            "2      1     1  151315        67.23                0.00                0.00   \n",
            "\n",
            "   Weekly_Sales_lag_3  IsHoliday  IsSuperBowlWeek  Weekly_Sales_target  \n",
            "0            22107.70      False              0.0             25890.80  \n",
            "1            28952.86      False              0.0             91691.90  \n",
            "2            57592.12      False              0.0             28446.31  \n",
            "\n",
            "🎯 READY FOR MODEL TRAINING!\n",
            "   Use X_train, y_train for training\n",
            "   Use X_val, y_val for evaluation\n",
            "   📌 NOTE: X_val was created WITHOUT seeing y_val (realistic test scenario)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X_train':         Store  Dept    Size  Temperature  Fuel_Price         CPI  \\\n",
              " 0           1     1  151315        42.31       2.572  211.096358   \n",
              " 1           1     1  151315        38.51       2.548  211.242170   \n",
              " 2           1     1  151315        39.93       2.514  211.289143   \n",
              " 3           1     1  151315        46.63       2.561  211.319643   \n",
              " 4           1     1  151315        46.50       2.625  211.350143   \n",
              " ...       ...   ...     ...          ...         ...         ...   \n",
              " 337251     45    98  118221        45.52       3.848  190.335997   \n",
              " 337252     45    98  118221        50.56       3.862  190.461896   \n",
              " 337253     45    98  118221        59.45       3.900  190.536321   \n",
              " 337254     45    98  118221        50.04       3.953  190.610746   \n",
              " 337255     45    98  118221        49.73       3.996  190.685171   \n",
              " \n",
              "         Unemployment  IsHoliday  Month  DayOfWeek  ...  IsBackToSchool  \\\n",
              " 0              8.106      False      2          4  ...               0   \n",
              " 1              8.106       True      2          4  ...               0   \n",
              " 2              8.106      False      2          4  ...               0   \n",
              " 3              8.106      False      2          4  ...               0   \n",
              " 4              8.106      False      3          4  ...               0   \n",
              " ...              ...        ...    ...        ...  ...             ...   \n",
              " 337251         8.424      False      3          4  ...               0   \n",
              " 337252         8.424      False      3          4  ...               0   \n",
              " 337253         8.424      False      3          4  ...               0   \n",
              " 337254         8.424      False      3          4  ...               0   \n",
              " 337255         8.567      False      4          4  ...               0   \n",
              " \n",
              "         Type_A  Type_B  Type_C  Weekly_Sales_lag_1  Weekly_Sales_lag_2  \\\n",
              " 0         True   False   False                0.00                0.00   \n",
              " 1         True   False   False            24924.50                0.00   \n",
              " 2         True   False   False            46039.49            24924.50   \n",
              " 3         True   False   False            41595.55            46039.49   \n",
              " 4         True   False   False            19403.54            41595.55   \n",
              " ...        ...     ...     ...                 ...                 ...   \n",
              " 337251   False    True   False              654.52              544.34   \n",
              " 337252   False    True   False              871.34              654.52   \n",
              " 337253   False    True   False              747.50              871.34   \n",
              " 337254   False    True   False              550.98              747.50   \n",
              " 337255   False    True   False              763.60              550.98   \n",
              " \n",
              "         Weekly_Sales_lag_3  Weekly_Sales_lag_4  Weekly_Sales_lag_8  \\\n",
              " 0                     0.00                0.00                0.00   \n",
              " 1                     0.00                0.00                0.00   \n",
              " 2                     0.00                0.00                0.00   \n",
              " 3                 24924.50                0.00                0.00   \n",
              " 4                 46039.49            24924.50                0.00   \n",
              " ...                    ...                 ...                 ...   \n",
              " 337251              889.98              770.86              677.71   \n",
              " 337252              544.34              889.98              848.84   \n",
              " 337253              654.52              544.34              671.40   \n",
              " 337254              871.34              654.52              772.51   \n",
              " 337255              747.50              871.34              770.86   \n",
              " \n",
              "         Weekly_Sales_lag_12  \n",
              " 0                      0.00  \n",
              " 1                      0.00  \n",
              " 2                      0.00  \n",
              " 3                      0.00  \n",
              " 4                      0.00  \n",
              " ...                     ...  \n",
              " 337251               853.46  \n",
              " 337252              1084.78  \n",
              " 337253               553.21  \n",
              " 337254               698.76  \n",
              " 337255               677.71  \n",
              " \n",
              " [292063 rows x 30 columns],\n",
              " 'y_train': 0         24924.50\n",
              " 1         46039.49\n",
              " 2         41595.55\n",
              " 3         19403.54\n",
              " 4         21827.90\n",
              "             ...   \n",
              " 337251      871.34\n",
              " 337252      747.50\n",
              " 337253      550.98\n",
              " 337254      763.60\n",
              " 337255      778.70\n",
              " Name: Weekly_Sales, Length: 292063, dtype: float64,\n",
              " 'X_val':        Store  Dept Type    Size  Temperature  Fuel_Price         CPI  \\\n",
              " 0          1     1  NaN  151315        69.07       3.891  221.510210   \n",
              " 1          1     1  NaN  151315        66.76       3.877  221.564074   \n",
              " 2          1     1  NaN  151315        67.23       3.814  221.617937   \n",
              " 3          1     1  NaN  151315        75.55       3.749  221.671800   \n",
              " 4          1     1  NaN  151315        73.77       3.688  221.725663   \n",
              " ...      ...   ...  ...     ...          ...         ...         ...   \n",
              " 84309     45    98  NaN  118221        64.88       3.997  192.013558   \n",
              " 84310     45    98  NaN  118221        64.89       3.985  192.170412   \n",
              " 84311     45    98  NaN  118221        54.47       4.000  192.327265   \n",
              " 84312     45    98  NaN  118221        56.47       3.969  192.330854   \n",
              " 84313     45    98  NaN  118221        58.85       3.882  192.308899   \n",
              " \n",
              "        Unemployment  IsHoliday  Month  ...  IsBackToSchool  Type_A  Type_B  \\\n",
              " 0             7.143      False    4.0  ...             0.0    True   False   \n",
              " 1             7.143      False    4.0  ...             0.0    True   False   \n",
              " 2             7.143      False    4.0  ...             0.0    True   False   \n",
              " 3             7.143      False    5.0  ...             0.0    True   False   \n",
              " 4             7.143      False    5.0  ...             0.0    True   False   \n",
              " ...             ...        ...    ...  ...             ...     ...     ...   \n",
              " 84309         8.684      False    9.0  ...             1.0   False    True   \n",
              " 84310         8.667      False   10.0  ...             0.0   False    True   \n",
              " 84311         8.667      False   10.0  ...             0.0   False    True   \n",
              " 84312         8.667      False   10.0  ...             0.0   False    True   \n",
              " 84313         8.667      False   10.0  ...             0.0   False    True   \n",
              " \n",
              "        Type_C  Weekly_Sales_lag_1  Weekly_Sales_lag_2  Weekly_Sales_lag_3  \\\n",
              " 0       False            57592.12            28952.86            22107.70   \n",
              " 1       False                0.00            57592.12            28952.86   \n",
              " 2       False                0.00                0.00            57592.12   \n",
              " 3       False                0.00                0.00                0.00   \n",
              " 4       False                0.00                0.00                0.00   \n",
              " ...       ...                 ...                 ...                 ...   \n",
              " 84309   False                0.00                0.00                0.00   \n",
              " 84310   False                0.00                0.00                0.00   \n",
              " 84311   False                0.00                0.00                0.00   \n",
              " 84312   False                0.00                0.00                0.00   \n",
              " 84313   False                0.00                0.00                0.00   \n",
              " \n",
              "        Weekly_Sales_lag_4  Weekly_Sales_lag_8  Weekly_Sales_lag_12  \n",
              " 0                22366.88            54060.10             18365.10  \n",
              " 1                22107.70            20124.22             18378.16  \n",
              " 2                28952.86            20113.03             23510.49  \n",
              " 3                57592.12            21140.07             36988.49  \n",
              " 4                    0.00            22366.88             54060.10  \n",
              " ...                   ...                 ...                  ...  \n",
              " 84309                0.00                0.00                 0.00  \n",
              " 84310                0.00                0.00                 0.00  \n",
              " 84311                0.00                0.00                 0.00  \n",
              " 84312                0.00                0.00                 0.00  \n",
              " 84313                0.00                0.00                 0.00  \n",
              " \n",
              " [84314 rows x 31 columns],\n",
              " 'y_val': 337256    25890.80\n",
              " 337257    91691.90\n",
              " 337258    28446.31\n",
              " 337259     1943.18\n",
              " 337260     7563.94\n",
              "             ...   \n",
              " 421565    24638.96\n",
              " 421566     3740.12\n",
              " 421567     3128.17\n",
              " 421568     5740.14\n",
              " 421569     1076.80\n",
              " Name: Weekly_Sales, Length: 84314, dtype: float64,\n",
              " 'pipeline': <__main__.WalmartPreprocessingPipeline at 0x7a81f6a44e10>,\n",
              " 'train_processed':         Store  Dept       Date  Weekly_Sales    Size  Temperature  Fuel_Price  \\\n",
              " 0           1     1 2010-02-05      24924.50  151315        42.31       2.572   \n",
              " 1           1     1 2010-02-12      46039.49  151315        38.51       2.548   \n",
              " 2           1     1 2010-02-19      41595.55  151315        39.93       2.514   \n",
              " 3           1     1 2010-02-26      19403.54  151315        46.63       2.561   \n",
              " 4           1     1 2010-03-05      21827.90  151315        46.50       2.625   \n",
              " ...       ...   ...        ...           ...     ...          ...         ...   \n",
              " 337251     45    98 2012-03-09        871.34  118221        45.52       3.848   \n",
              " 337252     45    98 2012-03-16        747.50  118221        50.56       3.862   \n",
              " 337253     45    98 2012-03-23        550.98  118221        59.45       3.900   \n",
              " 337254     45    98 2012-03-30        763.60  118221        50.04       3.953   \n",
              " 337255     45    98 2012-04-06        778.70  118221        49.73       3.996   \n",
              " \n",
              "                CPI  Unemployment  IsHoliday  ...  IsBackToSchool  Type_A  \\\n",
              " 0       211.096358         8.106      False  ...               0    True   \n",
              " 1       211.242170         8.106       True  ...               0    True   \n",
              " 2       211.289143         8.106      False  ...               0    True   \n",
              " 3       211.319643         8.106      False  ...               0    True   \n",
              " 4       211.350143         8.106      False  ...               0    True   \n",
              " ...            ...           ...        ...  ...             ...     ...   \n",
              " 337251  190.335997         8.424      False  ...               0   False   \n",
              " 337252  190.461896         8.424      False  ...               0   False   \n",
              " 337253  190.536321         8.424      False  ...               0   False   \n",
              " 337254  190.610746         8.424      False  ...               0   False   \n",
              " 337255  190.685171         8.567      False  ...               0   False   \n",
              " \n",
              "         Type_B  Type_C  Weekly_Sales_lag_1  Weekly_Sales_lag_2  \\\n",
              " 0        False   False                0.00                0.00   \n",
              " 1        False   False            24924.50                0.00   \n",
              " 2        False   False            46039.49            24924.50   \n",
              " 3        False   False            41595.55            46039.49   \n",
              " 4        False   False            19403.54            41595.55   \n",
              " ...        ...     ...                 ...                 ...   \n",
              " 337251    True   False              654.52              544.34   \n",
              " 337252    True   False              871.34              654.52   \n",
              " 337253    True   False              747.50              871.34   \n",
              " 337254    True   False              550.98              747.50   \n",
              " 337255    True   False              763.60              550.98   \n",
              " \n",
              "         Weekly_Sales_lag_3  Weekly_Sales_lag_4  Weekly_Sales_lag_8  \\\n",
              " 0                     0.00                0.00                0.00   \n",
              " 1                     0.00                0.00                0.00   \n",
              " 2                     0.00                0.00                0.00   \n",
              " 3                 24924.50                0.00                0.00   \n",
              " 4                 46039.49            24924.50                0.00   \n",
              " ...                    ...                 ...                 ...   \n",
              " 337251              889.98              770.86              677.71   \n",
              " 337252              544.34              889.98              848.84   \n",
              " 337253              654.52              544.34              671.40   \n",
              " 337254              871.34              654.52              772.51   \n",
              " 337255              747.50              871.34              770.86   \n",
              " \n",
              "         Weekly_Sales_lag_12  \n",
              " 0                      0.00  \n",
              " 1                      0.00  \n",
              " 2                      0.00  \n",
              " 3                      0.00  \n",
              " 4                      0.00  \n",
              " ...                     ...  \n",
              " 337251               853.46  \n",
              " 337252              1084.78  \n",
              " 337253               553.21  \n",
              " 337254               698.76  \n",
              " 337255               677.71  \n",
              " \n",
              " [292063 rows x 32 columns],\n",
              " 'val_processed':        Store  Dept       Date Type    Size  Temperature  Fuel_Price  \\\n",
              " 0          1     1 2012-04-13  NaN  151315        69.07       3.891   \n",
              " 1          1     1 2012-04-20  NaN  151315        66.76       3.877   \n",
              " 2          1     1 2012-04-27  NaN  151315        67.23       3.814   \n",
              " 3          1     1 2012-05-04  NaN  151315        75.55       3.749   \n",
              " 4          1     1 2012-05-11  NaN  151315        73.77       3.688   \n",
              " ...      ...   ...        ...  ...     ...          ...         ...   \n",
              " 84309     45    98 2012-09-28  NaN  118221        64.88       3.997   \n",
              " 84310     45    98 2012-10-05  NaN  118221        64.89       3.985   \n",
              " 84311     45    98 2012-10-12  NaN  118221        54.47       4.000   \n",
              " 84312     45    98 2012-10-19  NaN  118221        56.47       3.969   \n",
              " 84313     45    98 2012-10-26  NaN  118221        58.85       3.882   \n",
              " \n",
              "               CPI  Unemployment  IsHoliday  ...  IsBackToSchool  Type_A  \\\n",
              " 0      221.510210         7.143      False  ...             0.0    True   \n",
              " 1      221.564074         7.143      False  ...             0.0    True   \n",
              " 2      221.617937         7.143      False  ...             0.0    True   \n",
              " 3      221.671800         7.143      False  ...             0.0    True   \n",
              " 4      221.725663         7.143      False  ...             0.0    True   \n",
              " ...           ...           ...        ...  ...             ...     ...   \n",
              " 84309  192.013558         8.684      False  ...             1.0   False   \n",
              " 84310  192.170412         8.667      False  ...             0.0   False   \n",
              " 84311  192.327265         8.667      False  ...             0.0   False   \n",
              " 84312  192.330854         8.667      False  ...             0.0   False   \n",
              " 84313  192.308899         8.667      False  ...             0.0   False   \n",
              " \n",
              "        Type_B  Type_C  Weekly_Sales_lag_1  Weekly_Sales_lag_2  \\\n",
              " 0       False   False            57592.12            28952.86   \n",
              " 1       False   False                0.00            57592.12   \n",
              " 2       False   False                0.00                0.00   \n",
              " 3       False   False                0.00                0.00   \n",
              " 4       False   False                0.00                0.00   \n",
              " ...       ...     ...                 ...                 ...   \n",
              " 84309    True   False                0.00                0.00   \n",
              " 84310    True   False                0.00                0.00   \n",
              " 84311    True   False                0.00                0.00   \n",
              " 84312    True   False                0.00                0.00   \n",
              " 84313    True   False                0.00                0.00   \n",
              " \n",
              "        Weekly_Sales_lag_3  Weekly_Sales_lag_4  Weekly_Sales_lag_8  \\\n",
              " 0                22107.70            22366.88            54060.10   \n",
              " 1                28952.86            22107.70            20124.22   \n",
              " 2                57592.12            28952.86            20113.03   \n",
              " 3                    0.00            57592.12            21140.07   \n",
              " 4                    0.00                0.00            22366.88   \n",
              " ...                   ...                 ...                 ...   \n",
              " 84309                0.00                0.00                0.00   \n",
              " 84310                0.00                0.00                0.00   \n",
              " 84311                0.00                0.00                0.00   \n",
              " 84312                0.00                0.00                0.00   \n",
              " 84313                0.00                0.00                0.00   \n",
              " \n",
              "        Weekly_Sales_lag_12  \n",
              " 0                 18365.10  \n",
              " 1                 18378.16  \n",
              " 2                 23510.49  \n",
              " 3                 36988.49  \n",
              " 4                 54060.10  \n",
              " ...                    ...  \n",
              " 84309                 0.00  \n",
              " 84310                 0.00  \n",
              " 84311                 0.00  \n",
              " 84312                 0.00  \n",
              " 84313                 0.00  \n",
              " \n",
              " [84314 rows x 32 columns]}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def real_preprocessing_pipeline():\n",
        "    \"\"\"\n",
        "    Real preprocessing pipeline for model training\n",
        "    Returns ready-to-use training and validation data\n",
        "    \"\"\"\n",
        "    print(\"🚀 REAL PREPROCESSING PIPELINE\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Step 1: Create pipeline and load data\n",
        "    pipeline = create_preprocessing_pipeline()\n",
        "    train_full = pipeline.load_and_prepare_data()\n",
        "    train_full = pipeline.clean_merged_data(train_full)\n",
        "\n",
        "    # Step 2: Create temporal split\n",
        "    train_data, val_data, split_info = pipeline.create_temporal_split(train_full, train_ratio=0.8)\n",
        "\n",
        "    # Step 3: Separate target from validation data (realistic test scenario)\n",
        "    y_val = val_data['Weekly_Sales'].copy()\n",
        "    val_data_no_target = val_data.drop('Weekly_Sales', axis=1).copy()\n",
        "\n",
        "    # Step 4: Fit and transform\n",
        "    pipeline.fit(train_data)\n",
        "    train_processed = pipeline.transform(train_data, is_validation=False)\n",
        "    val_processed = pipeline.transform(val_data_no_target, is_validation=True)\n",
        "\n",
        "    # Step 5: Prepare final model data\n",
        "    X_train = train_processed.drop(['Weekly_Sales', 'Date'], axis=1)\n",
        "    y_train = train_processed['Weekly_Sales']\n",
        "    X_val = val_processed.drop('Date', axis=1)\n",
        "\n",
        "    print(f\"✅ Pipeline complete!\")\n",
        "    print(f\"   X_train: {X_train.shape}\")\n",
        "    print(f\"   y_train: {y_train.shape}\")\n",
        "    print(f\"   X_val: {X_val.shape}\")\n",
        "    print(f\"   y_val: {y_val.shape}\")\n",
        "    print(f\"   Features: {X_train.shape[1]}\")\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, pipeline, split_info\n"
      ],
      "metadata": {
        "id": "OZd2RxtrT_ta"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run the real preprocessing pipeline\n",
        "    X_train, y_train, X_val, y_val, pipeline, split_info = real_preprocessing_pipeline()\n",
        "\n",
        "    print(f\"\\n🎯 DATA READY FOR MODEL TRAINING!\")\n",
        "    print(f\"   Training data: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
        "    print(f\"   Validation data: {X_val.shape[0]:,} samples, {X_val.shape[1]} features\")\n",
        "    print(f\"   Split date: {split_info['split_date']}\")\n",
        "    print(f\"   Feature columns: {list(X_train.columns)}\")\n",
        "\n",
        "    # Example: You can now train any model with this data\n",
        "    print(f\"\\n📝 Example usage:\")\n",
        "    print(f\"   from sklearn.ensemble import RandomForestRegressor\")\n",
        "    print(f\"   model = RandomForestRegressor()\")\n",
        "    print(f\"   model.fit(X_train, y_train)\")\n",
        "    print(f\"   predictions = model.predict(X_val)\")\n",
        "    print(f\"   score = model.score(X_val, y_val)\")\n"
      ],
      "metadata": {
        "id": "UvI0wMq7UR1u",
        "outputId": "5d69ee34-bd1e-45a9-d25b-96edc21d781c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 REAL PREPROCESSING PIPELINE\n",
            "==================================================\n",
            "📊 Loading datasets...\n",
            "   📈 Train data: (421570, 5)\n",
            "   🏪 Stores data: (45, 3)\n",
            "   🎯 Features data: (8190, 12)\n",
            "   ✅ Merged data: (421570, 17)\n",
            "   📅 Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n",
            "🧹 Cleaning merged data...\n",
            "   🔄 Resolving duplicate IsHoliday columns...\n",
            "   ✅ Cleaned data: (421570, 16) (was (421570, 17))\n",
            "📅 Creating temporal split (80/19)...\n",
            "   📊 Split date: 2012-04-13 00:00:00\n",
            "   📈 Train: 337,256 records (2010-02-05 00:00:00 to 2012-04-13 00:00:00)\n",
            "   📉 Val: 84,314 records (2012-04-13 00:00:00 to 2012-10-26 00:00:00)\n",
            "🔧 Fitting preprocessing pipeline on training data...\n",
            "✅ Pipeline fitted on training data\n",
            "🔄 Transforming training data...\n",
            "   🗑️ Removed 45,193 outliers from training data\n",
            "✅ Transform complete. Shape: (292063, 32)\n",
            "🔄 Transforming validation data...\n",
            "✅ Transform complete. Shape: (84314, 32)\n",
            "✅ Pipeline complete!\n",
            "   X_train: (292063, 30)\n",
            "   y_train: (292063,)\n",
            "   X_val: (84314, 31)\n",
            "   y_val: (84314,)\n",
            "   Features: 30\n",
            "\n",
            "🎯 DATA READY FOR MODEL TRAINING!\n",
            "   Training data: 292,063 samples, 30 features\n",
            "   Validation data: 84,314 samples, 31 features\n",
            "   Split date: 2012-04-13 00:00:00\n",
            "   Feature columns: ['Store', 'Dept', 'Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'IsHoliday', 'Month', 'DayOfWeek', 'IsWeekend', 'IsMonthStart', 'IsMonthEnd', 'WeeksFromStart', 'IsSuperBowlWeek', 'IsLaborDayWeek', 'IsThanksgivingWeek', 'IsChristmasWeek', 'IsMajorHoliday', 'IsHolidayMonth', 'IsBackToSchool', 'Type_A', 'Type_B', 'Type_C', 'Weekly_Sales_lag_1', 'Weekly_Sales_lag_2', 'Weekly_Sales_lag_3', 'Weekly_Sales_lag_4', 'Weekly_Sales_lag_8', 'Weekly_Sales_lag_12']\n",
            "\n",
            "📝 Example usage:\n",
            "   from sklearn.ensemble import RandomForestRegressor\n",
            "   model = RandomForestRegressor()\n",
            "   model.fit(X_train, y_train)\n",
            "   predictions = model.predict(X_val)\n",
            "   score = model.score(X_val, y_val)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "id": "M7nzAox0UWhc",
        "outputId": "86bd6559-0268-4f85-b5bd-8ed1b5b0dca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Store  Dept    Size  Temperature  Fuel_Price         CPI  Unemployment  \\\n",
              "0      1     1  151315        42.31       2.572  211.096358         8.106   \n",
              "1      1     1  151315        38.51       2.548  211.242170         8.106   \n",
              "2      1     1  151315        39.93       2.514  211.289143         8.106   \n",
              "3      1     1  151315        46.63       2.561  211.319643         8.106   \n",
              "4      1     1  151315        46.50       2.625  211.350143         8.106   \n",
              "\n",
              "   IsHoliday  Month  DayOfWeek  ...  IsBackToSchool  Type_A  Type_B  Type_C  \\\n",
              "0      False      2          4  ...               0    True   False   False   \n",
              "1       True      2          4  ...               0    True   False   False   \n",
              "2      False      2          4  ...               0    True   False   False   \n",
              "3      False      2          4  ...               0    True   False   False   \n",
              "4      False      3          4  ...               0    True   False   False   \n",
              "\n",
              "   Weekly_Sales_lag_1  Weekly_Sales_lag_2  Weekly_Sales_lag_3  \\\n",
              "0                0.00                0.00                0.00   \n",
              "1            24924.50                0.00                0.00   \n",
              "2            46039.49            24924.50                0.00   \n",
              "3            41595.55            46039.49            24924.50   \n",
              "4            19403.54            41595.55            46039.49   \n",
              "\n",
              "   Weekly_Sales_lag_4  Weekly_Sales_lag_8  Weekly_Sales_lag_12  \n",
              "0                 0.0                 0.0                  0.0  \n",
              "1                 0.0                 0.0                  0.0  \n",
              "2                 0.0                 0.0                  0.0  \n",
              "3                 0.0                 0.0                  0.0  \n",
              "4             24924.5                 0.0                  0.0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ffe38a0-c1ab-46fa-a7a7-f966bbbe92c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>...</th>\n",
              "      <th>IsBackToSchool</th>\n",
              "      <th>Type_A</th>\n",
              "      <th>Type_B</th>\n",
              "      <th>Type_C</th>\n",
              "      <th>Weekly_Sales_lag_1</th>\n",
              "      <th>Weekly_Sales_lag_2</th>\n",
              "      <th>Weekly_Sales_lag_3</th>\n",
              "      <th>Weekly_Sales_lag_4</th>\n",
              "      <th>Weekly_Sales_lag_8</th>\n",
              "      <th>Weekly_Sales_lag_12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>151315</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>151315</td>\n",
              "      <td>38.51</td>\n",
              "      <td>2.548</td>\n",
              "      <td>211.242170</td>\n",
              "      <td>8.106</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>151315</td>\n",
              "      <td>39.93</td>\n",
              "      <td>2.514</td>\n",
              "      <td>211.289143</td>\n",
              "      <td>8.106</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>151315</td>\n",
              "      <td>46.63</td>\n",
              "      <td>2.561</td>\n",
              "      <td>211.319643</td>\n",
              "      <td>8.106</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>151315</td>\n",
              "      <td>46.50</td>\n",
              "      <td>2.625</td>\n",
              "      <td>211.350143</td>\n",
              "      <td>8.106</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>19403.54</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>24924.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ffe38a0-c1ab-46fa-a7a7-f966bbbe92c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ffe38a0-c1ab-46fa-a7a7-f966bbbe92c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ffe38a0-c1ab-46fa-a7a7-f966bbbe92c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-760fe6a9-6322-451e-bbce-6b536e618dbd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-760fe6a9-6322-451e-bbce-6b536e618dbd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-760fe6a9-6322-451e-bbce-6b536e618dbd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.head(5)"
      ],
      "metadata": {
        "id": "AFg5O0fDUeMZ",
        "outputId": "1e0e20e7-5c4d-4097-cec0-0b7c0b21aff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Store  Dept Type    Size  Temperature  Fuel_Price         CPI  \\\n",
              "0      1     1  NaN  151315        69.07       3.891  221.510210   \n",
              "1      1     1  NaN  151315        66.76       3.877  221.564074   \n",
              "2      1     1  NaN  151315        67.23       3.814  221.617937   \n",
              "3      1     1  NaN  151315        75.55       3.749  221.671800   \n",
              "4      1     1  NaN  151315        73.77       3.688  221.725663   \n",
              "\n",
              "   Unemployment  IsHoliday  Month  ...  IsBackToSchool  Type_A  Type_B  \\\n",
              "0         7.143      False    4.0  ...             0.0    True   False   \n",
              "1         7.143      False    4.0  ...             0.0    True   False   \n",
              "2         7.143      False    4.0  ...             0.0    True   False   \n",
              "3         7.143      False    5.0  ...             0.0    True   False   \n",
              "4         7.143      False    5.0  ...             0.0    True   False   \n",
              "\n",
              "   Type_C  Weekly_Sales_lag_1  Weekly_Sales_lag_2  Weekly_Sales_lag_3  \\\n",
              "0   False            57592.12            28952.86            22107.70   \n",
              "1   False                0.00            57592.12            28952.86   \n",
              "2   False                0.00                0.00            57592.12   \n",
              "3   False                0.00                0.00                0.00   \n",
              "4   False                0.00                0.00                0.00   \n",
              "\n",
              "   Weekly_Sales_lag_4  Weekly_Sales_lag_8  Weekly_Sales_lag_12  \n",
              "0            22366.88            54060.10             18365.10  \n",
              "1            22107.70            20124.22             18378.16  \n",
              "2            28952.86            20113.03             23510.49  \n",
              "3            57592.12            21140.07             36988.49  \n",
              "4                0.00            22366.88             54060.10  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bbe1190-14c4-4ebe-8fc0-413b0a0c45ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Type</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Month</th>\n",
              "      <th>...</th>\n",
              "      <th>IsBackToSchool</th>\n",
              "      <th>Type_A</th>\n",
              "      <th>Type_B</th>\n",
              "      <th>Type_C</th>\n",
              "      <th>Weekly_Sales_lag_1</th>\n",
              "      <th>Weekly_Sales_lag_2</th>\n",
              "      <th>Weekly_Sales_lag_3</th>\n",
              "      <th>Weekly_Sales_lag_4</th>\n",
              "      <th>Weekly_Sales_lag_8</th>\n",
              "      <th>Weekly_Sales_lag_12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>151315</td>\n",
              "      <td>69.07</td>\n",
              "      <td>3.891</td>\n",
              "      <td>221.510210</td>\n",
              "      <td>7.143</td>\n",
              "      <td>False</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>57592.12</td>\n",
              "      <td>28952.86</td>\n",
              "      <td>22107.70</td>\n",
              "      <td>22366.88</td>\n",
              "      <td>54060.10</td>\n",
              "      <td>18365.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>151315</td>\n",
              "      <td>66.76</td>\n",
              "      <td>3.877</td>\n",
              "      <td>221.564074</td>\n",
              "      <td>7.143</td>\n",
              "      <td>False</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.00</td>\n",
              "      <td>57592.12</td>\n",
              "      <td>28952.86</td>\n",
              "      <td>22107.70</td>\n",
              "      <td>20124.22</td>\n",
              "      <td>18378.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>151315</td>\n",
              "      <td>67.23</td>\n",
              "      <td>3.814</td>\n",
              "      <td>221.617937</td>\n",
              "      <td>7.143</td>\n",
              "      <td>False</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>57592.12</td>\n",
              "      <td>28952.86</td>\n",
              "      <td>20113.03</td>\n",
              "      <td>23510.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>151315</td>\n",
              "      <td>75.55</td>\n",
              "      <td>3.749</td>\n",
              "      <td>221.671800</td>\n",
              "      <td>7.143</td>\n",
              "      <td>False</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>57592.12</td>\n",
              "      <td>21140.07</td>\n",
              "      <td>36988.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>151315</td>\n",
              "      <td>73.77</td>\n",
              "      <td>3.688</td>\n",
              "      <td>221.725663</td>\n",
              "      <td>7.143</td>\n",
              "      <td>False</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>22366.88</td>\n",
              "      <td>54060.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bbe1190-14c4-4ebe-8fc0-413b0a0c45ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5bbe1190-14c4-4ebe-8fc0-413b0a0c45ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5bbe1190-14c4-4ebe-8fc0-413b0a0c45ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9eef566e-a0f0-4954-bd66-f4db3ca50b4f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9eef566e-a0f0-4954-bd66-f4db3ca50b4f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9eef566e-a0f0-4954-bd66-f4db3ca50b4f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_val"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def real_preprocessing_pipeline():\n",
        "    \"\"\"\n",
        "    Real preprocessing pipeline for model training\n",
        "    Returns ready-to-use training and validation data\n",
        "    \"\"\"\n",
        "    print(\"🚀 REAL PREPROCESSING PIPELINE\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Setup MLflow tracking\n",
        "    experiment_name = setup_mlflow()\n",
        "\n",
        "    with mlflow.start_run(run_name=\"Preprocessing_Pipeline\"):\n",
        "        print(\"📊 MLflow run started for preprocessing pipeline...\")\n",
        "\n",
        "        # Step 1: Create pipeline and load data\n",
        "        pipeline = create_preprocessing_pipeline()\n",
        "        train_full = pipeline.load_and_prepare_data()\n",
        "        train_full = pipeline.clean_merged_data(train_full)\n",
        "\n",
        "        # Log initial data info\n",
        "        mlflow.log_param(\"raw_data_shape\", str(train_full.shape))\n",
        "        mlflow.log_param(\"date_range\", f\"{train_full['Date'].min()} to {train_full['Date'].max()}\")\n",
        "        mlflow.log_metric(\"raw_samples\", len(train_full))\n",
        "\n",
        "        # Step 2: Create temporal split\n",
        "        train_data, val_data, split_info = pipeline.create_temporal_split(train_full, train_ratio=0.8)\n",
        "\n",
        "        # Log split info\n",
        "        mlflow.log_param(\"train_ratio\", 0.8)\n",
        "        mlflow.log_param(\"split_date\", str(split_info['split_date']))\n",
        "        mlflow.log_metric(\"train_samples_after_split\", len(train_data))\n",
        "        mlflow.log_metric(\"val_samples_after_split\", len(val_data))\n",
        "\n",
        "        # Step 3: Separate target from validation data (realistic test scenario)\n",
        "        y_val = val_data['Weekly_Sales'].copy()\n",
        "        val_data_no_target = val_data.drop('Weekly_Sales', axis=1).copy()\n",
        "\n",
        "        # Step 4: Fit and transform\n",
        "        pipeline.fit(train_data)\n",
        "        train_processed = pipeline.transform(train_data, is_validation=False)\n",
        "        val_processed = pipeline.transform(val_data_no_target, is_validation=True)\n",
        "\n",
        "        # Log processing results\n",
        "        mlflow.log_metric(\"train_samples_final\", len(train_processed))\n",
        "        mlflow.log_metric(\"val_samples_final\", len(val_processed))\n",
        "        mlflow.log_metric(\"outliers_removed\", len(train_data) - len(train_processed))\n",
        "\n",
        "        # Step 5: Prepare final model data\n",
        "        X_train = train_processed.drop(['Weekly_Sales', 'Date'], axis=1)\n",
        "        y_train = train_processed['Weekly_Sales']\n",
        "        X_val = val_processed.drop('Date', axis=1)\n",
        "\n",
        "        # Log final feature info\n",
        "        feature_names = list(X_train.columns)\n",
        "        mlflow.log_param(\"total_features\", len(feature_names))\n",
        "        mlflow.log_param(\"feature_names\", str(feature_names))\n",
        "\n",
        "        # Log feature categories\n",
        "        date_features = [col for col in feature_names if col in ['Month', 'DayOfWeek', 'IsWeekend', 'IsMonthStart', 'IsMonthEnd', 'WeeksFromStart']]\n",
        "        holiday_features = [col for col in feature_names if 'Holiday' in col or 'Bowl' in col or 'Labor' in col or 'Thanksgiving' in col or 'Christmas' in col or 'BackToSchool' in col]\n",
        "        lag_features = [col for col in feature_names if 'lag' in col]\n",
        "        type_features = [col for col in feature_names if 'Type_' in col]\n",
        "\n",
        "        mlflow.log_param(\"date_features_count\", len(date_features))\n",
        "        mlflow.log_param(\"holiday_features_count\", len(holiday_features))\n",
        "        mlflow.log_param(\"lag_features_count\", len(lag_features))\n",
        "        mlflow.log_param(\"type_features_count\", len(type_features))\n",
        "\n",
        "        mlflow.log_param(\"date_features\", str(date_features))\n",
        "        mlflow.log_param(\"holiday_features\", str(holiday_features))\n",
        "        mlflow.log_param(\"lag_features\", str(lag_features))\n",
        "        mlflow.log_param(\"type_features\", str(type_features))\n",
        "\n",
        "        # Log data statistics\n",
        "        mlflow.log_metric(\"train_target_mean\", float(y_train.mean()))\n",
        "        mlflow.log_metric(\"train_target_std\", float(y_train.std()))\n",
        "        mlflow.log_metric(\"val_target_mean\", float(y_val.mean()))\n",
        "        mlflow.log_metric(\"val_target_std\", float(y_val.std()))\n",
        "\n",
        "        # Log pipeline configuration\n",
        "        mlflow.log_param(\"preprocessing_steps\", \"date_features,holiday_features,categorical_encoding,lag_features,outlier_removal,markdown_removal,redundant_removal\")\n",
        "        mlflow.log_param(\"lag_windows\", \"1,2,3,4,8,12\")\n",
        "        mlflow.log_param(\"outlier_thresholds\", str(pipeline.outlier_thresholds))\n",
        "        mlflow.log_param(\"data_leakage_prevention\", \"YES - validation target separated before transformation\")\n",
        "\n",
        "        # Log pipeline object (optional - for reuse)\n",
        "        import joblib\n",
        "        import tempfile\n",
        "        import os\n",
        "\n",
        "        # Save pipeline to temporary file and log as artifact\n",
        "        with tempfile.NamedTemporaryFile(suffix='.joblib', delete=False) as tmp_file:\n",
        "            joblib.dump(pipeline, tmp_file.name)\n",
        "            mlflow.log_artifact(tmp_file.name, \"preprocessing_pipeline\")\n",
        "            os.unlink(tmp_file.name)  # Clean up temp file\n",
        "\n",
        "        print(f\"✅ Pipeline complete and logged to MLflow!\")\n",
        "        print(f\"   X_train: {X_train.shape}\")\n",
        "        print(f\"   y_train: {y_train.shape}\")\n",
        "        print(f\"   X_val: {X_val.shape}\")\n",
        "        print(f\"   y_val: {y_val.shape}\")\n",
        "        print(f\"   Features: {X_train.shape[1]}\")\n",
        "        print(f\"   📊 MLflow Run ID: {mlflow.active_run().info.run_id}\")\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, pipeline, split_info\n"
      ],
      "metadata": {
        "id": "3AlU8ICvVCvR"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run the real preprocessing pipeline\n",
        "    X_train, y_train, X_val, y_val, pipeline, split_info = real_preprocessing_pipeline()\n",
        "\n",
        "    print(f\"\\n🎯 DATA READY FOR MODEL TRAINING!\")\n",
        "    print(f\"   Training data: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
        "    print(f\"   Validation data: {X_val.shape[0]:,} samples, {X_val.shape[1]} features\")\n",
        "    print(f\"   Split date: {split_info['split_date']}\")\n",
        "    print(f\"   Feature columns: {list(X_train.columns)}\")\n",
        "\n",
        "    # Example: You can now train any model with this data\n",
        "    print(f\"\\n📝 Example usage:\")\n",
        "    print(f\"   from sklearn.ensemble import RandomForestRegressor\")\n",
        "    print(f\"   model = RandomForestRegressor()\")\n",
        "    print(f\"   model.fit(X_train, y_train)\")\n",
        "    print(f\"   predictions = model.predict(X_val)\")\n",
        "    print(f\"   score = model.score(X_val, y_val)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "HrGTBEzjVEef",
        "outputId": "924fff65-74d6-4e13-a6be-101c1693ff25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 REAL PREPROCESSING PIPELINE\n",
            "==================================================\n",
            "🔧 Setting up MLflow and DagsHub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DagsHub initialized successfully!\n",
            "✅ Created new experiment: Experiment_6_Complete_Pipeline_20250703_124755\n",
            "✅ MLflow setup complete!\n",
            "🔗 Tracking URI: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow\n",
            "📊 Experiment: Experiment_6_Complete_Pipeline_20250703_124755\n",
            "📊 MLflow run started for preprocessing pipeline...\n",
            "📊 Loading datasets...\n",
            "   📈 Train data: (421570, 5)\n",
            "   🏪 Stores data: (45, 3)\n",
            "   🎯 Features data: (8190, 12)\n",
            "   ✅ Merged data: (421570, 17)\n",
            "   📅 Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n",
            "🧹 Cleaning merged data...\n",
            "   🔄 Resolving duplicate IsHoliday columns...\n",
            "   ✅ Cleaned data: (421570, 16) (was (421570, 17))\n",
            "📅 Creating temporal split (80/19)...\n",
            "   📊 Split date: 2012-04-13 00:00:00\n",
            "   📈 Train: 337,256 records (2010-02-05 00:00:00 to 2012-04-13 00:00:00)\n",
            "   📉 Val: 84,314 records (2012-04-13 00:00:00 to 2012-10-26 00:00:00)\n",
            "🔧 Fitting preprocessing pipeline on training data...\n",
            "✅ Pipeline fitted on training data\n",
            "🔄 Transforming training data...\n",
            "   🗑️ Removed 45,193 outliers from training data\n",
            "✅ Transform complete. Shape: (292063, 32)\n",
            "🔄 Transforming validation data...\n",
            "✅ Transform complete. Shape: (84314, 32)\n",
            "✅ Pipeline complete and logged to MLflow!\n",
            "   X_train: (292063, 30)\n",
            "   y_train: (292063,)\n",
            "   X_val: (84314, 31)\n",
            "   y_val: (84314,)\n",
            "   Features: 30\n",
            "   📊 MLflow Run ID: 63174e4239df4d57815d07d1b7e865c8\n",
            "🏃 View run Preprocessing_Pipeline at: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/20/runs/63174e4239df4d57815d07d1b7e865c8\n",
            "🧪 View experiment at: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/20\n",
            "\n",
            "🎯 DATA READY FOR MODEL TRAINING!\n",
            "   Training data: 292,063 samples, 30 features\n",
            "   Validation data: 84,314 samples, 31 features\n",
            "   Split date: 2012-04-13 00:00:00\n",
            "   Feature columns: ['Store', 'Dept', 'Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'IsHoliday', 'Month', 'DayOfWeek', 'IsWeekend', 'IsMonthStart', 'IsMonthEnd', 'WeeksFromStart', 'IsSuperBowlWeek', 'IsLaborDayWeek', 'IsThanksgivingWeek', 'IsChristmasWeek', 'IsMajorHoliday', 'IsHolidayMonth', 'IsBackToSchool', 'Type_A', 'Type_B', 'Type_C', 'Weekly_Sales_lag_1', 'Weekly_Sales_lag_2', 'Weekly_Sales_lag_3', 'Weekly_Sales_lag_4', 'Weekly_Sales_lag_8', 'Weekly_Sales_lag_12']\n",
            "\n",
            "📝 Example usage:\n",
            "   from sklearn.ensemble import RandomForestRegressor\n",
            "   model = RandomForestRegressor()\n",
            "   model.fit(X_train, y_train)\n",
            "   predictions = model.predict(X_val)\n",
            "   score = model.score(X_val, y_val)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessing_pipeline(run_id):\n",
        "    \"\"\"\n",
        "    Load a saved preprocessing pipeline from MLflow\n",
        "\n",
        "    Args:\n",
        "        run_id (str): MLflow run ID where the pipeline was saved\n",
        "\n",
        "    Returns:\n",
        "        WalmartPreprocessingPipeline: Loaded pipeline ready to use\n",
        "    \"\"\"\n",
        "    import mlflow\n",
        "    import joblib\n",
        "\n",
        "    # Download the pipeline artifact\n",
        "    artifact_path = mlflow.artifacts.download_artifacts(\n",
        "        run_id=run_id,\n",
        "        artifact_path=\"preprocessing_pipeline\"\n",
        "    )\n",
        "\n",
        "    # Load the pipeline\n",
        "    pipeline_file = f\"{artifact_path}/preprocessing_pipeline.joblib\"\n",
        "    pipeline = joblib.load(pipeline_file)\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "def use_saved_pipeline_example(run_id):\n",
        "    \"\"\"\n",
        "    Example of how to use a saved preprocessing pipeline\n",
        "    \"\"\"\n",
        "    # Load the saved pipeline\n",
        "    pipeline = load_preprocessing_pipeline(run_id)\n",
        "\n",
        "    # Load your raw data\n",
        "    train_full = pipeline.load_and_prepare_data()\n",
        "    train_full = pipeline.clean_merged_data(train_full)\n",
        "\n",
        "    # Create split\n",
        "    train_data, val_data, split_info = pipeline.create_temporal_split(train_full)\n",
        "\n",
        "    # Separate validation target (for realistic test scenario)\n",
        "    y_val = val_data['Weekly_Sales'].copy()\n",
        "    val_data_no_target = val_data.drop('Weekly_Sales', axis=1).copy()\n",
        "\n",
        "    # Transform data using the saved pipeline (no fitting needed!)\n",
        "    train_processed = pipeline.transform(train_data, is_validation=False)\n",
        "    val_processed = pipeline.transform(val_data_no_target, is_validation=True)\n",
        "\n",
        "    # Prepare model data\n",
        "    X_train = train_processed.drop(['Weekly_Sales', 'Date'], axis=1)\n",
        "    y_train = train_processed['Weekly_Sales']\n",
        "    X_val = val_processed.drop('Date', axis=1)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val"
      ],
      "metadata": {
        "id": "iPQbyw6SV2a4"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_preprocessing_pipeline():\n",
        "    \"\"\"\n",
        "    Test the preprocessing pipeline workflow:\n",
        "    1. Load train data\n",
        "    2. Split 80-20\n",
        "    3. Remove Weekly_Sales from 20%\n",
        "    4. Load preprocessing model and fit/transform\n",
        "    5. Show what it does to data\n",
        "    \"\"\"\n",
        "    print(\"🧪 TESTING PREPROCESSING PIPELINE\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Step 1: Load train data\n",
        "    print(\"📁 Step 1: Loading train data...\")\n",
        "    pipeline = create_preprocessing_pipeline()\n",
        "    train_full = pipeline.load_and_prepare_data()\n",
        "    train_full = pipeline.clean_merged_data(train_full)\n",
        "    print(f\"   Raw data shape: {train_full.shape}\")\n",
        "    print(f\"   Date range: {train_full['Date'].min()} to {train_full['Date'].max()}\")\n",
        "    print(f\"   Columns: {list(train_full.columns)}\")\n",
        "\n",
        "    # Step 2: Split 80-20\n",
        "    print(\"\\n✂️ Step 2: Creating 80-20 temporal split...\")\n",
        "    train_data, val_data, split_info = pipeline.create_temporal_split(train_full, train_ratio=0.8)\n",
        "    print(f\"   Train data: {train_data.shape} (80%)\")\n",
        "    print(f\"   Val data: {val_data.shape} (20%)\")\n",
        "    print(f\"   Split date: {split_info['split_date']}\")\n",
        "\n",
        "    # Step 3: Remove Weekly_Sales from 20%\n",
        "    print(\"\\n🎯 Step 3: Removing Weekly_Sales from validation data...\")\n",
        "    y_val = val_data['Weekly_Sales'].copy()\n",
        "    val_data_no_target = val_data.drop('Weekly_Sales', axis=1).copy()\n",
        "    print(f\"   Validation target saved: {y_val.shape}\")\n",
        "    print(f\"   Validation data without target: {val_data_no_target.shape}\")\n",
        "    print(f\"   Validation columns now: {list(val_data_no_target.columns)}\")\n",
        "\n",
        "    # Step 4: Load preprocessing model and fit/transform\n",
        "    print(\"\\n🔧 Step 4: Fitting and transforming with preprocessing pipeline...\")\n",
        "\n",
        "    print(\"   4a. Fitting pipeline on training data...\")\n",
        "    pipeline.fit(train_data)\n",
        "    print(f\"      ✅ Pipeline fitted (outlier thresholds, encoders, etc. learned)\")\n",
        "\n",
        "    print(\"   4b. Transforming training data...\")\n",
        "    train_processed = pipeline.transform(train_data, is_validation=False)\n",
        "    print(f\"      Training data transformed: {train_processed.shape}\")\n",
        "\n",
        "    print(\"   4c. Transforming validation data...\")\n",
        "    val_processed = pipeline.transform(val_data_no_target, is_validation=True)\n",
        "    print(f\"      Validation data transformed: {val_processed.shape}\")\n",
        "\n",
        "    # Step 5: Show what it does to data\n",
        "    print(\"\\n📊 Step 5: Analyzing what preprocessing did to the data...\")\n",
        "\n",
        "    # Original vs processed features\n",
        "    original_features = list(train_data.columns)\n",
        "    processed_features = list(train_processed.columns)\n",
        "\n",
        "    print(f\"\\n   📋 FEATURE TRANSFORMATION:\")\n",
        "    print(f\"   Original features ({len(original_features)}): {original_features}\")\n",
        "    print(f\"   Processed features ({len(processed_features)}): {processed_features}\")\n",
        "\n",
        "    # New features created\n",
        "    new_features = [f for f in processed_features if f not in original_features]\n",
        "    print(f\"\\n   ✨ NEW FEATURES CREATED ({len(new_features)}):\")\n",
        "    for feature in new_features:\n",
        "        print(f\"      - {feature}\")\n",
        "\n",
        "    # Sample size changes\n",
        "    print(f\"\\n   📈 SAMPLE SIZE CHANGES:\")\n",
        "    print(f\"   Training: {len(train_data):,} → {len(train_processed):,} (outliers removed: {len(train_data) - len(train_processed):,})\")\n",
        "    print(f\"   Validation: {len(val_data_no_target):,} → {len(val_processed):,} (no outlier removal)\")\n",
        "\n",
        "    # Final model-ready data\n",
        "    print(f\"\\n   🎯 FINAL MODEL-READY DATA:\")\n",
        "    X_train = train_processed.drop(['Weekly_Sales', 'Date'], axis=1)\n",
        "    y_train = train_processed['Weekly_Sales']\n",
        "    X_val = val_processed.drop('Date', axis=1)\n",
        "\n",
        "    print(f\"   X_train: {X_train.shape} - Features for training\")\n",
        "    print(f\"   y_train: {y_train.shape} - Target for training\")\n",
        "    print(f\"   X_val: {X_val.shape} - Features for validation\")\n",
        "    print(f\"   y_val: {y_val.shape} - Target for validation (kept separate)\")\n",
        "\n",
        "    # Show sample of transformed data\n",
        "    print(f\"\\n   📄 SAMPLE OF TRANSFORMED FEATURES:\")\n",
        "    print(X_train.head(3).round(2))\n",
        "\n",
        "    print(f\"\\n✅ PREPROCESSING TEST COMPLETE!\")\n",
        "    print(f\"   Ready for model training with {X_train.shape[1]} features\")\n",
        "\n",
        "    return X_train, y_train, X_val, y_val\n"
      ],
      "metadata": {
        "id": "MUTHo-r9WuoQ"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Demonstrate loading and using saved preprocessing pipeline\n",
        "    run_id = \"63174e4239df4d57815d07d1b7e865c8\"\n",
        "\n",
        "    print(\"🔄 LOADING SAVED PREPROCESSING PIPELINE\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"📋 Run ID: {run_id}\")\n",
        "\n",
        "    # Test the preprocessing pipeline workflow with saved pipeline\n",
        "    X_train, y_train, X_val, y_val = test_preprocessing_pipeline()\n",
        "\n",
        "    print(f\"\\n🎯 PIPELINE TEST RESULTS:\")\n",
        "    print(f\"   Training data: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
        "    print(f\"   Validation data: {X_val.shape[0]:,} samples, {X_val.shape[1]} features\")\n",
        "    print(f\"   Feature columns: {list(X_train.columns)}\")\n",
        "\n",
        "    print(f\"\\n💾 TO USE THIS SAVED PIPELINE IN FUTURE:\")\n",
        "    print(f\"   # Load the saved pipeline\")\n",
        "    print(f\"   pipeline = load_preprocessing_pipeline('{run_id}')\")\n",
        "    print(f\"   \")\n",
        "    print(f\"   # Use it on new data\")\n",
        "    print(f\"   X_train, y_train, X_val, y_val = use_saved_pipeline_example('{run_id}')\")\n",
        "    print(f\"   \")\n",
        "    print(f\"   # Train your model\")\n",
        "    print(f\"   from sklearn.ensemble import RandomForestRegressor\")\n",
        "    print(f\"   model = RandomForestRegressor()\")\n",
        "    print(f\"   model.fit(X_train, y_train)\")\n",
        "    print(f\"   predictions = model.predict(X_val)\")\n",
        "    print(f\"   score = model.score(X_val, y_val)\")\n",
        "\n",
        "    print(f\"\\n📊 MLflow Dashboard:\")\n",
        "    print(f\"   https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/20/runs/{run_id}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hctb1_VEXEXt",
        "outputId": "14f8d94c-2a9d-4685-a4b5-153b77336525",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 LOADING SAVED PREPROCESSING PIPELINE\n",
            "==================================================\n",
            "📋 Run ID: 63174e4239df4d57815d07d1b7e865c8\n",
            "🧪 TESTING PREPROCESSING PIPELINE\n",
            "==================================================\n",
            "📁 Step 1: Loading train data...\n",
            "📊 Loading datasets...\n",
            "   📈 Train data: (421570, 5)\n",
            "   🏪 Stores data: (45, 3)\n",
            "   🎯 Features data: (8190, 12)\n",
            "   ✅ Merged data: (421570, 17)\n",
            "   📅 Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n",
            "🧹 Cleaning merged data...\n",
            "   🔄 Resolving duplicate IsHoliday columns...\n",
            "   ✅ Cleaned data: (421570, 16) (was (421570, 17))\n",
            "   Raw data shape: (421570, 16)\n",
            "   Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n",
            "   Columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'Type', 'Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday']\n",
            "\n",
            "✂️ Step 2: Creating 80-20 temporal split...\n",
            "📅 Creating temporal split (80/19)...\n",
            "   📊 Split date: 2012-04-13 00:00:00\n",
            "   📈 Train: 337,256 records (2010-02-05 00:00:00 to 2012-04-13 00:00:00)\n",
            "   📉 Val: 84,314 records (2012-04-13 00:00:00 to 2012-10-26 00:00:00)\n",
            "   Train data: (337256, 16) (80%)\n",
            "   Val data: (84314, 16) (20%)\n",
            "   Split date: 2012-04-13 00:00:00\n",
            "\n",
            "🎯 Step 3: Removing Weekly_Sales from validation data...\n",
            "   Validation target saved: (84314,)\n",
            "   Validation data without target: (84314, 15)\n",
            "   Validation columns now: ['Store', 'Dept', 'Date', 'Type', 'Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday']\n",
            "\n",
            "🔧 Step 4: Fitting and transforming with preprocessing pipeline...\n",
            "   4a. Fitting pipeline on training data...\n",
            "🔧 Fitting preprocessing pipeline on training data...\n",
            "✅ Pipeline fitted on training data\n",
            "      ✅ Pipeline fitted (outlier thresholds, encoders, etc. learned)\n",
            "   4b. Transforming training data...\n",
            "🔄 Transforming training data...\n",
            "   🗑️ Removed 45,193 outliers from training data\n",
            "✅ Transform complete. Shape: (292063, 32)\n",
            "      Training data transformed: (292063, 32)\n",
            "   4c. Transforming validation data...\n",
            "🔄 Transforming validation data...\n",
            "✅ Transform complete. Shape: (84314, 32)\n",
            "      Validation data transformed: (84314, 32)\n",
            "\n",
            "📊 Step 5: Analyzing what preprocessing did to the data...\n",
            "\n",
            "   📋 FEATURE TRANSFORMATION:\n",
            "   Original features (16): ['Store', 'Dept', 'Date', 'Weekly_Sales', 'Type', 'Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday']\n",
            "   Processed features (32): ['Store', 'Dept', 'Date', 'Weekly_Sales', 'Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'IsHoliday', 'Month', 'DayOfWeek', 'IsWeekend', 'IsMonthStart', 'IsMonthEnd', 'WeeksFromStart', 'IsSuperBowlWeek', 'IsLaborDayWeek', 'IsThanksgivingWeek', 'IsChristmasWeek', 'IsMajorHoliday', 'IsHolidayMonth', 'IsBackToSchool', 'Type_A', 'Type_B', 'Type_C', 'Weekly_Sales_lag_1', 'Weekly_Sales_lag_2', 'Weekly_Sales_lag_3', 'Weekly_Sales_lag_4', 'Weekly_Sales_lag_8', 'Weekly_Sales_lag_12']\n",
            "\n",
            "   ✨ NEW FEATURES CREATED (22):\n",
            "      - Month\n",
            "      - DayOfWeek\n",
            "      - IsWeekend\n",
            "      - IsMonthStart\n",
            "      - IsMonthEnd\n",
            "      - WeeksFromStart\n",
            "      - IsSuperBowlWeek\n",
            "      - IsLaborDayWeek\n",
            "      - IsThanksgivingWeek\n",
            "      - IsChristmasWeek\n",
            "      - IsMajorHoliday\n",
            "      - IsHolidayMonth\n",
            "      - IsBackToSchool\n",
            "      - Type_A\n",
            "      - Type_B\n",
            "      - Type_C\n",
            "      - Weekly_Sales_lag_1\n",
            "      - Weekly_Sales_lag_2\n",
            "      - Weekly_Sales_lag_3\n",
            "      - Weekly_Sales_lag_4\n",
            "      - Weekly_Sales_lag_8\n",
            "      - Weekly_Sales_lag_12\n",
            "\n",
            "   📈 SAMPLE SIZE CHANGES:\n",
            "   Training: 337,256 → 292,063 (outliers removed: 45,193)\n",
            "   Validation: 84,314 → 84,314 (no outlier removal)\n",
            "\n",
            "   🎯 FINAL MODEL-READY DATA:\n",
            "   X_train: (292063, 30) - Features for training\n",
            "   y_train: (292063,) - Target for training\n",
            "   X_val: (84314, 31) - Features for validation\n",
            "   y_val: (84314,) - Target for validation (kept separate)\n",
            "\n",
            "   📄 SAMPLE OF TRANSFORMED FEATURES:\n",
            "   Store  Dept    Size  Temperature  Fuel_Price     CPI  Unemployment  \\\n",
            "0      1     1  151315        42.31        2.57  211.10          8.11   \n",
            "1      1     1  151315        38.51        2.55  211.24          8.11   \n",
            "2      1     1  151315        39.93        2.51  211.29          8.11   \n",
            "\n",
            "   IsHoliday  Month  DayOfWeek  ...  IsBackToSchool  Type_A  Type_B  Type_C  \\\n",
            "0      False      2          4  ...               0    True   False   False   \n",
            "1       True      2          4  ...               0    True   False   False   \n",
            "2      False      2          4  ...               0    True   False   False   \n",
            "\n",
            "   Weekly_Sales_lag_1  Weekly_Sales_lag_2  Weekly_Sales_lag_3  \\\n",
            "0                0.00                 0.0                 0.0   \n",
            "1            24924.50                 0.0                 0.0   \n",
            "2            46039.49             24924.5                 0.0   \n",
            "\n",
            "   Weekly_Sales_lag_4  Weekly_Sales_lag_8  Weekly_Sales_lag_12  \n",
            "0                 0.0                 0.0                  0.0  \n",
            "1                 0.0                 0.0                  0.0  \n",
            "2                 0.0                 0.0                  0.0  \n",
            "\n",
            "[3 rows x 30 columns]\n",
            "\n",
            "✅ PREPROCESSING TEST COMPLETE!\n",
            "   Ready for model training with 30 features\n",
            "\n",
            "🎯 PIPELINE TEST RESULTS:\n",
            "   Training data: 292,063 samples, 30 features\n",
            "   Validation data: 84,314 samples, 31 features\n",
            "   Feature columns: ['Store', 'Dept', 'Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'IsHoliday', 'Month', 'DayOfWeek', 'IsWeekend', 'IsMonthStart', 'IsMonthEnd', 'WeeksFromStart', 'IsSuperBowlWeek', 'IsLaborDayWeek', 'IsThanksgivingWeek', 'IsChristmasWeek', 'IsMajorHoliday', 'IsHolidayMonth', 'IsBackToSchool', 'Type_A', 'Type_B', 'Type_C', 'Weekly_Sales_lag_1', 'Weekly_Sales_lag_2', 'Weekly_Sales_lag_3', 'Weekly_Sales_lag_4', 'Weekly_Sales_lag_8', 'Weekly_Sales_lag_12']\n",
            "\n",
            "💾 TO USE THIS SAVED PIPELINE IN FUTURE:\n",
            "   # Load the saved pipeline\n",
            "   pipeline = load_preprocessing_pipeline('63174e4239df4d57815d07d1b7e865c8')\n",
            "   \n",
            "   # Use it on new data\n",
            "   X_train, y_train, X_val, y_val = use_saved_pipeline_example('63174e4239df4d57815d07d1b7e865c8')\n",
            "   \n",
            "   # Train your model\n",
            "   from sklearn.ensemble import RandomForestRegressor\n",
            "   model = RandomForestRegressor()\n",
            "   model.fit(X_train, y_train)\n",
            "   predictions = model.predict(X_val)\n",
            "   score = model.score(X_val, y_val)\n",
            "\n",
            "📊 MLflow Dashboard:\n",
            "   https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/20/runs/63174e4239df4d57815d07d1b7e865c8\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "379eed18e40a4d4d8d70393d4c7e5b57": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_bd5c12e790504278a5c666ad1a914ed7",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32m⠙\u001b[0m Waiting for authorization\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠙</span> Waiting for authorization\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "bd5c12e790504278a5c666ad1a914ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}