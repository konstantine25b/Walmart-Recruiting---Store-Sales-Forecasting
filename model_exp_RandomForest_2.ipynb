{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMOjz1d4XzRqp8wgEAyxuqw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting/blob/lodia/model_exp_RandomForest_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEZ8FY0CwPki",
        "outputId": "0106c0a1-bdcc-45bf-ee76-2dd5b36436fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq5fIaugwScY",
        "outputId": "d5b60641-3653-4f2f-ce89-4b24777b4d26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "-liCye9VwUc_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "3yVKvQmNwWV1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "NOgNnzXiwYHn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c walmart-recruiting-store-sales-forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFwaHbKJwZ0f",
        "outputId": "b02e1cdc-dea1-4d7c-f15e-d8350863c367"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading walmart-recruiting-store-sales-forecasting.zip to /content\n",
            "\r  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "\r100% 2.70M/2.70M [00:00<00:00, 1.02GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip walmart-recruiting-store-sales-forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK2Kc2vQwbkd",
        "outputId": "9d280955-cf15-4022-d46f-5aecb2d38af7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  walmart-recruiting-store-sales-forecasting.zip\n",
            "  inflating: features.csv.zip        \n",
            "  inflating: sampleSubmission.csv.zip  \n",
            "  inflating: stores.csv              \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "path = \"/content/\"\n",
        "\n",
        "\n",
        "files_to_unzip = [\n",
        "    \"features.csv.zip\",\n",
        "    \"test.csv.zip\",\n",
        "    \"train.csv.zip\",\n",
        "    \"sampleSubmission.csv.zip\"\n",
        "]\n",
        "\n",
        "print(\"Checking and unzipping individual files...\")\n",
        "for file_name in files_to_unzip:\n",
        "    full_path = os.path.join(path, file_name)\n",
        "    if os.path.exists(full_path):\n",
        "        try:\n",
        "            with zipfile.ZipFile(full_path, 'r') as zip_ref:\n",
        "\n",
        "                zip_ref.extractall(path)\n",
        "            print(f\"Successfully unzipped: {file_name}\")\n",
        "\n",
        "        except zipfile.BadZipFile:\n",
        "            print(f\"Warning: {file_name} is not a valid zip file or already unzipped/corrupted.\")\n",
        "    else:\n",
        "        print(f\"Info: {file_name} not found, likely already unzipped or not present.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN4OnSjvw9K_",
        "outputId": "6eefc7d8-9f26-429e-c427-f905088a30c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking and unzipping individual files...\n",
            "Successfully unzipped: features.csv.zip\n",
            "Successfully unzipped: test.csv.zip\n",
            "Successfully unzipped: train.csv.zip\n",
            "Successfully unzipped: sampleSubmission.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    train_df = pd.read_csv(path + \"train.csv\")\n",
        "    test_df = pd.read_csv(path + \"test.csv\")\n",
        "    features_df = pd.read_csv(path + \"features.csv\")\n",
        "    stores_df = pd.read_csv(path + \"stores.csv\")\n",
        "    print(\"All datasets loaded successfully!\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading file: {e}. Please check the 'path' variable.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSFCbsTSxBdw",
        "outputId": "f1196aba-13e4-47e7-87ec-a71d9ad02361"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All datasets loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
        "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
        "features_df['Date'] = pd.to_datetime(features_df['Date'])"
      ],
      "metadata": {
        "id": "pnYROTcXxGuc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged = pd.merge(train_df, features_df, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "train_merged = pd.merge(train_merged, stores_df, on=['Store'], how='left')"
      ],
      "metadata": {
        "id": "HbFKIpR6xO9i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_merged = pd.merge(test_df, features_df, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "test_merged = pd.merge(test_merged, stores_df, on=['Store'], how='left')"
      ],
      "metadata": {
        "id": "PIZdc9BOxW3h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape:\", train_merged.shape)\n",
        "print(\"\\n--- Merged Training Data Sample ---\")\n",
        "print(train_merged.head())\n",
        "print(\"\\nMissing values in merged train data after initial merge:\")\n",
        "print(train_merged.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaDvdVHgxb_H",
        "outputId": "0ca97e40-14c0-441d-a722-6a2ea8a5be22"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (421570, 16)\n",
            "\n",
            "--- Merged Training Data Sample ---\n",
            "   Store  Dept       Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
            "0      1     1 2010-02-05      24924.50      False        42.31       2.572   \n",
            "1      1     1 2010-02-12      46039.49       True        38.51       2.548   \n",
            "2      1     1 2010-02-19      41595.55      False        39.93       2.514   \n",
            "3      1     1 2010-02-26      19403.54      False        46.63       2.561   \n",
            "4      1     1 2010-03-05      21827.90      False        46.50       2.625   \n",
            "\n",
            "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
            "0        NaN        NaN        NaN        NaN        NaN  211.096358   \n",
            "1        NaN        NaN        NaN        NaN        NaN  211.242170   \n",
            "2        NaN        NaN        NaN        NaN        NaN  211.289143   \n",
            "3        NaN        NaN        NaN        NaN        NaN  211.319643   \n",
            "4        NaN        NaN        NaN        NaN        NaN  211.350143   \n",
            "\n",
            "   Unemployment Type    Size  \n",
            "0         8.106    A  151315  \n",
            "1         8.106    A  151315  \n",
            "2         8.106    A  151315  \n",
            "3         8.106    A  151315  \n",
            "4         8.106    A  151315  \n",
            "\n",
            "Missing values in merged train data after initial merge:\n",
            "Store                0\n",
            "Dept                 0\n",
            "Date                 0\n",
            "Weekly_Sales         0\n",
            "IsHoliday            0\n",
            "Temperature          0\n",
            "Fuel_Price           0\n",
            "MarkDown1       270889\n",
            "MarkDown2       310322\n",
            "MarkDown3       284479\n",
            "MarkDown4       286603\n",
            "MarkDown5       270138\n",
            "CPI                  0\n",
            "Unemployment         0\n",
            "Type                 0\n",
            "Size                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error # For basic MAE\n",
        "import warnings\n",
        "\n",
        "# Suppress pandas FutureWarnings related to .loc[] with boolean indexing\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "# --- WMAE Custom Metric Function ---\n",
        "def weighted_mean_absolute_error(y_true, y_pred, is_holiday_flag):\n",
        "    weights = np.where(is_holiday_flag, 5, 1) # 5 for holiday, 1 for non-holiday\n",
        "    y_pred = np.maximum(0, y_pred) # Ensure predictions are non-negative\n",
        "    return np.sum(weights * np.abs(y_true - y_pred)) / np.sum(weights)"
      ],
      "metadata": {
        "id": "vHoRA3tcxhwq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting Random Forest Model Improvement Process...\")\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    if 'train_df' not in locals() or 'features_df' not in locals() or 'stores_df' not in locals():\n",
        "        print(\"Raw dataframes not found in current session. Attempting to load from '/' path.\")\n",
        "        path = \"/\"\n",
        "        train_df = pd.read_csv(path + \"train.csv\")\n",
        "        test_df = pd.read_csv(path + \"test.csv\")\n",
        "        features_df = pd.read_csv(path + \"features.csv\")\n",
        "        stores_df = pd.read_csv(path + \"stores.csv\")\n",
        "        print(\"Raw datasets reloaded successfully!\")\n",
        "\n",
        "    train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
        "    features_df['Date'] = pd.to_datetime(features_df['Date'])\n",
        "\n",
        "    train_merged = pd.merge(train_df, features_df, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "    train_merged = pd.merge(train_merged, stores_df, on=['Store'], how='left')\n",
        "    print(\"train_merged created successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error re-loading or merging dataframes: {e}. Please ensure original CSVs are accessible.\")\n",
        "    # Exit or handle appropriately if dataframes can't be loaded\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf5AIhibx1XW",
        "outputId": "798b5368-9bb6-410c-dc45-e23d45639ccf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Random Forest Model Improvement Process...\n",
            "train_merged created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged = train_merged.sort_values(by=['Store', 'Dept', 'Date']).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "blY_lnIc1Vpm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Preprocessing & Feature Engineering (Improved) ---\")\n",
        "\n",
        "# 1. Handle Negative Weekly_Sales in training data\n",
        "train_merged['Weekly_Sales'] = train_merged['Weekly_Sales'].apply(lambda x: max(0, x))\n",
        "print(\"Handled negative Weekly_Sales by setting them to 0 in training data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb9Cx83_1WKa",
        "outputId": "d891b95a-1bdd-4de1-ee18-b53a01765625"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Preprocessing & Feature Engineering (Improved) ---\n",
            "Handled negative Weekly_Sales by setting them to 0 in training data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Date Feature Engineering\n",
        "def create_date_features(df):\n",
        "    df['Year'] = df['Date'].dt.year\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "    df['Week'] = df['Date'].dt.isocalendar().week.astype(int) # Week of the year\n",
        "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "    df['DayOfYear'] = df['Date'].dt.dayofyear\n",
        "    df['IsMonthStart'] = df['Date'].dt.is_month_start.astype(int)\n",
        "    df['IsMonthEnd'] = df['Date'].dt.is_month_end.astype(int)\n",
        "    df['TimeIdx'] = (df['Date'] - df['Date'].min()).dt.days\n",
        "\n",
        "\n",
        "    # The 'IsHoliday' flag itself is already a strong feature.\n",
        "\n",
        "    return df\n",
        "\n",
        "train_merged = create_date_features(train_merged)\n",
        "print(\"Created date-based features.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kwxTdoH1fkO",
        "outputId": "bdd55be9-2c1b-45e8-92f1-4ecd496c854c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created date-based features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Handle Missing Values for MarkDowns\n",
        "markdown_cols = [f'MarkDown{i}' for i in range(1, 6)]\n",
        "for col in markdown_cols:\n",
        "    train_merged[col] = train_merged[col].fillna(0)\n",
        "print(\"Filled NaN values in MarkDown columns with 0.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7v0wtch0OgG",
        "outputId": "84c9f9b1-b88f-4fcf-d18c-8f4ffd607577"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filled NaN values in MarkDown columns with 0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_merged.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clSujDan1q_w",
        "outputId": "2a54d8fc-e332-45ed-bd4a-a605163398c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Store  Dept       Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
            "0      1     1 2010-02-05      24924.50      False        42.31       2.572   \n",
            "1      1     1 2010-02-12      46039.49       True        38.51       2.548   \n",
            "2      1     1 2010-02-19      41595.55      False        39.93       2.514   \n",
            "3      1     1 2010-02-26      19403.54      False        46.63       2.561   \n",
            "4      1     1 2010-03-05      21827.90      False        46.50       2.625   \n",
            "\n",
            "   MarkDown1  MarkDown2  MarkDown3  ...  Type    Size  Year  Month Week  \\\n",
            "0        0.0        0.0        0.0  ...     A  151315  2010      2    5   \n",
            "1        0.0        0.0        0.0  ...     A  151315  2010      2    6   \n",
            "2        0.0        0.0        0.0  ...     A  151315  2010      2    7   \n",
            "3        0.0        0.0        0.0  ...     A  151315  2010      2    8   \n",
            "4        0.0        0.0        0.0  ...     A  151315  2010      3    9   \n",
            "\n",
            "   DayOfWeek  DayOfYear  IsMonthStart  IsMonthEnd  TimeIdx  \n",
            "0          4         36             0           0        0  \n",
            "1          4         43             0           0        7  \n",
            "2          4         50             0           0       14  \n",
            "3          4         57             0           0       21  \n",
            "4          4         64             0           0       28  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Handle Missing Values for CPI and Unemployment (Teammate's observation about features.csv complexity)\n",
        "# Use ffill/bfill within each Store group, then fallback to median for robustness.\n",
        "print(\"Handling NaN values for CPI and Unemployment (using ffill/bfill per store, then median fallback)...\")\n",
        "train_merged['CPI'] = train_merged.groupby('Store')['CPI'].ffill().bfill()\n",
        "train_merged['Unemployment'] = train_merged.groupby('Store')['Unemployment'].ffill().bfill()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za5n0jF0RbvW",
        "outputId": "1aab0030-d42c-4083-d191-7fd0e9d4fbb6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Handling NaN values for CPI and Unemployment (using ffill/bfill per store, then median fallback)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fallback to global median for any remaining NaNs (e.g., if an entire store's CPI/Unemployment was NaN)\n",
        "train_merged['CPI'] = train_merged['CPI'].fillna(train_merged['CPI'].median())\n",
        "train_merged['Unemployment'] = train_merged['Unemployment'].fillna(train_merged['Unemployment'].median())\n",
        "print(\"Filled NaN values in CPI and Unemployment columns.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4Gh_xh7Rci6",
        "outputId": "57047701-ac2c-4bc0-a67f-0a34d435fa9b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filled NaN values in CPI and Unemployment columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Create Lagged and Rolling Mean Features\n",
        "print(\"Creating lagged and rolling mean features (this might take a few moments)...\")\n",
        "\n",
        "# Sort again just to be sure, critical for lags\n",
        "train_merged = train_merged.sort_values(by=['Store', 'Dept', 'Date'])\n",
        "\n",
        "# Lag 1: Sales from the previous week for the same Store and Dept\n",
        "# Ensure to apply on the 'Weekly_Sales' column AFTER negative sales have been handled\n",
        "train_merged['Lag_Weekly_Sales'] = train_merged.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(1)\n",
        "\n",
        "# Lag 52: Sales from the same week in the previous year (annual seasonality)\n",
        "train_merged['Lag52_Weekly_Sales'] = train_merged.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(52)\n",
        "\n",
        "# Rolling Mean: Average sales over the last 4 weeks (shifted to avoid data leakage)\n",
        "train_merged['RollingMean_4W_Sales'] = train_merged.groupby(['Store', 'Dept'])['Weekly_Sales'].transform(\n",
        "    lambda x: x.shift(1).rolling(window=4, min_periods=1).mean()\n",
        ")\n",
        "\n",
        "# Rolling Std: Standard deviation of sales over the last 4 weeks (shifted)\n",
        "train_merged['RollingStd_4W_Sales'] = train_merged.groupby(['Store', 'Dept'])['Weekly_Sales'].transform(\n",
        "    lambda x: x.shift(1).rolling(window=4, min_periods=1).std()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k81eHPvc1yiT",
        "outputId": "b3da75b7-2791-4c4a-b2b1-20a71ef20b44"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating lagged and rolling mean features (this might take a few moments)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill NaNs created by lagging (for first few weeks of each series)\n",
        "# Use 0 or a reasonable default, depending on how you want the model to interpret \"no past sales\".\n",
        "train_merged['Lag_Weekly_Sales'] = train_merged['Lag_Weekly_Sales'].fillna(0)\n",
        "train_merged['Lag52_Weekly_Sales'] = train_merged['Lag52_Weekly_Sales'].fillna(0)\n",
        "train_merged['RollingMean_4W_Sales'] = train_merged['RollingMean_4W_Sales'].fillna(0)\n",
        "train_merged['RollingStd_4W_Sales'] = train_merged['RollingStd_4W_Sales'].fillna(0)\n",
        "print(\"Lagged and rolling mean/std features created and NaNs filled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r88rK1UK2MOC",
        "outputId": "3f13795c-4187-4d82-fb90-b286a430cb25"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lagged and rolling mean/std features created and NaNs filled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Define features and target before splitting\n",
        "# IMPORTANT: Now include 'IsHoliday' and the new lagged/rolling features in 'numerical_features'\n",
        "X = train_merged.drop(columns=['Weekly_Sales', 'Date']) # Date is dropped after features are extracted\n",
        "y = train_merged['Weekly_Sales']\n",
        "is_holiday_flags = train_merged['IsHoliday'] # Store for WMAE calculation"
      ],
      "metadata": {
        "id": "oScL3O-52bsa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_merged.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zXMpTiH2ont",
        "outputId": "43153429-b529-450b-c5d0-abe966ed939a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Store  Dept       Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
            "0      1     1 2010-02-05      24924.50      False        42.31       2.572   \n",
            "1      1     1 2010-02-12      46039.49       True        38.51       2.548   \n",
            "2      1     1 2010-02-19      41595.55      False        39.93       2.514   \n",
            "3      1     1 2010-02-26      19403.54      False        46.63       2.561   \n",
            "4      1     1 2010-03-05      21827.90      False        46.50       2.625   \n",
            "\n",
            "   MarkDown1  MarkDown2  MarkDown3  ...  Week  DayOfWeek  DayOfYear  \\\n",
            "0        0.0        0.0        0.0  ...     5          4         36   \n",
            "1        0.0        0.0        0.0  ...     6          4         43   \n",
            "2        0.0        0.0        0.0  ...     7          4         50   \n",
            "3        0.0        0.0        0.0  ...     8          4         57   \n",
            "4        0.0        0.0        0.0  ...     9          4         64   \n",
            "\n",
            "   IsMonthStart IsMonthEnd  TimeIdx  Lag_Weekly_Sales  Lag52_Weekly_Sales  \\\n",
            "0             0          0        0              0.00                 0.0   \n",
            "1             0          0        7          24924.50                 0.0   \n",
            "2             0          0       14          46039.49                 0.0   \n",
            "3             0          0       21          41595.55                 0.0   \n",
            "4             0          0       28          19403.54                 0.0   \n",
            "\n",
            "   RollingMean_4W_Sales  RollingStd_4W_Sales  \n",
            "0              0.000000             0.000000  \n",
            "1          24924.500000             0.000000  \n",
            "2          35481.995000         14930.552614  \n",
            "3          37519.846667         11131.900957  \n",
            "4          32990.770000         12832.106391  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Categorical & Numerical Feature Definitions for Preprocessor\n",
        "categorical_features = ['Type']\n",
        "numerical_features = ['Store', 'Dept', 'Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment'] + \\\n",
        "                     markdown_cols + \\\n",
        "                     ['Year', 'Month', 'Week', 'DayOfWeek', 'DayOfYear', 'IsMonthStart', 'IsMonthEnd', 'TimeIdx'] + \\\n",
        "                     ['IsHoliday', 'Lag_Weekly_Sales', 'Lag52_Weekly_Sales', 'RollingMean_4W_Sales', 'RollingStd_4W_Sales'] # <-- New features included!\n"
      ],
      "metadata": {
        "id": "XDkI7hnE2z9A"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ],\n",
        "    remainder='drop' # Drop any other columns not specified\n",
        ")\n",
        "print(\"Defined preprocessor for categorical encoding and updated numerical features.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJCHB0PA2_TD",
        "outputId": "c8b8f566-69fb-4da0-a8d9-930a72501e11"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined preprocessor for categorical encoding and updated numerical features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ],\n",
        "    remainder='drop' # Drop any other columns not specified\n",
        ")\n",
        "print(\"Defined preprocessor for categorical encoding and updated numerical features.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61wPI7b43L3_",
        "outputId": "4bfe53a4-7bbb-4965-e463-9d9abbad4651"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined preprocessor for categorical encoding and updated numerical features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_merged.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF37SZaR3OIh",
        "outputId": "d4242197-c1f4-4e28-b74c-38bf733d2212"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Store  Dept       Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
            "0      1     1 2010-02-05      24924.50      False        42.31       2.572   \n",
            "1      1     1 2010-02-12      46039.49       True        38.51       2.548   \n",
            "2      1     1 2010-02-19      41595.55      False        39.93       2.514   \n",
            "3      1     1 2010-02-26      19403.54      False        46.63       2.561   \n",
            "4      1     1 2010-03-05      21827.90      False        46.50       2.625   \n",
            "\n",
            "   MarkDown1  MarkDown2  MarkDown3  ...  Week  DayOfWeek  DayOfYear  \\\n",
            "0        0.0        0.0        0.0  ...     5          4         36   \n",
            "1        0.0        0.0        0.0  ...     6          4         43   \n",
            "2        0.0        0.0        0.0  ...     7          4         50   \n",
            "3        0.0        0.0        0.0  ...     8          4         57   \n",
            "4        0.0        0.0        0.0  ...     9          4         64   \n",
            "\n",
            "   IsMonthStart IsMonthEnd  TimeIdx  Lag_Weekly_Sales  Lag52_Weekly_Sales  \\\n",
            "0             0          0        0              0.00                 0.0   \n",
            "1             0          0        7          24924.50                 0.0   \n",
            "2             0          0       14          46039.49                 0.0   \n",
            "3             0          0       21          41595.55                 0.0   \n",
            "4             0          0       28          19403.54                 0.0   \n",
            "\n",
            "   RollingMean_4W_Sales  RollingStd_4W_Sales  \n",
            "0              0.000000             0.000000  \n",
            "1          24924.500000             0.000000  \n",
            "2          35481.995000         14930.552614  \n",
            "3          37519.846667         11131.900957  \n",
            "4          32990.770000         12832.106391  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Data Splitting (Chronological 60/20/20 split)\n",
        "total_rows = len(train_merged)\n",
        "train_end_idx = int(total_rows * 0.6)\n",
        "val_end_idx = int(total_rows * 0.8) # 60% + 20%\n",
        "\n",
        "X_train = X.iloc[:train_end_idx]\n",
        "y_train = y.iloc[:train_end_idx]\n",
        "is_holiday_train = is_holiday_flags.iloc[:train_end_idx]\n",
        "\n",
        "X_val = X.iloc[train_end_idx:val_end_idx]\n",
        "y_val = y.iloc[train_end_idx:val_end_idx]\n",
        "is_holiday_val = is_holiday_flags.iloc[train_end_idx:val_end_idx]\n",
        "\n",
        "X_local_test = X.iloc[val_end_idx:]\n",
        "y_local_test = y.iloc[val_end_idx:]\n",
        "is_holiday_local_test = is_holiday_flags.iloc[val_end_idx:]\n"
      ],
      "metadata": {
        "id": "HeHLrvHB3XiG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nData split into Training ({len(X_train)} rows), Validation ({len(X_val)} rows), Local Test ({len(X_local_test)} rows).\")\n",
        "# Print actual dates to confirm the split ranges\n",
        "if not train_merged.empty:\n",
        "    print(f\"Train dates: {train_merged['Date'].iloc[0].date()} to {train_merged['Date'].iloc[train_end_idx-1].date()}\")\n",
        "    if val_end_idx > train_end_idx: # Check if validation set is not empty\n",
        "        print(f\"Validation dates: {train_merged['Date'].iloc[train_end_idx].date()} to {train_merged['Date'].iloc[val_end_idx-1].date()}\")\n",
        "    if len(X_local_test) > 0: # Check if local test set is not empty\n",
        "        print(f\"Local Test dates: {train_merged['Date'].iloc[val_end_idx].date()} to {train_merged['Date'].iloc[-1].date()}\")\n",
        "else:\n",
        "    print(\"train_merged DataFrame is empty, cannot display date ranges.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDa3IeMZ3ixm",
        "outputId": "413f2e44-9f9b-43b5-891a-eb13544e67ce"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data split into Training (252942 rows), Validation (84314 rows), Local Test (84314 rows).\n",
            "Train dates: 2010-02-05 to 2011-04-29\n",
            "Validation dates: 2011-05-06 to 2010-11-19\n",
            "Local Test dates: 2010-11-26 to 2012-10-26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- RandomForest_Training_&_Evaluation (Conceptual MLflow Run) ---\n",
        "print(\"\\n--- Model Training & Evaluation (Random Forest - Improved Features) ---\")\n",
        "\n",
        "# Create the Random Forest Regressor model within a pipeline\n",
        "# For a start, we'll keep n_estimators=100. Consider increasing later.\n",
        "rf_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "                          ])\n",
        "\n",
        "print(\"Training Random Forest model on training set with improved features...\")\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnxjhE4h3oqL",
        "outputId": "cd69be81-f4bf-4c58-99ca-7ee23aee5e9c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Training & Evaluation (Random Forest - Improved Features) ---\n",
            "Training Random Forest model on training set with improved features...\n",
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Make predictions and evaluate on the Validation Set\n",
        "print(\"\\nEvaluating on Validation Set...\")\n",
        "val_predictions = rf_model.predict(X_val)\n",
        "val_wmae = weighted_mean_absolute_error(y_val, val_predictions, is_holiday_val)\n",
        "print(f\"Validation WMAE: {val_wmae:.4f}\")\n",
        "val_mae = mean_absolute_error(y_val, val_predictions)\n",
        "print(f\"Validation MAE: {val_mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-Ox9aE46aTd",
        "outputId": "ccc83d7a-5eeb-44b7-d2d7-61ead1ca6ad3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on Validation Set...\n",
            "Validation WMAE: 1873.3626\n",
            "Validation MAE: 1692.2703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Make predictions and evaluate on the Local Test Set\n",
        "print(\"\\nEvaluating on Local Test Set...\")\n",
        "local_test_predictions = rf_model.predict(X_local_test)\n",
        "local_test_wmae = weighted_mean_absolute_error(y_local_test, local_test_predictions, is_holiday_local_test)\n",
        "print(f\"Local Test WMAE: {local_test_wmae:.4f}\")\n",
        "local_test_mae = mean_absolute_error(y_local_test, local_test_predictions)\n",
        "print(f\"Local Test MAE: {local_test_mae:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHb9gPMs6mrK",
        "outputId": "c7aff899-5c7b-4ea4-b33c-f89267e1c57e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on Local Test Set...\n",
            "Local Test WMAE: 1578.4943\n",
            "Local Test MAE: 1407.5672\n"
          ]
        }
      ]
    }
  ]
}