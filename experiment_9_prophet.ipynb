{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T41zxA-Mjh_J"
      },
      "source": [
        "# Experiment 9 Prophet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle wandb onnx -Uq\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Pz5Dr3yrjmnf",
        "outputId": "bd1316ea-f07e-4365-d8df-a16db47c992d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c walmart-recruiting-store-sales-forecasting\n",
        "! unzip walmart-recruiting-store-sales-forecasting.zip\n",
        "!unzip train.csv.zip\n",
        "!unzip features.csv.zip"
      ],
      "metadata": {
        "id": "kQcMTkUBju-A",
        "outputId": "6dfaad8b-4844-4f81-ad14-6fd19b8f8154",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading walmart-recruiting-store-sales-forecasting.zip to /content\n",
            "\r  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "\r100% 2.70M/2.70M [00:00<00:00, 613MB/s]\n",
            "Archive:  walmart-recruiting-store-sales-forecasting.zip\n",
            "  inflating: features.csv.zip        \n",
            "  inflating: sampleSubmission.csv.zip  \n",
            "  inflating: stores.csv              \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prophet plotly mlflow dagshub -q prophet"
      ],
      "metadata": {
        "id": "t3jWyJMNjwVy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CA0Ce3JMmRXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Core libraries\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import dagshub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prophet\n",
        "from prophet import Prophet\n",
        "import joblib\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "5MCDyN1fkv2Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WalmartPreprocessingPipeline:\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline for Walmart sales data\n",
        "    Supports fit/transform pattern for proper train/validation handling\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.fitted = False\n",
        "        self.outlier_thresholds = None\n",
        "        self.feature_columns = None\n",
        "\n",
        "    def load_and_prepare_data(self):\n",
        "        \"\"\"Load and merge train.csv, stores.csv, features.csv datasets\"\"\"\n",
        "        print(\"📊 Loading datasets...\")\n",
        "\n",
        "        # Load datasets\n",
        "        train_df = pd.read_csv('train.csv')\n",
        "        stores_df = pd.read_csv('stores.csv')\n",
        "        features_df = pd.read_csv('features.csv')\n",
        "\n",
        "        print(f\"   📈 Train data: {train_df.shape}\")\n",
        "        print(f\"   🏪 Stores data: {stores_df.shape}\")\n",
        "        print(f\"   🎯 Features data: {features_df.shape}\")\n",
        "\n",
        "        # Convert Date column to datetime\n",
        "        train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
        "        features_df['Date'] = pd.to_datetime(features_df['Date'])\n",
        "\n",
        "        # Merge datasets\n",
        "        train_stores = train_df.merge(stores_df, on='Store', how='left')\n",
        "        train_full = train_stores.merge(features_df, on=['Store', 'Date'], how='left')\n",
        "\n",
        "        print(f\"   ✅ Merged data: {train_full.shape}\")\n",
        "        print(f\"   📅 Date range: {train_full['Date'].min()} to {train_full['Date'].max()}\")\n",
        "\n",
        "        return train_full\n",
        "\n",
        "    def clean_merged_data(self, train_full):\n",
        "        \"\"\"Clean merged data by handling duplicate IsHoliday columns\"\"\"\n",
        "        print(\"🧹 Cleaning merged data...\")\n",
        "\n",
        "        initial_shape = train_full.shape\n",
        "\n",
        "        # Handle duplicate IsHoliday columns if they exist\n",
        "        if 'IsHoliday_x' in train_full.columns and 'IsHoliday_y' in train_full.columns:\n",
        "            print(\"   🔄 Resolving duplicate IsHoliday columns...\")\n",
        "            train_full['IsHoliday'] = train_full['IsHoliday_x'] | train_full['IsHoliday_y']\n",
        "            train_full = train_full.drop(['IsHoliday_x', 'IsHoliday_y'], axis=1)\n",
        "\n",
        "        print(f\"   ✅ Cleaned data: {train_full.shape} (was {initial_shape})\")\n",
        "        return train_full\n",
        "\n",
        "    def create_temporal_split(self, df, train_ratio=0.8):\n",
        "        \"\"\"Create temporal split to prevent data leakage\"\"\"\n",
        "        print(f\"📅 Creating temporal split ({int(train_ratio*100)}/{int((1-train_ratio)*100)})...\")\n",
        "\n",
        "        # Sort by date to ensure temporal order\n",
        "        df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "        # Find split point\n",
        "        split_idx = int(len(df_sorted) * train_ratio)\n",
        "        split_date = df_sorted.iloc[split_idx]['Date']\n",
        "\n",
        "        # Create splits\n",
        "        train_data = df_sorted.iloc[:split_idx].copy()\n",
        "        val_data = df_sorted.iloc[split_idx:].copy()\n",
        "\n",
        "        # Create split info dictionary\n",
        "        split_info = {\n",
        "            'split_date': split_date,\n",
        "            'train_size': len(train_data),\n",
        "            'val_size': len(val_data),\n",
        "            'train_date_range': (train_data['Date'].min(), train_data['Date'].max()),\n",
        "            'val_date_range': (val_data['Date'].min(), val_data['Date'].max())\n",
        "        }\n",
        "\n",
        "        print(f\"   📊 Split date: {split_date}\")\n",
        "        print(f\"   📈 Train: {len(train_data):,} records ({train_data['Date'].min()} to {train_data['Date'].max()})\")\n",
        "        print(f\"   📉 Val: {len(val_data):,} records ({val_data['Date'].min()} to {val_data['Date'].max()})\")\n",
        "\n",
        "        return train_data, val_data, split_info\n",
        "\n",
        "    def fit(self, train_data):\n",
        "        \"\"\"Fit the preprocessing pipeline on training data\"\"\"\n",
        "        print(\"🔧 Fitting preprocessing pipeline on training data...\")\n",
        "\n",
        "        # Store training data for lag feature creation\n",
        "        self.train_data_for_lags = train_data.copy()\n",
        "\n",
        "        # Fit outlier removal thresholds on training data only\n",
        "        self.outlier_thresholds = {\n",
        "            'A': {'lower': -1000, 'upper': 50000},  # Type A stores\n",
        "            'B': {'lower': -500, 'upper': 25000},   # Type B stores\n",
        "            'C': {'lower': -200, 'upper': 15000}    # Type C stores\n",
        "        }\n",
        "\n",
        "        print(\"✅ Pipeline fitted on training data\")\n",
        "        self.fitted = True\n",
        "        return self\n",
        "\n",
        "    def transform(self, data, is_validation=False):\n",
        "        \"\"\"Transform data using fitted pipeline\"\"\"\n",
        "        if not self.fitted:\n",
        "            raise ValueError(\"Pipeline must be fitted before transform!\")\n",
        "\n",
        "        print(f\"🔄 Transforming {'validation' if is_validation else 'training'} data...\")\n",
        "\n",
        "        df = data.copy()\n",
        "\n",
        "        # Step 1: Create date features\n",
        "        df = self._create_date_features(df)\n",
        "\n",
        "        # Step 2: Create holiday features\n",
        "        df = self._create_holiday_features(df)\n",
        "\n",
        "        # Step 3: Encode categorical features (BEFORE outlier removal!)\n",
        "        df = self._encode_categorical_features(df)\n",
        "\n",
        "        # Step 4: Create lag features (different for train vs validation)\n",
        "        if is_validation:\n",
        "            df = self._create_lag_features_validation(df)\n",
        "        else:\n",
        "            df = self._create_lag_features_training(df)\n",
        "\n",
        "        # Step 5: Remove outliers (only on training data, AFTER encoding)\n",
        "        if not is_validation:\n",
        "            df = self._remove_outliers(df)\n",
        "\n",
        "        # Step 6: Remove markdown features\n",
        "        df = self._remove_markdown_features(df)\n",
        "\n",
        "        # Step 7: Remove redundant features\n",
        "        df = self._remove_redundant_features(df)\n",
        "\n",
        "        print(f\"✅ Transform complete. Shape: {df.shape}\")\n",
        "        return df\n",
        "\n",
        "    def fit_transform(self, train_data):\n",
        "        \"\"\"Fit and transform training data in one step\"\"\"\n",
        "        return self.fit(train_data).transform(train_data, is_validation=False)\n",
        "\n",
        "    def _create_date_features(self, df):\n",
        "        \"\"\"Create date features\"\"\"\n",
        "        df = df.copy()\n",
        "        df['Year'] = df['Date'].dt.year\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "        df['Day'] = df['Date'].dt.day\n",
        "        df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "        df['WeekOfYear'] = df['Date'].dt.isocalendar().week\n",
        "        df['Quarter'] = df['Date'].dt.quarter\n",
        "        df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)\n",
        "        df['IsMonthStart'] = df['Date'].dt.is_month_start.astype(int)\n",
        "        df['IsMonthEnd'] = df['Date'].dt.is_month_end.astype(int)\n",
        "        df['IsQuarterStart'] = df['Date'].dt.is_quarter_start.astype(int)\n",
        "        df['IsQuarterEnd'] = df['Date'].dt.is_quarter_end.astype(int)\n",
        "        start_date = df['Date'].min()\n",
        "        df['DaysFromStart'] = (df['Date'] - start_date).dt.days\n",
        "        df['WeeksFromStart'] = df['DaysFromStart'] // 7\n",
        "        return df\n",
        "\n",
        "    def _create_holiday_features(self, df):\n",
        "        \"\"\"Create holiday features\"\"\"\n",
        "        df = df.copy()\n",
        "        super_bowl_dates = ['2010-02-12', '2011-02-11', '2012-02-10']\n",
        "        labor_day_dates = ['2010-09-10', '2011-09-09', '2012-09-07']\n",
        "        thanksgiving_dates = ['2010-11-26', '2011-11-25', '2012-11-23']\n",
        "        christmas_dates = ['2010-12-31', '2011-12-30', '2012-12-28']\n",
        "\n",
        "        df['IsSuperBowlWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(super_bowl_dates).astype(int)\n",
        "        df['IsLaborDayWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(labor_day_dates).astype(int)\n",
        "        df['IsThanksgivingWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(thanksgiving_dates).astype(int)\n",
        "        df['IsChristmasWeek'] = df['Date'].dt.strftime('%Y-%m-%d').isin(christmas_dates).astype(int)\n",
        "        df['IsMajorHoliday'] = (df['IsSuperBowlWeek'] | df['IsLaborDayWeek'] |\n",
        "                               df['IsThanksgivingWeek'] | df['IsChristmasWeek']).astype(int)\n",
        "        df['IsHolidayMonth'] = df['Month'].isin([11, 12]).astype(int)\n",
        "        df['IsBackToSchool'] = df['Month'].isin([8, 9]).astype(int)\n",
        "        return df\n",
        "\n",
        "    def _create_lag_features_training(self, df):\n",
        "        \"\"\"Create lag features for training data - DISABLED to reduce overfitting\"\"\"\n",
        "        # Lag features removed to prevent overfitting\n",
        "        return df\n",
        "\n",
        "    def _create_lag_features_validation(self, df):\n",
        "        \"\"\"Create lag features for validation data - DISABLED to reduce overfitting\"\"\"\n",
        "        # Lag features removed to prevent overfitting\n",
        "        return df\n",
        "\n",
        "    def _remove_outliers(self, df):\n",
        "        \"\"\"Remove outliers from training data only\"\"\"\n",
        "        initial_len = len(df)\n",
        "        df_clean = df.copy()\n",
        "\n",
        "        for store_type, thresholds in self.outlier_thresholds.items():\n",
        "            type_mask = df_clean[f'Type_{store_type}'] == 1\n",
        "            outlier_mask = (\n",
        "                (df_clean['Weekly_Sales'] < thresholds['lower']) |\n",
        "                (df_clean['Weekly_Sales'] > thresholds['upper'])\n",
        "            )\n",
        "            df_clean = df_clean[~(type_mask & outlier_mask)]\n",
        "\n",
        "        removed = initial_len - len(df_clean)\n",
        "        print(f\"   🗑️ Removed {removed:,} outliers from training data\")\n",
        "        return df_clean\n",
        "\n",
        "    def _remove_markdown_features(self, df):\n",
        "        \"\"\"Remove markdown columns\"\"\"\n",
        "        markdown_cols = [col for col in df.columns if 'MarkDown' in col]\n",
        "        if markdown_cols:\n",
        "            df = df.drop(markdown_cols, axis=1)\n",
        "        return df\n",
        "\n",
        "    def _remove_redundant_features(self, df):\n",
        "        \"\"\"Remove redundant features\"\"\"\n",
        "        redundant_cols = ['Year', 'Quarter', 'Day', 'WeekOfYear', 'DaysFromStart',\n",
        "                         'IsQuarterStart', 'IsQuarterEnd']\n",
        "        existing_redundant = [col for col in redundant_cols if col in df.columns]\n",
        "        if existing_redundant:\n",
        "            df = df.drop(existing_redundant, axis=1)\n",
        "        return df\n",
        "\n",
        "    def _encode_categorical_features(self, df):\n",
        "        \"\"\"Encode categorical features using both one-hot and label encoding\"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        if 'Type' in df.columns:\n",
        "            print(f\"   🔧 Encoding Type column using both one-hot and label encoding...\")\n",
        "\n",
        "            # One-hot encoding (existing approach)\n",
        "            type_dummies = pd.get_dummies(df['Type'], prefix='Type', dtype=int)\n",
        "\n",
        "            # Label encoding (experiment_2 approach)\n",
        "            # A=0, B=1, C=2 (same as experiment_2)\n",
        "            type_mapping = {'A': 0, 'B': 1, 'C': 2}\n",
        "            df['Type_Encoded'] = df['Type'].map(type_mapping)\n",
        "\n",
        "            # Add one-hot columns\n",
        "            for col in type_dummies.columns:\n",
        "                df[col] = type_dummies[col]\n",
        "\n",
        "            # Remove original Type column\n",
        "            df = df.drop('Type', axis=1)\n",
        "\n",
        "            print(f\"   ✅ Added both Type_Encoded and {list(type_dummies.columns)}\")\n",
        "\n",
        "        return df\n",
        "\n"
      ],
      "metadata": {
        "id": "3r9N8yHhlBHj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_mlflow():\n",
        "    \"\"\"Setup MLflow and DagsHub tracking\"\"\"\n",
        "    print(\"🔧 Setting up MLflow and DagsHub...\")\n",
        "\n",
        "    # End any active runs first\n",
        "    try:\n",
        "        mlflow.end_run()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Initialize DagsHub\n",
        "    try:\n",
        "        dagshub.init(\n",
        "            repo_owner='konstantine25b',\n",
        "            repo_name='Walmart-Recruiting---Store-Sales-Forecasting',\n",
        "            mlflow=True\n",
        "        )\n",
        "        print(\"✅ DagsHub initialized successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ DagsHub init warning: {e}\")\n",
        "\n",
        "    # Set MLflow tracking URI\n",
        "    mlflow.set_tracking_uri(\"https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow\")\n",
        "\n",
        "    # Create unique experiment name with timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    experiment_name = f\"Experiment_9_Prophet_{timestamp}\"\n",
        "\n",
        "    try:\n",
        "        experiment_id = mlflow.create_experiment(experiment_name)\n",
        "        print(f\"✅ Created new experiment: {experiment_name}\")\n",
        "    except mlflow.exceptions.MlflowException as e:\n",
        "        if \"already exists\" in str(e):\n",
        "            experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "            experiment_id = experiment.experiment_id\n",
        "            print(f\"✅ Using existing experiment: {experiment_name}\")\n",
        "        else:\n",
        "            # Fallback to default experiment\n",
        "            experiment_name = \"Default\"\n",
        "            mlflow.set_experiment(experiment_name)\n",
        "            print(f\"⚠️ Using default experiment due to: {e}\")\n",
        "\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "\n",
        "    print(f\"✅ MLflow setup complete!\")\n",
        "    print(f\"🔗 Tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "    print(f\"📊 Experiment: {experiment_name}\")\n",
        "\n",
        "    return experiment_name\n",
        "\n"
      ],
      "metadata": {
        "id": "-B4qUhjWlDfI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessed_data():\n",
        "    \"\"\"\n",
        "    Use preprocessing pipeline to get model-ready data\n",
        "\n",
        "    Returns:\n",
        "        X_train, y_train, X_val, y_val: Model-ready datasets\n",
        "        train_holidays, val_holidays: Holiday indicators for WMAE\n",
        "        split_info: Information about the temporal split\n",
        "    \"\"\"\n",
        "    print(\"🔄 Getting preprocessed data using pipeline...\")\n",
        "\n",
        "    # Create the preprocessing pipeline\n",
        "    pipeline = WalmartPreprocessingPipeline()\n",
        "\n",
        "    # Load raw data\n",
        "    train_full = pipeline.load_and_prepare_data()\n",
        "    train_full = pipeline.clean_merged_data(train_full)\n",
        "\n",
        "    # Create temporal split\n",
        "    train_data, val_data, split_info = pipeline.create_temporal_split(train_full)\n",
        "\n",
        "    # Extract holiday information before preprocessing\n",
        "    val_holidays = val_data['IsHoliday'].values.astype(bool)\n",
        "\n",
        "    # Separate validation target (realistic test scenario)\n",
        "    y_val = val_data['Weekly_Sales'].copy()\n",
        "    val_data_no_target = val_data.drop('Weekly_Sales', axis=1).copy()\n",
        "\n",
        "    # Fit and transform data using pipeline\n",
        "    pipeline.fit(train_data)\n",
        "    train_processed = pipeline.transform(train_data, is_validation=False)\n",
        "    val_processed = pipeline.transform(val_data_no_target, is_validation=True)\n",
        "\n",
        "    # Prepare final model data\n",
        "    X_train = train_processed.drop(['Weekly_Sales', 'Date'], axis=1)\n",
        "    y_train = train_processed['Weekly_Sales']\n",
        "    X_val = val_processed.drop('Date', axis=1)\n",
        "    train_holidays = train_processed['IsHoliday'].values.astype(bool)\n",
        "\n",
        "    # Store feature columns for later reference\n",
        "    feature_columns = list(X_train.columns)\n",
        "\n",
        "    print(f\"✅ Data preprocessing complete!\")\n",
        "    print(f\"   📊 Training shape: {X_train.shape}\")\n",
        "    print(f\"   📊 Validation shape: {X_val.shape}\")\n",
        "    print(f\"   🎯 Features: {len(feature_columns)}\")\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, train_holidays, val_holidays, split_info, feature_columns\n"
      ],
      "metadata": {
        "id": "Or22vwialFWN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_wmae(y_true, y_pred, is_holiday, holiday_weight=5.0):\n",
        "    \"\"\"Calculate Weighted Mean Absolute Error (WMAE)\"\"\"\n",
        "    abs_errors = np.abs(y_true - y_pred)\n",
        "    weights = np.where(is_holiday, holiday_weight, 1.0)\n",
        "    wmae = np.sum(weights * abs_errors) / np.sum(weights)\n",
        "    return wmae\n",
        "\n",
        "\n",
        "def prepare_prophet_data(X_train, y_train, X_val, y_val, train_holidays, val_holidays):\n",
        "    \"\"\"Prepare data for Prophet training on Store-Dept combinations\"\"\"\n",
        "    print(\"📊 Preparing data for Prophet modeling...\")\n",
        "\n",
        "    # Reconstruct full datasets with dates for Prophet\n",
        "    # We need to reload the original data to get dates back\n",
        "    pipeline = WalmartPreprocessingPipeline()\n",
        "    train_full = pipeline.load_and_prepare_data()\n",
        "    train_full = pipeline.clean_merged_data(train_full)\n",
        "    train_data, val_data, _ = pipeline.create_temporal_split(train_full)\n",
        "\n",
        "    print(f\"   📈 Train data shape: {train_data.shape}\")\n",
        "    print(f\"   📉 Val data shape: {val_data.shape}\")\n",
        "\n",
        "    # Get unique Store-Dept combinations\n",
        "    train_combinations = set(zip(train_data['Store'], train_data['Dept']))\n",
        "    val_combinations = set(zip(val_data['Store'], val_data['Dept']))\n",
        "\n",
        "    print(f\"   🏪 Train combinations: {len(train_combinations)}\")\n",
        "    print(f\"   🔮 Val combinations: {len(val_combinations)}\")\n",
        "\n",
        "    # Find missing combinations in validation\n",
        "    missing_in_val = train_combinations - val_combinations\n",
        "    missing_in_train = val_combinations - train_combinations\n",
        "\n",
        "    print(f\"   ⚠️ Missing in validation: {len(missing_in_val)}\")\n",
        "    print(f\"   ⚠️ Missing in training: {len(missing_in_train)}\")\n",
        "\n",
        "    return train_data, val_data, train_combinations, val_combinations\n",
        "\n"
      ],
      "metadata": {
        "id": "mKL3pKzPlIst"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_prophet_models(train_data, val_data, feature_columns):\n",
        "    \"\"\"Train individual Prophet models for each Store-Dept combination - OPTIMIZED FOR SPEED\"\"\"\n",
        "    print(\"🔮 Training Prophet models for each Store-Dept combination (SPEED OPTIMIZED)...\")\n",
        "\n",
        "    # Get unique combinations from training data\n",
        "    train_combinations = train_data.groupby(['Store', 'Dept']).size().index.tolist()\n",
        "    print(f\"   📊 Training models for {len(train_combinations)} combinations\")\n",
        "\n",
        "    models = {}\n",
        "    predictions = {}\n",
        "    training_errors = {}\n",
        "\n",
        "    # SPEED OPTIMIZATION 1: Reduce regressors to only the most important ones\n",
        "    important_regressors = ['IsHoliday', 'Temperature', 'Type_Encoded', 'Month', 'IsWeekend']\n",
        "\n",
        "    regressor_cols = [col for col in important_regressors if col in feature_columns]\n",
        "    print(f\"   🎯 Using {len(regressor_cols)} regressors: {regressor_cols}\")\n",
        "\n",
        "    successful_models = 0\n",
        "    failed_models = 0\n",
        "\n",
        "    for i, (store, dept) in enumerate(train_combinations):\n",
        "        try:\n",
        "            # Filter data for this combination\n",
        "            store_dept_data = train_data[\n",
        "                (train_data['Store'] == store) &\n",
        "                (train_data['Dept'] == dept)\n",
        "            ].copy()\n",
        "\n",
        "            # Skip if insufficient data\n",
        "            if len(store_dept_data) < 8:  # Reduced threshold\n",
        "                failed_models += 1\n",
        "                continue\n",
        "\n",
        "            # Prepare Prophet dataset\n",
        "            prophet_df = pd.DataFrame({\n",
        "                'ds': store_dept_data['Date'],\n",
        "                'y': store_dept_data['Weekly_Sales']\n",
        "            })\n",
        "\n",
        "            # Add only essential regressors\n",
        "            for col in regressor_cols:\n",
        "                if col in store_dept_data.columns:\n",
        "                    prophet_df[col] = store_dept_data[col].values\n",
        "\n",
        "            # SPEED OPTIMIZATION 2: Simplified Prophet model with faster settings\n",
        "            model = Prophet(\n",
        "                yearly_seasonality=True,\n",
        "                weekly_seasonality=False,  # Disabled for speed\n",
        "                daily_seasonality=False,\n",
        "                holidays_prior_scale=1.0,  # Reduced from 10.0\n",
        "                seasonality_prior_scale=1.0,  # Reduced from 10.0\n",
        "                changepoint_prior_scale=0.01,  # Reduced from 0.05\n",
        "                mcmc_samples=0,  # Disable MCMC for speed\n",
        "                interval_width=0.8,  # Reduced from default\n",
        "                uncertainty_samples=0  # Disable uncertainty for speed\n",
        "            )\n",
        "\n",
        "            # Add regressors to model\n",
        "            for col in regressor_cols:\n",
        "                if col in prophet_df.columns:\n",
        "                    model.add_regressor(col)\n",
        "\n",
        "            # SPEED OPTIMIZATION 3: Suppress Stan output\n",
        "            import logging\n",
        "            logging.getLogger('prophet').setLevel(logging.WARNING)\n",
        "            logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n",
        "\n",
        "            # Fit model\n",
        "            model.fit(prophet_df)\n",
        "            models[(store, dept)] = model\n",
        "            successful_models += 1\n",
        "\n",
        "            # Quick training error calculation\n",
        "            if successful_models % 50 == 0:  # Only calculate for some models to save time\n",
        "                train_pred = model.predict(prophet_df)\n",
        "                train_mae = mean_absolute_error(prophet_df['y'], train_pred['yhat'])\n",
        "                training_errors[(store, dept)] = train_mae\n",
        "\n",
        "            # Progress updates every 25 models\n",
        "            if i % 25 == 0:\n",
        "                print(f\"   ✅ Trained {i+1}/{len(train_combinations)} models\")\n",
        "\n",
        "        except Exception as e:\n",
        "            failed_models += 1\n",
        "            if failed_models < 3:  # Only print first few errors\n",
        "                print(f\"   ⚠️ Failed to train model for Store {store}, Dept {dept}: {e}\")\n",
        "\n",
        "    print(f\"✅ Prophet training complete!\")\n",
        "    print(f\"   🎯 Successful models: {successful_models}\")\n",
        "    print(f\"   ❌ Failed models: {failed_models}\")\n",
        "\n",
        "    return models, training_errors, regressor_cols\n"
      ],
      "metadata": {
        "id": "ihwhXOSGlJkb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prophet_predictions(models, val_data, regressor_cols):\n",
        "    \"\"\"Make predictions using trained Prophet models\"\"\"\n",
        "    print(\"🔮 Making Prophet predictions...\")\n",
        "\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    holidays = []\n",
        "    successful_predictions = 0\n",
        "    failed_predictions = 0\n",
        "\n",
        "    # Get validation combinations\n",
        "    val_combinations = val_data.groupby(['Store', 'Dept']).groups.keys()\n",
        "\n",
        "    for store, dept in val_combinations:\n",
        "        try:\n",
        "            # Check if we have a model for this combination\n",
        "            if (store, dept) not in models:\n",
        "                # Use overall mean as fallback\n",
        "                fallback_pred = val_data['Weekly_Sales'].mean()\n",
        "                store_dept_val = val_data[\n",
        "                    (val_data['Store'] == store) &\n",
        "                    (val_data['Dept'] == dept)\n",
        "                ]\n",
        "                predictions.extend([fallback_pred] * len(store_dept_val))\n",
        "                actuals.extend(store_dept_val['Weekly_Sales'].tolist())\n",
        "                holidays.extend(store_dept_val['IsHoliday'].tolist())\n",
        "                failed_predictions += len(store_dept_val)\n",
        "                continue\n",
        "\n",
        "            # Get validation data for this combination\n",
        "            store_dept_val = val_data[\n",
        "                (val_data['Store'] == store) &\n",
        "                (val_data['Dept'] == dept)\n",
        "            ].copy()\n",
        "\n",
        "            # Prepare Prophet prediction dataset\n",
        "            future_df = pd.DataFrame({\n",
        "                'ds': store_dept_val['Date']\n",
        "            })\n",
        "\n",
        "            # Add regressors\n",
        "            for col in regressor_cols:\n",
        "                if col in store_dept_val.columns:\n",
        "                    future_df[col] = store_dept_val[col].values\n",
        "\n",
        "            # Make prediction\n",
        "            model = models[(store, dept)]\n",
        "            forecast = model.predict(future_df)\n",
        "\n",
        "            # Store results\n",
        "            predictions.extend(forecast['yhat'].tolist())\n",
        "            actuals.extend(store_dept_val['Weekly_Sales'].tolist())\n",
        "            holidays.extend(store_dept_val['IsHoliday'].tolist())\n",
        "            successful_predictions += len(store_dept_val)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Fallback prediction\n",
        "            fallback_pred = val_data['Weekly_Sales'].mean()\n",
        "            store_dept_val = val_data[\n",
        "                (val_data['Store'] == store) &\n",
        "                (val_data['Dept'] == dept)\n",
        "            ]\n",
        "            predictions.extend([fallback_pred] * len(store_dept_val))\n",
        "            actuals.extend(store_dept_val['Weekly_Sales'].tolist())\n",
        "            holidays.extend(store_dept_val['IsHoliday'].tolist())\n",
        "            failed_predictions += len(store_dept_val)\n",
        "\n",
        "    print(f\"✅ Predictions complete!\")\n",
        "    print(f\"   🎯 Successful predictions: {successful_predictions}\")\n",
        "    print(f\"   ❌ Failed/fallback predictions: {failed_predictions}\")\n",
        "\n",
        "    return np.array(predictions), np.array(actuals), np.array(holidays)\n"
      ],
      "metadata": {
        "id": "sB4_YFkulMB1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SPEED OPTIMIZATION: Suppress verbose logging globally\n",
        "import logging\n",
        "logging.getLogger('prophet').setLevel(logging.WARNING)\n",
        "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n",
        "logging.getLogger('prophet.models').setLevel(logging.WARNING)\n",
        "\n",
        "# Core librar"
      ],
      "metadata": {
        "id": "mQ_UgkN8tCJ8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main experiment execution\"\"\"\n",
        "    print(\"🚀 Starting Experiment 9: Prophet with Experiment 7 Features\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Setup MLflow tracking\n",
        "    experiment_name = setup_mlflow()\n",
        "\n",
        "    with mlflow.start_run(run_name=\"Prophet_Exp7_Features_Complete\") as run:\n",
        "        print(f\"🔄 Starting MLflow run: {run.info.run_id}\")\n",
        "\n",
        "        # Log experiment metadata\n",
        "        mlflow.log_param(\"experiment_type\", \"Prophet_with_Exp7_Features\")\n",
        "        mlflow.log_param(\"model_type\", \"Prophet_Individual_Models\")\n",
        "        mlflow.log_param(\"feature_engineering\", \"Experiment_7_Pipeline\")\n",
        "        mlflow.log_param(\"data_split\", \"temporal_80_20\")\n",
        "\n",
        "        try:\n",
        "            # Step 1: Get preprocessed data\n",
        "            print(\"\\n📊 Step 1: Data preprocessing...\")\n",
        "            X_train, y_train, X_val, y_val, train_holidays, val_holidays, split_info, feature_columns = get_preprocessed_data()\n",
        "\n",
        "            # Log data info\n",
        "            mlflow.log_metric(\"train_samples\", len(X_train))\n",
        "            mlflow.log_metric(\"val_samples\", len(X_val))\n",
        "            mlflow.log_metric(\"total_features\", len(feature_columns))\n",
        "            mlflow.log_param(\"split_date\", str(split_info['split_date']))\n",
        "\n",
        "            # Step 2: Prepare Prophet-specific data\n",
        "            print(\"\\n📊 Step 2: Preparing Prophet data...\")\n",
        "            train_data, val_data, train_combinations, val_combinations = prepare_prophet_data(\n",
        "                X_train, y_train, X_val, y_val, train_holidays, val_holidays\n",
        "            )\n",
        "\n",
        "            # Log combination info\n",
        "            mlflow.log_metric(\"train_combinations\", len(train_combinations))\n",
        "            mlflow.log_metric(\"val_combinations\", len(val_combinations))\n",
        "            mlflow.log_metric(\"missing_combinations\", len(train_combinations - val_combinations))\n",
        "\n",
        "            # Step 3: Train Prophet models\n",
        "            print(\"\\n🔮 Step 3: Training Prophet models...\")\n",
        "            models, training_errors, regressor_cols = train_prophet_models(\n",
        "                train_data, val_data, feature_columns\n",
        "            )\n",
        "\n",
        "            # Log training info\n",
        "            mlflow.log_metric(\"successful_models\", len(models))\n",
        "            mlflow.log_metric(\"avg_training_mae\", np.mean(list(training_errors.values())) if training_errors else 0)\n",
        "            mlflow.log_param(\"regressors_used\", regressor_cols)\n",
        "            mlflow.log_metric(\"num_regressors\", len(regressor_cols))\n",
        "\n",
        "            # Step 4: Make predictions\n",
        "            print(\"\\n🔮 Step 4: Making predictions...\")\n",
        "            y_pred, y_true, is_holiday = make_prophet_predictions(\n",
        "                models, val_data, regressor_cols\n",
        "            )\n",
        "\n",
        "            # Step 5: Calculate metrics\n",
        "            print(\"\\n📊 Step 5: Calculating metrics...\")\n",
        "\n",
        "            # Standard metrics\n",
        "            mae = mean_absolute_error(y_true, y_pred)\n",
        "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "            r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "            # WMAE (Competition metric)\n",
        "            wmae = calculate_wmae(y_true, y_pred, is_holiday)\n",
        "\n",
        "            # Holiday vs non-holiday breakdown\n",
        "            holiday_mask = is_holiday == True\n",
        "            non_holiday_mask = is_holiday == False\n",
        "\n",
        "            holiday_mae = mean_absolute_error(y_true[holiday_mask], y_pred[holiday_mask]) if holiday_mask.sum() > 0 else 0\n",
        "            non_holiday_mae = mean_absolute_error(y_true[non_holiday_mask], y_pred[non_holiday_mask]) if non_holiday_mask.sum() > 0 else 0\n",
        "\n",
        "            # Log all metrics\n",
        "            mlflow.log_metric(\"mae\", mae)\n",
        "            mlflow.log_metric(\"rmse\", rmse)\n",
        "            mlflow.log_metric(\"r2_score\", r2)\n",
        "            mlflow.log_metric(\"wmae\", wmae)\n",
        "            mlflow.log_metric(\"holiday_mae\", holiday_mae)\n",
        "            mlflow.log_metric(\"non_holiday_mae\", non_holiday_mae)\n",
        "            mlflow.log_metric(\"holiday_samples\", holiday_mask.sum())\n",
        "            mlflow.log_metric(\"non_holiday_samples\", non_holiday_mask.sum())\n",
        "\n",
        "            # Step 6: Results summary\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"🎯 EXPERIMENT 9 RESULTS SUMMARY\")\n",
        "            print(\"=\" * 60)\n",
        "            print(f\"📊 Validation Metrics:\")\n",
        "            print(f\"   WMAE (Competition Metric): ${wmae:,.2f}\")\n",
        "            print(f\"   MAE: ${mae:,.2f}\")\n",
        "            print(f\"   RMSE: ${rmse:,.2f}\")\n",
        "            print(f\"   R²: {r2:.4f}\")\n",
        "            print(f\"\\n📊 Holiday Breakdown:\")\n",
        "            print(f\"   Holiday MAE: ${holiday_mae:,.2f} ({holiday_mask.sum():,} samples)\")\n",
        "            print(f\"   Non-Holiday MAE: ${non_holiday_mae:,.2f} ({non_holiday_mask.sum():,} samples)\")\n",
        "            print(f\"\\n📊 Model Statistics:\")\n",
        "            print(f\"   Successful models trained: {len(models):,}\")\n",
        "            print(f\"   Store-Dept combinations: {len(train_combinations):,}\")\n",
        "            print(f\"   Features used: {len(feature_columns):,}\")\n",
        "            print(f\"   Regressors per model: {len(regressor_cols):,}\")\n",
        "\n",
        "            # Step 7: Save artifacts\n",
        "            print(f\"\\n💾 Saving model artifacts...\")\n",
        "\n",
        "            # Save model summary\n",
        "            model_summary = {\n",
        "                'experiment_name': experiment_name,\n",
        "                'run_id': run.info.run_id,\n",
        "                'models_trained': len(models),\n",
        "                'feature_columns': feature_columns,\n",
        "                'regressor_columns': regressor_cols,\n",
        "                'metrics': {\n",
        "                    'wmae': wmae,\n",
        "                    'mae': mae,\n",
        "                    'rmse': rmse,\n",
        "                    'r2': r2\n",
        "                }\n",
        "            }\n",
        "\n",
        "            with open('prophet_exp9_summary.json', 'w') as f:\n",
        "                json.dump(model_summary, f, indent=2, default=str)\n",
        "\n",
        "            mlflow.log_artifact('prophet_exp9_summary.json')\n",
        "\n",
        "            print(\"✅ Experiment 9 completed successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Experiment failed: {e}\")\n",
        "            mlflow.log_param(\"error\", str(e))\n",
        "            raise\n",
        "\n",
        "    print(\"\\n🎉 Experiment 9: Prophet with Experiment 7 Features - COMPLETE!\")\n"
      ],
      "metadata": {
        "id": "YGU2RlzwlNjx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la *.csv\n",
        "!unzip train.csv.zip\n",
        "!unzip features.csv.zip"
      ],
      "metadata": {
        "id": "q1wB_tKClkzT",
        "outputId": "a9b54508-e1a7-40a0-eb6d-bb0838d3236a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 532 Dec 11  2019 stores.csv\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  features.csv.zip\n",
            "  inflating: features.csv            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "H5LPn_5qlPTW",
        "outputId": "56a4f4be-d13f-4267-f351-26f77137cf61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting Experiment 9: Prophet with Experiment 7 Features\n",
            "================================================================================\n",
            "🔧 Setting up MLflow and DagsHub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DagsHub initialized successfully!\n",
            "✅ Created new experiment: Experiment_9_Prophet_20250710_142018\n",
            "✅ MLflow setup complete!\n",
            "🔗 Tracking URI: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow\n",
            "📊 Experiment: Experiment_9_Prophet_20250710_142018\n",
            "🔄 Starting MLflow run: 7ac70aa921df495d82525d6415ca9c53\n",
            "\n",
            "📊 Step 1: Data preprocessing...\n",
            "🔄 Getting preprocessed data using pipeline...\n",
            "📊 Loading datasets...\n",
            "   📈 Train data: (421570, 5)\n",
            "   🏪 Stores data: (45, 3)\n",
            "   🎯 Features data: (8190, 12)\n",
            "   ✅ Merged data: (421570, 17)\n",
            "   📅 Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n",
            "🧹 Cleaning merged data...\n",
            "   🔄 Resolving duplicate IsHoliday columns...\n",
            "   ✅ Cleaned data: (421570, 16) (was (421570, 17))\n",
            "📅 Creating temporal split (80/19)...\n",
            "   📊 Split date: 2012-04-13 00:00:00\n",
            "   📈 Train: 337,256 records (2010-02-05 00:00:00 to 2012-04-13 00:00:00)\n",
            "   📉 Val: 84,314 records (2012-04-13 00:00:00 to 2012-10-26 00:00:00)\n",
            "🔧 Fitting preprocessing pipeline on training data...\n",
            "✅ Pipeline fitted on training data\n",
            "🔄 Transforming training data...\n",
            "   🔧 Encoding Type column using both one-hot and label encoding...\n",
            "   ✅ Added both Type_Encoded and ['Type_A', 'Type_B', 'Type_C']\n",
            "   🗑️ Removed 45,193 outliers from training data\n",
            "✅ Transform complete. Shape: (292063, 27)\n",
            "🔄 Transforming validation data...\n",
            "   🔧 Encoding Type column using both one-hot and label encoding...\n",
            "   ✅ Added both Type_Encoded and ['Type_A', 'Type_B', 'Type_C']\n",
            "✅ Transform complete. Shape: (84314, 26)\n",
            "✅ Data preprocessing complete!\n",
            "   📊 Training shape: (292063, 25)\n",
            "   📊 Validation shape: (84314, 25)\n",
            "   🎯 Features: 25\n",
            "\n",
            "📊 Step 2: Preparing Prophet data...\n",
            "📊 Preparing data for Prophet modeling...\n",
            "📊 Loading datasets...\n",
            "   📈 Train data: (421570, 5)\n",
            "   🏪 Stores data: (45, 3)\n",
            "   🎯 Features data: (8190, 12)\n",
            "   ✅ Merged data: (421570, 17)\n",
            "   📅 Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n",
            "🧹 Cleaning merged data...\n",
            "   🔄 Resolving duplicate IsHoliday columns...\n",
            "   ✅ Cleaned data: (421570, 16) (was (421570, 17))\n",
            "📅 Creating temporal split (80/19)...\n",
            "   📊 Split date: 2012-04-13 00:00:00\n",
            "   📈 Train: 337,256 records (2010-02-05 00:00:00 to 2012-04-13 00:00:00)\n",
            "   📉 Val: 84,314 records (2012-04-13 00:00:00 to 2012-10-26 00:00:00)\n",
            "   📈 Train data shape: (337256, 16)\n",
            "   📉 Val data shape: (84314, 16)\n",
            "   🏪 Train combinations: 3313\n",
            "   🔮 Val combinations: 3166\n",
            "   ⚠️ Missing in validation: 165\n",
            "   ⚠️ Missing in training: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:20:33 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔮 Step 3: Training Prophet models...\n",
            "🔮 Training Prophet models for each Store-Dept combination (SPEED OPTIMIZED)...\n",
            "   📊 Training models for 3313 combinations\n",
            "   🎯 Using 5 regressors: ['IsHoliday', 'Temperature', 'Type_Encoded', 'Month', 'IsWeekend']\n",
            "   ✅ Trained 1/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:20:34 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 26/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:20:36 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:20:37 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:20:38 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 51/3313 models\n",
            "   ✅ Trained 76/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:20:52 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:20:52 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 101/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:20:55 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 126/3313 models\n",
            "   ✅ Trained 151/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:20:56 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:20:57 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:20:57 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:20:58 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 176/3313 models\n",
            "   ✅ Trained 201/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:00 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:21:01 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 226/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:03 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 251/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:05 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 276/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:06 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 301/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:07 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 326/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:09 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 351/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:11 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 376/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:11 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 401/3313 models\n",
            "   ✅ Trained 426/3313 models\n",
            "   ✅ Trained 451/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:17 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 476/3313 models\n",
            "   ✅ Trained 501/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:19 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 526/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:21 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 551/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:29 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 576/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:31 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 626/3313 models\n",
            "   ✅ Trained 651/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:34 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:21:36 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 676/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:36 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 701/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:37 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:21:39 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 726/3313 models\n",
            "   ✅ Trained 751/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:41 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:21:42 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 776/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:44 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:21:44 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:21:55 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 826/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:57 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 851/3313 models\n",
            "   ✅ Trained 876/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:21:59 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:22:00 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:22:01 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 901/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:22:01 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:22:02 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 926/3313 models\n",
            "   ✅ Trained 951/3313 models\n",
            "   ✅ Trained 976/3313 models\n",
            "   ✅ Trained 1001/3313 models\n",
            "   ✅ Trained 1026/3313 models\n",
            "   ✅ Trained 1051/3313 models\n",
            "   ✅ Trained 1076/3313 models\n",
            "   ✅ Trained 1101/3313 models\n",
            "   ✅ Trained 1126/3313 models\n",
            "   ✅ Trained 1151/3313 models\n",
            "   ✅ Trained 1176/3313 models\n",
            "   ✅ Trained 1201/3313 models\n",
            "   ✅ Trained 1226/3313 models\n",
            "   ✅ Trained 1251/3313 models\n",
            "   ✅ Trained 1276/3313 models\n",
            "   ✅ Trained 1301/3313 models\n",
            "   ✅ Trained 1326/3313 models\n",
            "   ✅ Trained 1351/3313 models\n",
            "   ✅ Trained 1376/3313 models\n",
            "   ✅ Trained 1401/3313 models\n",
            "   ✅ Trained 1426/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:22:56 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 1451/3313 models\n",
            "   ✅ Trained 1476/3313 models\n",
            "   ✅ Trained 1501/3313 models\n",
            "   ✅ Trained 1526/3313 models\n",
            "   ✅ Trained 1551/3313 models\n",
            "   ✅ Trained 1576/3313 models\n",
            "   ✅ Trained 1601/3313 models\n",
            "   ✅ Trained 1626/3313 models\n",
            "   ✅ Trained 1651/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:09 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 1701/3313 models\n",
            "   ✅ Trained 1726/3313 models\n",
            "   ✅ Trained 1751/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:13 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 1776/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:16 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 1801/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:16 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 1826/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:18 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 1851/3313 models\n",
            "   ✅ Trained 1876/3313 models\n",
            "   ✅ Trained 1901/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:23 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 1926/3313 models\n",
            "   ✅ Trained 1951/3313 models\n",
            "   ✅ Trained 1976/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:28 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2001/3313 models\n",
            "   ✅ Trained 2026/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:44 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2051/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:47 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2076/3313 models\n",
            "   ✅ Trained 2101/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:49 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:23:50 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:23:50 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2126/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:51 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:23:51 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:23:52 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2151/3313 models\n",
            "   ✅ Trained 2201/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:57 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2226/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:23:59 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2251/3313 models\n",
            "   ✅ Trained 2301/3313 models\n",
            "   ✅ Trained 2326/3313 models\n",
            "   ✅ Trained 2351/3313 models\n",
            "   ✅ Trained 2376/3313 models\n",
            "   ✅ Trained 2401/3313 models\n",
            "   ✅ Trained 2426/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:24:09 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:24:09 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2451/3313 models\n",
            "   ✅ Trained 2476/3313 models\n",
            "   ✅ Trained 2501/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:24:22 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2526/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:24:25 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:24:26 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2576/3313 models\n",
            "   ✅ Trained 2601/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:24:31 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:24:32 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2651/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:24:33 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2676/3313 models\n",
            "   ✅ Trained 2701/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:24:38 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2726/3313 models\n",
            "   ✅ Trained 2751/3313 models\n",
            "   ✅ Trained 2776/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:25:02 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:25:03 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2851/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:25:06 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "14:25:07 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 2876/3313 models\n",
            "   ✅ Trained 2901/3313 models\n",
            "   ✅ Trained 2926/3313 models\n",
            "   ✅ Trained 2951/3313 models\n",
            "   ✅ Trained 2976/3313 models\n",
            "   ✅ Trained 3001/3313 models\n",
            "   ✅ Trained 3026/3313 models\n",
            "   ✅ Trained 3051/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:25:24 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 3076/3313 models\n",
            "   ✅ Trained 3101/3313 models\n",
            "   ✅ Trained 3126/3313 models\n",
            "   ✅ Trained 3176/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:25:43 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Trained 3226/3313 models\n",
            "   ✅ Trained 3251/3313 models\n",
            "   ✅ Trained 3276/3313 models\n",
            "   ✅ Trained 3301/3313 models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:25:54 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Operation not permitted\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Prophet training complete!\n",
            "   🎯 Successful models: 3167\n",
            "   ❌ Failed models: 146\n",
            "\n",
            "🔮 Step 4: Making predictions...\n",
            "🔮 Making Prophet predictions...\n",
            "✅ Predictions complete!\n",
            "   🎯 Successful predictions: 83962\n",
            "   ❌ Failed/fallback predictions: 352\n",
            "\n",
            "📊 Step 5: Calculating metrics...\n",
            "\n",
            "============================================================\n",
            "🎯 EXPERIMENT 9 RESULTS SUMMARY\n",
            "============================================================\n",
            "📊 Validation Metrics:\n",
            "   WMAE (Competition Metric): $1,871.08\n",
            "   MAE: $1,819.20\n",
            "   RMSE: $3,786.26\n",
            "   R²: 0.9702\n",
            "\n",
            "📊 Holiday Breakdown:\n",
            "   Holiday MAE: $2,239.76 (2,966 samples)\n",
            "   Non-Holiday MAE: $1,803.86 (81,348 samples)\n",
            "\n",
            "📊 Model Statistics:\n",
            "   Successful models trained: 3,167\n",
            "   Store-Dept combinations: 3,313\n",
            "   Features used: 25\n",
            "   Regressors per model: 5\n",
            "\n",
            "💾 Saving model artifacts...\n",
            "✅ Experiment 9 completed successfully!\n",
            "🏃 View run Prophet_Exp7_Features_Complete at: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/36/runs/7ac70aa921df495d82525d6415ca9c53\n",
            "🧪 View experiment at: https://dagshub.com/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/36\n",
            "\n",
            "🎉 Experiment 9: Prophet with Experiment 7 Features - COMPLETE!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}