ჩვენი საწყისი მიდგომა გულისხმობს Random Forest რეგრესორის გამოყენებას, რადგან ის არის მძლავრი, მოქნილი და კარგად უმკლავდება როგორც რიცხვით, ისე კატეგორიულ მახასიათებლებს.

კონკურსის ძირითადი მიზანია რაც შეიძლება ზუსტი პროგნოზების მიღება Weekly_Sales (ყოველკვირეული გაყიდვების) ველისთვის.

ჩვენი მოდელის შეფასება ხდება WMAE  მეტრიკის გამოყენებით.
ამ მეტრიკის მიხედვით, დღესასწაულების კვირებს 5 ჯერ მეტი წონა აქვს, ვიდრე არასადღესასწაულოს. 

მონაცემთა ნაკრები (Dataset)
პროექტი იყენებს Walmart-ის გაყიდვების კონკურსის მონაცემთა ნაკრებს, რომელიც შედგება 4 ცალკეული .csv ფაილისგან:
train.csv: მოიცავს ისტორიულ გაყიდვებს (Weekly_Sales) 2010-02-05-დან 2012-11-01-მდე, მაღაზიის და დეპარტამენტის ID-ს, თარიღს და IsHoliday დროშას.
test.csv: იდენტური სტრუქტურისაა train.csv-ის, მაგრამ Weekly_Sales ველის გარეშე. ეს არის ის მონაცემები, რომლებზეც პროგნოზირება გვჭირდება კონკურსისთვის. (შენიშვნა: ამჟამინდელ ვერსიაში ეს ფაილი არ გამოიყენება. სამაგიეროდ, train.csv იყოფა ლოკალურ სასწავლო, ვალიდაციისა და ტესტირების ნაწილებად.)
features.csv: შეიცავს დამატებით ინფორმაციას თარიღის, მაღაზიის, ტემპერატურის, საწვავის ფასის, CPI-ის, უმუშევრობის დონის და MarkDown მონაცემების (MarkDown1-5) შესახებ. MarkDown მონაცემებს ხშირად აქვს ბევრი გამოტოვებული მნიშვნელობა.
stores.csv: მოიცავს სტატიკურ ინფორმაციას თითოეული მაღაზიის შესახებ: მაღაზიის ტიპი (Type) და ზომა (Size).


RandomForest_Preprocessing_&_FeatureEngineering Run
ეს ეტაპი მოიცავს მონაცემთა მომზადებას და ახალი მახასიათებლების შექმნას Random Forest მოდელისთვის.
მონაცემთა ჩატვირთვა და გაერთიანება: თავდაპირველად იტვირთება train.csv, features.csv და stores.csv ფაილები და ერთიანდება train_merged DataFrame-ში.

თარიღის მახასიათებლების შექმნა: Date სვეტიდან ამოღებულია დროზე დამოკიდებული მახასიათებლები, როგორიცაა წელი (Year), თვე (Month), კვირა (Week), კვირის დღე (DayOfWeek), წლის დღე (DayOfYear), თვის დასაწყისი/ბოლო (IsMonthStart, IsMonthEnd) და დროის ინდექსი (TimeIdx).

უარყოფითი გაყიდვების დამუშავება: Weekly_Sales ველში არსებული უარყოფითი მნიშვნელობები (რომლებიც შეიძლება დაბრუნებებს ნიშნავდეს) იცვლება 0-ით.

გამოტოვებული მნიშვნელობების დამუშავება (MarkDowns): MarkDown1-5 სვეტებში არსებული NaN მნიშვნელობები ივსება 0-ით. ეს მიანიშნებს, რომ მოცემულ პერიოდში სარეკლამო აქცია არ ყოფილა აქტიური.

კატეგორიული მახასიათებლების კოდირება: Type (მაღაზიის ტიპი A, B, C) სვეტი გარდაიქმნება One-Hot Encoding-ის გამოყენებით. Store და Dept სვეტები ამ ეტაპზე განიხილება როგორც რიცხვითი ID-ები Random Forest-ისთვის.

მონაცემთა გაყოფა (ქრონოლოგიური): train_merged მონაცემთა ნაკრები ქრონოლოგიურად იყოფა სამ ნაწილად:
სასწავლო ნაკრები (Training Set): მონაცემების 60%.
ვალიდაციის ნაკრები (Validation Set): მონაცემების მომდევნო 20%.
ლოკალური ტესტირების ნაკრები (Local Test Set): მონაცემების ბოლო 20%. ეს გაყოფა უზრუნველყოფს, რომ ჩვენი შეფასება რეალისტური იყოს დროითი სერიების პროგნოზირებისთვის, რადგან მოდელი ყოველთვის ახდენს პროგნოზირებას მომავალი მონაცემებისთვის.


RandomForest_Training_&_Evaluation Run
ეს ეტაპი მოიცავს Random Forest მოდელის სწავლებას და მის შეფასებას შიდა ვალიდაციისა და ლოკალური ტესტირების ნაკრებებზე.
მოდელის ინსტანცირება: გამოიყენება sklearn.ensemble.RandomForestRegressor 100 ესტიმატორით (n_estimators=100) და random_state=42 რეპროდუცირებადობისთვის. n_jobs=-1 უზრუნველყოფს ყველა ხელმისაწვდომი CPU ბირთვის გამოყენებას.
ტრენინგი: მოდელი წვრთნება სასწავლო ნაკრებზე (X_train, y_train).
პროგნოზირება: პროგნოზები კეთდება როგორც ვალიდაციის, ისე ლოკალური ტესტირების ნაკრებებზე. ყველა პროგნოზი, რომელიც უარყოფითია, იცვლება 0-ით, რადგან გაყიდვები არ შეიძლება იყოს უარყოფითი.
შეფასება: გამოითვლება WMAE და MAE ვალიდაციისა და ლოკალური ტესტირების ნაკრებებზე. IsHoliday დროშა გამოიყენება WMAE-ის გამოსათვლელად სწორი წონების მისაცემად.


მოდელის პირველი გაშვების შედეგები შიდა ვალიდაციისა და ლოკალური ტესტირების ნაკრებებზე:
Evaluating on Validation Set...
Validation WMAE: 3035.2597
Validation MAE: 2816.7839

Evaluating on Local Test Set...
Local Test WMAE: 2564.8268
Local Test MAE: 2543.5857


აღსანიშნავია, რომ ლოკალური ტესტირების ნაკრებზე მიღებული WMAE უკეთესია (დაბალია), ვიდრე ვალიდაციის ნაკრებზე მიღებული. ეს შეიძლება გამოწვეული იყოს მონაცემთა გაყოფის სპეციფიკით ან იმით, რომ ლოკალური ტესტირების პერიოდი (თუმცა უფრო გვიანია) შესაძლოა ნაკლებად რთულ დღესასწაულებს ან ანომალიებს შეიცავს, ვიდრე ვალიდაციის პერიოდი. ეს არის კარგი საწყისი წერტილი შემდგომი გაუმჯობესებისთვის.

——————————————————————————————————————-
მეორე ექსპეტიმენტი RandomForest-ზე, გაუმჯობესება!

CPI-სა და Unemployment-ში გამოტოვებული მნიშვნელობების დახვეწილი დამუშავება:
ცვლილება: NaN (გამოტოვებული) მნიშვნელობები ამ სვეტებში ახლა ივსება დახვეწილი სტრატეგიით: მონაცემები ჯგუფდება Store-ის მიხედვით, შემდეგ გამოიყენება ffill() (წინა მნიშვნელობით შევსება) და bfill() (შემდეგი მნიშვნელობით შევსება). ნებისმიერი დარჩენილი NaN უსაფრთხოების მიზნით ივსება გლობალური მედიანით.
გაუმჯობესება: ეს მიდგომა იყენებს მაკროეკონომიკური ინდიკატორების დროით სერიულ ბუნებას, ავსებს ხარვეზებს მაღაზიის რეგიონისთვის ცნობილი უახლოესი  მნიშვნელობით, რაც უფრო ზუსტია, ვიდრე უბრალო გლობალური მედიანით შევსება.

დროითი სერიების მოწინავე მახასიათებლების შემოტანა:
ცვლილება: დაემატა რამდენიმე ახალი მახასიათებელი, რომლებიც უშუალოდ ასახავს გაყიდვების ტენდენციებსა და სეზონურობას.
Lag_Weekly_Sales: წინა კვირის გაყიდვები იმავე მაღაზიისა და დეპარტამენტისთვის.
Lag52_Weekly_Sales: გაყიდვები წინა წლის იმავე კვირიდან (52 კვირით ადრე) იმავე მაღაზიისა და დეპარტამენტისთვის, რაც წლიურ სეზონურობას ითვალისწინებს.
RollingMean_4W_Sales: ბოლო 4 კვირის გაყიდვების მოძრავი საშუალო (გადატანილია ერთი კვირით წინ მონაცემთა გაჟონვის თავიდან ასაცილებლად).
RollingStd_4W_Sales: ბოლო 4 კვირის გაყიდვების მოძრავი სტანდარტული გადახრა (ასევე გადატანილი).
გაუმჯობესება: ეს მახასიათებლები Random Forest მოდელს აწვდის ძლიერ ინფორმაციას ტრენდების აღბეჭდვისთვის, სეზონურობის ნაწილობრივი აღბეჭდვისთვის, რაც ფუნდამენტურია ზუსტი დროითი სერიების პროგნოზირებისთვის. ლაგირებით წარმოქმნილი გამოტოვებული მნიშვნელობები შეივსო 0-ით.

ვერსია 2.0-ის შედეგები (ახალი მახასიათებლებით და დახვეწილი წინასწარი დამუშავებით):
ვალიდაციის WMAE: 1873.3626

ვალიდაციის MAE: 1692.2703

ლოკალური ტესტის WMAE: 1578.4943

ლოკალური ტესტის MAE: 1407.5672

რაოდენობრივი გაუმჯობესება:

ვალიდაციის WMAE გაუმჯობესდა დაახლოებით 38.3%-ით (3035-დან 1873-მდე).\

ლოკალური ტესტის WMAE გაუმჯობესდა დაახლოებით 38.5%-ით (2565-დან 1578-მდე).

ჯერჯერობით წინსვლა გვაქ შეგვიძლია ვთქვათ

------------------------------------------------
მესამე ექსპეტიმენტი RandomForest-ზე, გაუმჯობესება!

გაყოფის პრინციპი შენარჩუნებულია, მაგრამ დამატებულია "პარასკევის გასწორება" (Friday Alignment). ეს ნიშნავს, რომ გაყოფის თარიღები ზუსტდება უახლოეს პარასკევზე. ეს კრიტიკულად მნიშვნელოვანია ყოველკვირეული გაყიდვების მონაცემებისთვის, რათა ვალიდაციის და ტესტის ნაკრებებმა ზუსტად დაიწყოს ახალი სრული კვირა, რაც ხელს უშლის მონაცემთა გაჟონვას და უზრუნველყოფს უფრო რეალისტურ შეფასებას.

ციკლური თარიღის მახასიათებლები: დამატებულია ახალი მახასიათებლები: Month_sin და Month_cos. ეს ტრანსფორმაციები Random Forest-ს აძლევს უკეთეს საშუალებას, გაიგოს სეზონურობა და თვეების ციკლური ბუნება, რაც ხშირად აუმჯობესებს პროგნოზირების სიზუსტეს.

Weekly_Sales-ში უარყოფითი მნიშვნელობები კვლავ ნულდება.

MarkDown სვეტებში NaN მნიშვნელობები კვლავ ნულდება.

CPI და Unemployment სვეტებში NaN მნიშვნელობები ივსება ffill() და bfill()-ით მაღაზიის მიხედვით, შემდეგ კი დარჩენილი NaN-ები მედიანით.

წინასწარი დამუშავების Pipeline: ColumnTransformer გამოიყენება კატეგორიული (Type სვეტის One-Hot Encoding) და რიცხვითი მახასიათებლების დასამუშავებლად.

RandomizedSearchCV გამოიყენება Random Forest-ის ოპტიმალური ჰიპერპარამეტრების მოსაძებნად. დროითი სერიების ვალიდაციისთვის გამოიყენება TimeSeriesSplit.

უბრალოდ ის არი რო, random_search.fit(X_train, y_train) ამას ანდომებს უაზროდ ბევრ დროს რა, ხოდა ჯერ ვერ მივხვდი რატომ.

ნუ დაამთავრა და შედეგი აჩვენა ასეთი:

Validation WMAE: 1805.7305 (Improved!)

Validation MAE: 1615.0387 (Improved!)

Local Test WMAE: 1490.7268 (Improved!)

Local Test MAE: 1307.3495 (Improved!)



--------------------------------------------------
# model_exp_Prophet_1

მოდელი გატრენინგდა ისტორიული ტრენინგისა და ვალიდაციის მონაცემების კომბინირებულ ნაკრებზე, შემდეგ კი შეფასდა ცალკე, უცნობ სატესტო მონაცემთა ნაკრებზე.

train_ts და val_ts მონაცემთა ნაკრებები გაერთიანებულია უფრო დიდი combined_train_val_df-ის შესაქმნელად, რომელიც გამოიყენება მოდელის საბოლოო ტრენინგისთვის.

სვეტების სახელები (Date-დან ds-ზე, Weekly_Sales-დან y-ზე) მორგებულია Prophet-ის მოთხოვნებთან.

test_ts მონაცემთა ნაკრები მზადდება out-of-sample პროგნოზირებისთვის.

სკრიპტი იმეორებს combined_train_val_df-ში არსებულ თითოეულ უნიკალურ (Store, Dept) კომბინაციას.

თითოეული სერიისთვის, Prophet მოდელი ინიციალიზდება კონკრეტული კონფიგურაციებით (წლიური/ყოველკვირეული სეზონურობა, მულტიპლიკაციური სეზონურობის რეჟიმი, ხაზოვანი ზრდა).

ყველა შესაბამისი წინასწარ დამუშავებული ფუნქცია (მაგ., IsHoliday, Temperature, Fuel_Price, CPI, Unemployment, Type_Encoded, Size) დამატებულია, როგორც დამატებითი რეგრესორები Prophet მოდელში.

გამძლეობის შემოწმება: სერიები MIN_OBSERVATIONS_FOR_PROPHET-ზე (დაყენებულია 50-ზე) ნაკლები დაკვირვებით გამოტოვებულია და მათი პროგნოზები ნულდება. შეცდომების დამუშავება ხორციელდება Prophet.fit() ან Prophet.predict() პოტენციური შეცდომების თავიდან ასაცილებლად, პრობლემური სერიებისთვის პროგნოზების ნულამდე დაყენებით.
მეტრიკის გამოთვლა: საშუალო აბსოლუტური შეცდომა (MAE), ფესვი საშუალო კვადრატული შეცდომიდან (RMSE) და შეწონილი საშუალო აბსოლუტური შეცდომა (WMAE) გამოითვლება როგორც კომბინირებული სატრენინგო ნაკრებისთვის (in-sample), ასევე სატესტო ნაკრებისთვის (out-of-sample).

დიაგნოსტიკური ანალიზები:

სადღესასწაულო კვირის ანალიზი: გვაწვდის სადღესასწაულო კვირების რაოდენობასა და პროცენტებს როგორც ტრენინგის, ასევე ტესტირების მონაცემთა ნაკრებებში.

თარიღის დაფარვა: ამოწმებს ტრენინგისა და ტესტირების პერიოდების თარიღების დიაპაზონებს და უწყვეტობას.

პროგნოზების დეტალური ანალიზი (ტესტის ნაკრები):

იქმნება predictions_comparison DataFrame, რომელიც აერთიანებს რეალურ გაყიდვებს, პროგნოზირებულ გაყიდვებს და გამოთვლილ შეცდომებს სატესტო ნაკრებისთვის.

ნაჩვენებია შეცდომის ყოვლისმომცველი სტატისტიკა (საშუალო, მედიანა, პროცენტულები, მინ/მაქს).

გაყიდვების შეცდომის განაწილების დაყოფა აბსოლუტური შეცდომის დიაპაზონების მიხედვით (<$1K, $1K-$2.5K და ა.შ.) მოწოდებულია იმის საჩვენებლად, თუ სად ხდება შეცდომების უმეტესობა.

სადღესასწაულო vs. არასადღესასწაულო დღეების შესრულება: შეცდომის მეტრიკები დაჯგუფებულია IsHoliday დროშის მიხედვით, რათა გავიგოთ შესრულების განსხვავებები სადღესასწაულო კვირების განმავლობაში.

# შედეგები

საბოლოო ტესტირების ფაზა ავლენს მოდელის მუშაობის მნიშვნელოვან ცვლილებას ვალიდაციის ფაზასთან შედარებით:
rophet მოდელის აგრეგირებული შედეგები (საბოლოო ტესტირების ფაზა):

ტრენინგი (Train+Val In-Sample):

MAE: $2,463.04

RMSE: $6,697.10

WMAE: $2,759.62

ტესტირება (Test Out-of-Sample):

MAE: $15,535.41

RMSE: $26,635.84

WMAE: $15,697.87

ტრენინგი: 2010-02-05-დან 2012-07-13-მდე

ტესტირება: 2012-07-20-დან 2012-10-26-მდე

დროის სერიების უწყვეტი დაყენება დადასტურებულია.

ძააააააალიან ცუდი შედეგია. ძააააალიან.



-------------------------------------------------------
# model_exp_prophet_2


მონაცემთა წინასწარი დამუშავების პაიპლაინი:

მონაცემთა ჩატვირთვა და გაერთიანება: აერთიანებს train, stores და features მონაცემთა ნაკრებებს Store-სა და Date-ის საფუძველზე.

მონაცემთა გაწმენდა: აგვარებს IsHoliday დუბლიკატი სვეტების პრობლემას, რომელიც გაერთიანების შედეგად ჩნდება.

თარიღის ფიჩერების ინჟინერია: ამოაქვს სხვადასხვა დროითი ფიჩერები Date სვეტიდან (წელი, თვე, დღე, კვირის დღე, წლის კვირა, კვარტალი, შაბათ-კვირაა თუ არა, თვის/კვარტლის დასაწყისი/დასასრული, დღეები/კვირები დაწყებიდან).

დღესასწაულის ფიჩერების ინჟინერია: ქმნის მკაფიო ბინარულ ინდიკატორებს აშშ-ის ძირითადი დღესასწაულებისთვის (Super Bowl, Labor Day, Thanksgiving, Christmas) და უფრო ფართო სადღესასწაულო პერიოდებისთვის (IsMajorHoliday, IsHolidayMonth, IsBackToSchool).

კატეგორიული დაშიფვრა: Type მაღაზიის ტიპს (A, B, C) ახდენს One-hot და Label დაშიფვრას (Type_A, Type_B, Type_C, Type_Encoded).

Lag ფიჩერები (გამორთულია): ოვერფიტინგის თავიდან ასაცილებლად, როგორც ამ ექსპერიმენტის დიზაინში იყო გათვალისწინებული, Lag ფიჩერები აშკარად გამორთული იყო.

აუტლაიერების ამოღება: განსაზღვრული ზღვრების გამოყენებით Weekly_Sales-დან აუტლაიერებს ხსნის მხოლოდ ტრენინგის მონაცემებიდან, მაღაზიის ტიპის (A, B, C) მიხედვით. ამ კონკრეტულ გაშვებაში 0 აუტლაიერი იქნა ამოღებული, რაც მიუთითებს, რომ განსაზღვრული ზღვრები ან მონაცემთა განაწილება არ გამოიწვია ამოღებები გაყიდვების მნიშვნელობებზე დაყრდნობით.

მარკდაუნის ფიჩერების ამოღება: ყველა MarkDown სვეტი ამოღებულ იქნა, რადგან ისინი არ იყო განკუთვნილი Prophet მოდელის ამ კონფიგურაციაში გამოსაყენებლად.

ჭარბი ფიჩერების ამოღება: ამოღებულია გარკვეული ფიჩერები, როგორიცაა Year, Quarter, Day, IsQuarterStart, IsQuarterEnd, რომლებიც მიჩნეულ იქნა ჭარბად ან პოტენციურად კოლინეარულად Prophet-ის შიდა სეზონურობის კომპონენტებთან.


დროის დატის გაყოფა: 
გაყოფის კოეფიციენტი: დაახლოებით 80% ტრენინგისთვის და 20% ვალიდაციისთვის.

გაყოფის თარიღი: 2012-04-13 00:00:00

ტრენინგის მონაცემები: 337,256 ჩანაწერი, 2010-02-05 00:00:00-დან 2012-04-13 00:00:00-მდე.

ვალიდაციის მონაცემები: 84,314 ჩანაწერი, 2012-04-13 00:00:00-დან 2012-10-26 00:00:00-მდე.

სერიების დონის Prophet მოდელირება
Prophet მოდელები ინდივიდუალურად გატრენინგდა ტრენინგის მონაცემებში აღმოჩენილი თითოეული უნიკალური მაღაზია-განყოფილების კომბინაციისთვის. ეს მიდგომა იძლევა მაღალპერსონალიზებული პროგნოზების საშუალებას, რომლებიც მორგებულია თითოეული გაყიდვების სერიის სპეციფიკურ ნიმუშებზე.

იდენტიფიცირებული სერიების ჯამური რაოდენობა: 3082 უნიკალური მაღაზია-განყოფილების კომბინაცია.

მინიმალური დაკვირვებები: სერიას სჭირდებოდა მინიმუმ 50 დაკვირვება, რათა Prophet-ის მიერ გატრენინგებულიყო. ნაკლები დაკვირვების მქონე სერიები გამოტოვებული იყო, ხოლო მათი ვალიდაციის გაყიდვები პროგნოზირებულ იქნა როგორც 0.

იდენტიფიცირებული სერიების ჯამური რაოდენობა 3082

გატრენინგებული სერიები 2615

გამოტოვებული სერიები (ძალიან მოკლე) 467

ვერ გატრენინგდა 0

ვერ განახორციელა პროგნოზი (ვალიდაცია) 0

ტრენინგი:
WMAE: 1439.43

RMSE: 2831.60

MAE: 1388.21

R²: 0.9246

ვალიდაცია:
WMAE: 6178.43 ⭐

RMSE: 19636.79

MAE: 6141.23

R²: -1.1195

მაღალი ოვერფიტინგი.
უარყოფითი R² ნიშნავს, რომ მოდელის პროგნოზები უარესია, ვიდრე უბრალოდ ვალიდაციის მონაცემების საშუალოს პროგნოზირება.
--------------------------------------------------------------
## model_exp_LightGBM_1.

იგივე WalmartPreprocessingPipeline იქნა გამოყენებული, რაც Prophet ექსპერიმენტში. ეს უზრუნველყოფს თანმიმდევრულობას ფიჩერების ინჟინერიასა და მონაცემთა გაწმენდაში. ნაბიჯები მოიცავს:

მონაცემთა ჩატვირთვა და გაერთიანება

მონაცემთა გაწმენდა (duplicate IsHoliday სვეტების მოგვარება)

თარიღის ფიჩერების ინჟინერია (Year, Month, Day, DayOfWeek, WeekOfYear, Quarter, IsWeekend, IsMonthStart/End, Days/WeeksFromStart)

დღესასწაულის ფიჩერების ინჟინერია (IsSuperBowlWeek, IsLaborDayWeek, IsThanksgivingWeek, IsChristmasWeek, IsMajorHoliday, IsHolidayMonth, IsBackToSchool)

კატეგორიული დაშიფვრა: Type სვეტი დაშიფრულია One-hot (Type_A, Type_B, Type_C) და Label (Type_Encoded) მეთოდებით. LightGBM-ისთვის, Type_Encoded და One-Hot კოდირებული სვეტები გამოყენებული იქნება როგორც ცალკეული ფიჩერები. Store და Dept სვეტები ასევე იქნება გამოყენებული როგორც კატეგორიული ფიჩერები.

Lag ფიჩერები (გამორთულია): რჩება გამორთული ოვერფიტინგის თავიდან ასაცილებლად.

მარკდაუნის ფიჩერების ამოღება: ყველა MarkDown სვეტი ამოღებულია.

ჭარბი ფიჩერების ამოღება: ზოგიერთი დროითი ფიჩერი, რომელიც შესაძლოა ჭარბი იყოს.

# დროითი მონაცემების დაყოფა

მონაცემთა ნაკრები დაიყო ტრენინგისა და ვალიდაციის ნაკრებებად ზუსტად ისე, როგორც წინა ექსპერიმენტში, დროითი გაყოფის გამოყენებით:

გაყოფის კოეფიციენტი: დაახლოებით 80% ტრენინგისთვის, 20% ვალიდაციისთვის.

გაყოფის თარიღი: 2012-04-13 00:00:00

ტრენინგის მონაცემები: 2010-02-05 00:00:00-დან 2012-04-13 00:00:00-მდე.

ვალიდაციის მონაცემები: 2012-04-13 00:00:00-დან 2012-10-26 00:00:00-მდე.

# გლობალური LightGBM მოდელი
Prophet-ისგან განსხვავებით, რომელიც მოდელებს ინდივიდუალურად ატრენინგებს თითოეული სერიისთვის, LightGBM-ის მიდგომა გულისხმობს ერთი გლობალური მოდელის ტრენინგს, რომელიც სწავლობს ყველა Store-Department კომბინაციის მონაცემებს ერთდროულად. Store და Dept ID-ები შეყვანილია როგორც კატეგორიული ფიჩერები, რაც მოდელს საშუალებას აძლევს ისწავლოს თითოეული მაღაზიისა და განყოფილების სპეციფიკური ნიმუშები.

{
    'objective': 'regression_l1', # MAE ობიექტური ფუნქცია, უფრო მდგრადია აუტლაიერების მიმართ
    'metric': 'mae',
    'n_estimators': 1000,
    'learning_rate': 0.05,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 1,
    'lambda_l1': 0.1,
    'lambda_l2': 0.1,
    'num_leaves': 31,
    'verbose': -1, # არ აჩვენებს პროგრესს
    'n_jobs': -1, # იყენებს ყველა ხელმისაწვდომ ბირთვს
    'seed': 42,
    'boosting_type': 'gbdt',
    'early_stopping_round': 50 # შეაჩერებს ტრენინგს, თუ ვალიდაციის მეტრიკა 50 რაუნდის განმავლობაში არ გაუმჯობესდება
}

ფიჩერების შერჩევა
Prophet-ისგან განსხვავებით, LightGBM-ს შეუძლია უშუალოდ გამოიყენოს მეტი ფიჩერი. Date და Weekly_Sales სვეტების გარდა, LightGBM მოდელი იყენებს ყველა სხვა სვეტს, როგორც საპროგნოზო ფიჩერებს:

კატეგორიული ფიჩერები: Store, Dept, Type_A, Type_B, Type_C, Type_Encoded, Month, DayOfWeek, WeekOfYear, IsHoliday, IsWeekend, IsMonthStart, IsMonthEnd, IsSuperBowlWeek, IsLaborDayWeek, IsThanksgivingWeek, IsChristmasWeek, IsMajorHoliday, IsHolidayMonth, IsBackToSchool.

რიცხვითი ფიჩერები: Size, Temperature, Fuel_Price, CPI, Unemployment, DaysFromStart, WeeksFromStart.

# შედეგები

აგრირებული ტრენინგის მეტრიკები (In-Sample)

WMAE: 1554.33

RMSE: 3251.47

MAE: 1464.41

R²: 0.9481

აგრირებული ვალიდაციის მეტრიკები (Out-of-Sample)

WMAE: 1663.04 ⭐ (კონკურსის მთავარი მეტრიკა)

RMSE: 3359.20

MAE: 1654.74

R²: 0.9449

რა თქმა უნდა! შესანიშნავი შედეგებია. LightGBM მოდელმა აჩვენა ძალიან კარგი შესრულება, დაბალი WMAE-ით და მაღალი R²-ით, მინიმალური ოვერფიტინგით.

