{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konstantine25b/Walmart-Recruiting---Store-Sales-Forecasting/blob/lodia/model_exp_RandomForest_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the kaggle python library"
      ],
      "metadata": {
        "id": "7lvdgeEMgCoy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlwSaX9akGfG",
        "outputId": "650f89a4-913f-41aa-eeb0-6c11061e9f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the Google drive so you can store your kaggle API credentials for future use"
      ],
      "metadata": {
        "id": "rw0DfSAggHED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGineQt7dErh",
        "outputId": "18e853e4-1d22-4d3a-eb4d-69f4afba1eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a directory for kaggle at the temporary instance location on Colab drive.\n",
        "\n",
        "Download your kaggle API key (.json file). You can do this by going to your kaggle account page and clicking 'Create new API token' under the API section."
      ],
      "metadata": {
        "id": "Rvmi3WbigOmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vhywUxLXgjBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ZTkKggcylXfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to copy the kaggle API credentials to the temporary location... (I recommend placing it on your Google Drive)"
      ],
      "metadata": {
        "id": "rKv_7jNggXv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "DD56NrWmlb5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the json file to Google Drive and then copy to the temporary location."
      ],
      "metadata": {
        "id": "p3N4it0xrFmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "IQq6ZMyTrEfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the file permissions to read/write to the owner only"
      ],
      "metadata": {
        "id": "p3dHJgtLehrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "7ncAtrq2lg5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Competitions and Datasets are the two types of Kaggle data**"
      ],
      "metadata": {
        "id": "Rb3Zm9VMlu3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Download competition data**\n",
        "\n",
        "If you get 403 Forbidden error, you need to click 'Late Submission' on the Kaggle page for that competition."
      ],
      "metadata": {
        "id": "OrdSFfGjl3Ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c walmart-recruiting-store-sales-forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0yNdtoRln8A",
        "outputId": "c5de5e4e-701f-4aba-98e7-084c6ab0461d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading walmart-recruiting-store-sales-forecasting.zip to /content\n",
            "\r  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "\r100% 2.70M/2.70M [00:00<00:00, 443MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip, in case the downloaded file is zipped. Refresh the files on the left hand side to update the view."
      ],
      "metadata": {
        "id": "fRmXZnHghNAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip walmart-recruiting-store-sales-forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAs9oVnNoziL",
        "outputId": "9ed3ffb8-8438-4641-8e30-0d3d0098add1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  walmart-recruiting-store-sales-forecasting.zip\n",
            "  inflating: features.csv.zip        \n",
            "  inflating: sampleSubmission.csv.zip  \n",
            "  inflating: stores.csv              \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To downloaad specific files, instead of the netire data set\n",
        "\n"
      ],
      "metadata": {
        "id": "ePE1ItOFpPYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "path = \"/content/\"\n",
        "\n",
        "\n",
        "files_to_unzip = [\n",
        "    \"features.csv.zip\",\n",
        "    \"test.csv.zip\",\n",
        "    \"train.csv.zip\",\n",
        "    \"sampleSubmission.csv.zip\"\n",
        "]\n",
        "\n",
        "print(\"Checking and unzipping individual files...\")\n",
        "for file_name in files_to_unzip:\n",
        "    full_path = os.path.join(path, file_name)\n",
        "    if os.path.exists(full_path):\n",
        "        try:\n",
        "            with zipfile.ZipFile(full_path, 'r') as zip_ref:\n",
        "\n",
        "                zip_ref.extractall(path)\n",
        "            print(f\"Successfully unzipped: {file_name}\")\n",
        "\n",
        "        except zipfile.BadZipFile:\n",
        "            print(f\"Warning: {file_name} is not a valid zip file or already unzipped/corrupted.\")\n",
        "    else:\n",
        "        print(f\"Info: {file_name} not found, likely already unzipped or not present.\")\n"
      ],
      "metadata": {
        "id": "7lYOoWxeF0DS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5558949-69e0-41c6-8b4a-c56be4bb66f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking and unzipping individual files...\n",
            "Successfully unzipped: features.csv.zip\n",
            "Successfully unzipped: test.csv.zip\n",
            "Successfully unzipped: train.csv.zip\n",
            "Successfully unzipped: sampleSubmission.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    train_df = pd.read_csv(path + \"train.csv\")\n",
        "    test_df = pd.read_csv(path + \"test.csv\")\n",
        "    features_df = pd.read_csv(path + \"features.csv\")\n",
        "    stores_df = pd.read_csv(path + \"stores.csv\")\n",
        "    print(\"All datasets loaded successfully!\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading file: {e}. Please check the 'path' variable.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o32yshpwAwzC",
        "outputId": "96f25300-ae65-44fe-c656-9fa471098816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All datasets loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- train_df ---\")\n",
        "print(\"Shape:\", train_df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nInfo (data types, non-null counts):\")\n",
        "train_df.info()\n",
        "print(\"\\nDescriptive statistics:\")\n",
        "print(train_df.describe())\n",
        "print(\"\\nUnique stores and departments:\")\n",
        "print(f\"Number of unique stores: {train_df['Store'].nunique()}\")\n",
        "print(f\"Number of unique departments: {train_df['Dept'].nunique()}\")\n",
        "print(\"\\nCheck for missing values:\")\n",
        "print(train_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-AOTSXyCxSI",
        "outputId": "74875e2c-0ce3-4fe3-9260-c0564dc1c39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- train_df ---\n",
            "Shape: (421570, 5)\n",
            "\n",
            "First 5 rows:\n",
            "   Store  Dept        Date  Weekly_Sales  IsHoliday\n",
            "0      1     1  2010-02-05      24924.50      False\n",
            "1      1     1  2010-02-12      46039.49       True\n",
            "2      1     1  2010-02-19      41595.55      False\n",
            "3      1     1  2010-02-26      19403.54      False\n",
            "4      1     1  2010-03-05      21827.90      False\n",
            "\n",
            "Info (data types, non-null counts):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 421570 entries, 0 to 421569\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   Store         421570 non-null  int64  \n",
            " 1   Dept          421570 non-null  int64  \n",
            " 2   Date          421570 non-null  object \n",
            " 3   Weekly_Sales  421570 non-null  float64\n",
            " 4   IsHoliday     421570 non-null  bool   \n",
            "dtypes: bool(1), float64(1), int64(2), object(1)\n",
            "memory usage: 13.3+ MB\n",
            "\n",
            "Descriptive statistics:\n",
            "               Store           Dept   Weekly_Sales\n",
            "count  421570.000000  421570.000000  421570.000000\n",
            "mean       22.200546      44.260317   15981.258123\n",
            "std        12.785297      30.492054   22711.183519\n",
            "min         1.000000       1.000000   -4988.940000\n",
            "25%        11.000000      18.000000    2079.650000\n",
            "50%        22.000000      37.000000    7612.030000\n",
            "75%        33.000000      74.000000   20205.852500\n",
            "max        45.000000      99.000000  693099.360000\n",
            "\n",
            "Unique stores and departments:\n",
            "Number of unique stores: 45\n",
            "Number of unique departments: 81\n",
            "\n",
            "Check for missing values:\n",
            "Store           0\n",
            "Dept            0\n",
            "Date            0\n",
            "Weekly_Sales    0\n",
            "IsHoliday       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- test_df ---\")\n",
        "print(\"Shape:\", test_df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(test_df.head())\n",
        "print(\"\\nInfo:\")\n",
        "test_df.info()\n",
        "print(\"\\nCheck for missing values:\")\n",
        "print(test_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9CoYip7GWC_",
        "outputId": "22014754-d2f9-4d0a-bdd1-61adcdbcff34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- test_df ---\n",
            "Shape: (115064, 4)\n",
            "\n",
            "First 5 rows:\n",
            "   Store  Dept        Date  IsHoliday\n",
            "0      1     1  2012-11-02      False\n",
            "1      1     1  2012-11-09      False\n",
            "2      1     1  2012-11-16      False\n",
            "3      1     1  2012-11-23       True\n",
            "4      1     1  2012-11-30      False\n",
            "\n",
            "Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 115064 entries, 0 to 115063\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count   Dtype \n",
            "---  ------     --------------   ----- \n",
            " 0   Store      115064 non-null  int64 \n",
            " 1   Dept       115064 non-null  int64 \n",
            " 2   Date       115064 non-null  object\n",
            " 3   IsHoliday  115064 non-null  bool  \n",
            "dtypes: bool(1), int64(2), object(1)\n",
            "memory usage: 2.7+ MB\n",
            "\n",
            "Check for missing values:\n",
            "Store        0\n",
            "Dept         0\n",
            "Date         0\n",
            "IsHoliday    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- features_df ---\")\n",
        "print(\"Shape:\", features_df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(features_df.head())\n",
        "print(\"\\nInfo:\")\n",
        "features_df.info()\n",
        "print(\"\\nDescriptive statistics:\")\n",
        "print(features_df.describe())\n",
        "print(\"\\nCheck for missing values:\")\n",
        "print(features_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RirH6viAGrC_",
        "outputId": "0e35c911-0816-4db3-8186-b95165cc687a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- features_df ---\n",
            "Shape: (8190, 12)\n",
            "\n",
            "First 5 rows:\n",
            "   Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
            "0      1  2010-02-05        42.31       2.572        NaN        NaN   \n",
            "1      1  2010-02-12        38.51       2.548        NaN        NaN   \n",
            "2      1  2010-02-19        39.93       2.514        NaN        NaN   \n",
            "3      1  2010-02-26        46.63       2.561        NaN        NaN   \n",
            "4      1  2010-03-05        46.50       2.625        NaN        NaN   \n",
            "\n",
            "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
            "0        NaN        NaN        NaN  211.096358         8.106      False  \n",
            "1        NaN        NaN        NaN  211.242170         8.106       True  \n",
            "2        NaN        NaN        NaN  211.289143         8.106      False  \n",
            "3        NaN        NaN        NaN  211.319643         8.106      False  \n",
            "4        NaN        NaN        NaN  211.350143         8.106      False  \n",
            "\n",
            "Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8190 entries, 0 to 8189\n",
            "Data columns (total 12 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Store         8190 non-null   int64  \n",
            " 1   Date          8190 non-null   object \n",
            " 2   Temperature   8190 non-null   float64\n",
            " 3   Fuel_Price    8190 non-null   float64\n",
            " 4   MarkDown1     4032 non-null   float64\n",
            " 5   MarkDown2     2921 non-null   float64\n",
            " 6   MarkDown3     3613 non-null   float64\n",
            " 7   MarkDown4     3464 non-null   float64\n",
            " 8   MarkDown5     4050 non-null   float64\n",
            " 9   CPI           7605 non-null   float64\n",
            " 10  Unemployment  7605 non-null   float64\n",
            " 11  IsHoliday     8190 non-null   bool   \n",
            "dtypes: bool(1), float64(9), int64(1), object(1)\n",
            "memory usage: 712.0+ KB\n",
            "\n",
            "Descriptive statistics:\n",
            "             Store  Temperature   Fuel_Price      MarkDown1      MarkDown2  \\\n",
            "count  8190.000000  8190.000000  8190.000000    4032.000000    2921.000000   \n",
            "mean     23.000000    59.356198     3.405992    7032.371786    3384.176594   \n",
            "std      12.987966    18.678607     0.431337    9262.747448    8793.583016   \n",
            "min       1.000000    -7.290000     2.472000   -2781.450000    -265.760000   \n",
            "25%      12.000000    45.902500     3.041000    1577.532500      68.880000   \n",
            "50%      23.000000    60.710000     3.513000    4743.580000     364.570000   \n",
            "75%      34.000000    73.880000     3.743000    8923.310000    2153.350000   \n",
            "max      45.000000   101.950000     4.468000  103184.980000  104519.540000   \n",
            "\n",
            "           MarkDown3     MarkDown4      MarkDown5          CPI  Unemployment  \n",
            "count    3613.000000   3464.000000    4050.000000  7605.000000   7605.000000  \n",
            "mean     1760.100180   3292.935886    4132.216422   172.460809      7.826821  \n",
            "std     11276.462208   6792.329861   13086.690278    39.738346      1.877259  \n",
            "min      -179.260000      0.220000    -185.170000   126.064000      3.684000  \n",
            "25%         6.600000    304.687500    1440.827500   132.364839      6.634000  \n",
            "50%        36.260000   1176.425000    2727.135000   182.764003      7.806000  \n",
            "75%       163.150000   3310.007500    4832.555000   213.932412      8.567000  \n",
            "max    149483.310000  67474.850000  771448.100000   228.976456     14.313000  \n",
            "\n",
            "Check for missing values:\n",
            "Store              0\n",
            "Date               0\n",
            "Temperature        0\n",
            "Fuel_Price         0\n",
            "MarkDown1       4158\n",
            "MarkDown2       5269\n",
            "MarkDown3       4577\n",
            "MarkDown4       4726\n",
            "MarkDown5       4140\n",
            "CPI              585\n",
            "Unemployment     585\n",
            "IsHoliday          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- stores_df ---\")\n",
        "print(\"Shape:\", stores_df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(stores_df.head())\n",
        "print(\"\\nInfo:\")\n",
        "stores_df.info()\n",
        "print(\"\\nDescriptive statistics:\")\n",
        "print(stores_df.describe())\n",
        "print(\"\\nUnique store types:\")\n",
        "print(stores_df['Type'].value_counts())\n",
        "print(\"\\nCheck for missing values:\")\n",
        "print(stores_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RQzgi1zH5UU",
        "outputId": "47dd7830-47b7-423e-dd27-73446f4347ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- stores_df ---\n",
            "Shape: (45, 3)\n",
            "\n",
            "First 5 rows:\n",
            "   Store Type    Size\n",
            "0      1    A  151315\n",
            "1      2    A  202307\n",
            "2      3    B   37392\n",
            "3      4    A  205863\n",
            "4      5    B   34875\n",
            "\n",
            "Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45 entries, 0 to 44\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Store   45 non-null     int64 \n",
            " 1   Type    45 non-null     object\n",
            " 2   Size    45 non-null     int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.2+ KB\n",
            "\n",
            "Descriptive statistics:\n",
            "           Store           Size\n",
            "count  45.000000      45.000000\n",
            "mean   23.000000  130287.600000\n",
            "std    13.133926   63825.271991\n",
            "min     1.000000   34875.000000\n",
            "25%    12.000000   70713.000000\n",
            "50%    23.000000  126512.000000\n",
            "75%    34.000000  202307.000000\n",
            "max    45.000000  219622.000000\n",
            "\n",
            "Unique store types:\n",
            "Type\n",
            "A    22\n",
            "B    17\n",
            "C     6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Check for missing values:\n",
            "Store    0\n",
            "Type     0\n",
            "Size     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
        "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
        "features_df['Date'] = pd.to_datetime(features_df['Date'])"
      ],
      "metadata": {
        "id": "RGrgeMpMLsWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged = pd.merge(train_df, features_df, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "train_merged = pd.merge(train_merged, stores_df, on=['Store'], how='left')"
      ],
      "metadata": {
        "id": "huVXi129LxrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_merged = pd.merge(test_df, features_df, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "test_merged = pd.merge(test_merged, stores_df, on=['Store'], how='left')"
      ],
      "metadata": {
        "id": "2qLfM629Np-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape:\", train_merged.shape)\n",
        "print(\"\\n--- Merged Training Data Sample ---\")\n",
        "print(train_merged.head())\n",
        "print(\"\\nMissing values in merged train data after initial merge:\")\n",
        "print(train_merged.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajgMjVZ9NvJa",
        "outputId": "b675300c-fcf6-4070-aea4-40a535e14eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (421570, 16)\n",
            "\n",
            "--- Merged Training Data Sample ---\n",
            "   Store  Dept       Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
            "0      1     1 2010-02-05      24924.50      False        42.31       2.572   \n",
            "1      1     1 2010-02-12      46039.49       True        38.51       2.548   \n",
            "2      1     1 2010-02-19      41595.55      False        39.93       2.514   \n",
            "3      1     1 2010-02-26      19403.54      False        46.63       2.561   \n",
            "4      1     1 2010-03-05      21827.90      False        46.50       2.625   \n",
            "\n",
            "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
            "0        NaN        NaN        NaN        NaN        NaN  211.096358   \n",
            "1        NaN        NaN        NaN        NaN        NaN  211.242170   \n",
            "2        NaN        NaN        NaN        NaN        NaN  211.289143   \n",
            "3        NaN        NaN        NaN        NaN        NaN  211.319643   \n",
            "4        NaN        NaN        NaN        NaN        NaN  211.350143   \n",
            "\n",
            "   Unemployment Type    Size  \n",
            "0         8.106    A  151315  \n",
            "1         8.106    A  151315  \n",
            "2         8.106    A  151315  \n",
            "3         8.106    A  151315  \n",
            "4         8.106    A  151315  \n",
            "\n",
            "Missing values in merged train data after initial merge:\n",
            "Store                0\n",
            "Dept                 0\n",
            "Date                 0\n",
            "Weekly_Sales         0\n",
            "IsHoliday            0\n",
            "Temperature          0\n",
            "Fuel_Price           0\n",
            "MarkDown1       270889\n",
            "MarkDown2       310322\n",
            "MarkDown3       284479\n",
            "MarkDown4       286603\n",
            "MarkDown5       270138\n",
            "CPI                  0\n",
            "Unemployment         0\n",
            "Type                 0\n",
            "Size                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape:\", test_merged.shape)\n",
        "print(\"\\n--- Merged Test Data Sample ---\")\n",
        "print(test_merged.head())\n",
        "print(\"\\nMissing values in merged test data after initial merge:\")\n",
        "print(test_merged.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xoi9a3NSOIv7",
        "outputId": "1d70a8c4-b841-424e-e57b-0412bfe2c2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (115064, 15)\n",
            "\n",
            "--- Merged Test Data Sample ---\n",
            "   Store  Dept       Date  IsHoliday  Temperature  Fuel_Price  MarkDown1  \\\n",
            "0      1     1 2012-11-02      False        55.32       3.386    6766.44   \n",
            "1      1     1 2012-11-09      False        61.24       3.314   11421.32   \n",
            "2      1     1 2012-11-16      False        52.92       3.252    9696.28   \n",
            "3      1     1 2012-11-23       True        56.23       3.211     883.59   \n",
            "4      1     1 2012-11-30      False        52.34       3.207    2460.03   \n",
            "\n",
            "   MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment Type  \\\n",
            "0    5147.70      50.82    3639.90    2737.42  223.462779         6.573    A   \n",
            "1    3370.89      40.28    4646.79    6154.16  223.481307         6.573    A   \n",
            "2     292.10     103.78    1133.15    6612.69  223.512911         6.573    A   \n",
            "3       4.17   74910.32     209.91     303.32  223.561947         6.573    A   \n",
            "4        NaN    3838.35     150.57    6966.34  223.610984         6.573    A   \n",
            "\n",
            "     Size  \n",
            "0  151315  \n",
            "1  151315  \n",
            "2  151315  \n",
            "3  151315  \n",
            "4  151315  \n",
            "\n",
            "Missing values in merged test data after initial merge:\n",
            "Store               0\n",
            "Dept                0\n",
            "Date                0\n",
            "IsHoliday           0\n",
            "Temperature         0\n",
            "Fuel_Price          0\n",
            "MarkDown1         149\n",
            "MarkDown2       28627\n",
            "MarkDown3        9829\n",
            "MarkDown4       12888\n",
            "MarkDown5           0\n",
            "CPI             38162\n",
            "Unemployment    38162\n",
            "Type                0\n",
            "Size                0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "7h6NM1ZXfubX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- WMAE Custom Metric Function ---\n",
        "def weighted_mean_absolute_error(y_true, y_pred, is_holiday_flag):\n",
        "    weights = np.where(is_holiday_flag, 5, 1)\n",
        "    y_pred = np.maximum(0, y_pred)\n",
        "    return np.sum(weights * np.abs(y_true - y_pred)) / np.sum(weights)"
      ],
      "metadata": {
        "id": "-D07gj-hhwGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged = train_merged.sort_values(by='Date').reset_index(drop=True)\n",
        "print(\"\\n--- Preprocessing & Feature Engineering ---\")\n",
        "\n",
        "# 1. Handle Negative Weekly_Sales in training data\n",
        "train_merged['Weekly_Sales'] = train_merged['Weekly_Sales'].apply(lambda x: max(0, x))\n",
        "print(\"Handled negative Weekly_Sales by setting them to 0 in training data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5GH2MApieBx",
        "outputId": "5a74b59a-b91d-4197-9a4f-637d8de8978b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Preprocessing & Feature Engineering ---\n",
            "Handled negative Weekly_Sales by setting them to 0 in training data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Date Feature Engineering\n",
        "def create_date_features(df):\n",
        "    df['Year'] = df['Date'].dt.year\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "    # Using isocalendar().week ensures consistency for week of year, then convert to int\n",
        "    df['Week'] = df['Date'].dt.isocalendar().week.astype(int)\n",
        "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "    df['DayOfYear'] = df['Date'].dt.dayofyear\n",
        "    df['IsMonthStart'] = df['Date'].dt.is_month_start.astype(int)\n",
        "    df['IsMonthEnd'] = df['Date'].dt.is_month_end.astype(int)\n",
        "    # Add a simple linear time trend (days since the start of the data)\n",
        "    df['TimeIdx'] = (df['Date'] - df['Date'].min()).dt.days\n",
        "    return df"
      ],
      "metadata": {
        "id": "VEEP5j3ziESY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged = create_date_features(train_merged)\n",
        "print(\"Created date-based features.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEHidIIEjlrU",
        "outputId": "776e1b63-8242-4877-e7a5-72c3f6844e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created date-based features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_merged.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1eg2MCMkCwo",
        "outputId": "a6430ad3-267d-4200-8794-bd4149b73339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Store  Dept       Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
            "0      1     1 2010-02-05      24924.50      False        42.31       2.572   \n",
            "1     29     5 2010-02-05      15552.08      False        24.36       2.788   \n",
            "2     29     6 2010-02-05       3200.22      False        24.36       2.788   \n",
            "3     29     7 2010-02-05      10820.05      False        24.36       2.788   \n",
            "4     29     8 2010-02-05      20055.64      False        24.36       2.788   \n",
            "5      2    49 2010-02-05      15767.00      False        40.19       2.572   \n",
            "6     29     9 2010-02-05       4419.73      False        24.36       2.788   \n",
            "7     29    10 2010-02-05       7550.67      False        24.36       2.788   \n",
            "8     29    11 2010-02-05       6964.21      False        24.36       2.788   \n",
            "9     29    12 2010-02-05       2293.66      False        24.36       2.788   \n",
            "\n",
            "   MarkDown1  MarkDown2  MarkDown3  ...  Type    Size  Year  Month Week  \\\n",
            "0        NaN        NaN        NaN  ...     A  151315  2010      2    5   \n",
            "1        NaN        NaN        NaN  ...     B   93638  2010      2    5   \n",
            "2        NaN        NaN        NaN  ...     B   93638  2010      2    5   \n",
            "3        NaN        NaN        NaN  ...     B   93638  2010      2    5   \n",
            "4        NaN        NaN        NaN  ...     B   93638  2010      2    5   \n",
            "5        NaN        NaN        NaN  ...     A  202307  2010      2    5   \n",
            "6        NaN        NaN        NaN  ...     B   93638  2010      2    5   \n",
            "7        NaN        NaN        NaN  ...     B   93638  2010      2    5   \n",
            "8        NaN        NaN        NaN  ...     B   93638  2010      2    5   \n",
            "9        NaN        NaN        NaN  ...     B   93638  2010      2    5   \n",
            "\n",
            "   DayOfWeek  DayOfYear  IsMonthStart  IsMonthEnd  TimeIdx  \n",
            "0          4         36             0           0        0  \n",
            "1          4         36             0           0        0  \n",
            "2          4         36             0           0        0  \n",
            "3          4         36             0           0        0  \n",
            "4          4         36             0           0        0  \n",
            "5          4         36             0           0        0  \n",
            "6          4         36             0           0        0  \n",
            "7          4         36             0           0        0  \n",
            "8          4         36             0           0        0  \n",
            "9          4         36             0           0        0  \n",
            "\n",
            "[10 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Handle Missing Values for MarkDowns\n",
        "markdown_cols = [f'MarkDown{i}' for i in range(1, 6)]\n",
        "for col in markdown_cols:\n",
        "    train_merged[col] = train_merged[col].fillna(0)\n",
        "print(\"Filled NaN values in MarkDown columns with 0.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgfAT_MZknWk",
        "outputId": "de7abc5b-9ddc-419f-b958-a08132cb8e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filled NaN values in MarkDown columns with 0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define features and target before splitting\n",
        "# Dropping 'Date' as its components have been extracted.\n",
        "# 'IsHoliday' is kept as a feature for the model.\n",
        "X = train_merged.drop(columns=['Weekly_Sales', 'Date'])\n",
        "y = train_merged['Weekly_Sales']\n",
        "is_holiday_flags = train_merged['IsHoliday'] # Store for WMAE calculation\n"
      ],
      "metadata": {
        "id": "zbnfsVxBk1cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Categorical & Numerical Feature Definitions for Preprocessor\n",
        "categorical_features = ['Type']\n",
        "# 'Store', 'Dept' will be treated as numerical IDs.\n",
        "numerical_features = ['Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment'] + \\\n",
        "                     markdown_cols + \\\n",
        "                     ['Year', 'Month', 'Week', 'DayOfWeek', 'DayOfYear', 'IsMonthStart', 'IsMonthEnd', 'TimeIdx'] + \\\n",
        "                     ['Store', 'Dept', 'IsHoliday']"
      ],
      "metadata": {
        "id": "xMTP9yChm5xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ],\n",
        "    remainder='drop' # Drop any other columns not specified (like original IsHoliday, which is in y/flags)\n",
        ")\n",
        "print(\"Defined preprocessor for categorical encoding.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHt6xO6Qm8KD",
        "outputId": "a7cb6821-c9bc-4013-f6a8-3521d870c242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined preprocessor for categorical encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Data Splitting (Chronological 60/20/20 split)\n",
        "total_rows = len(train_merged)\n",
        "train_end_idx = int(total_rows * 0.6)\n",
        "val_end_idx = int(total_rows * 0.8) # 60% + 20%\n",
        "\n",
        "X_train = X.iloc[:train_end_idx]\n",
        "y_train = y.iloc[:train_end_idx]\n",
        "is_holiday_train = is_holiday_flags.iloc[:train_end_idx]\n",
        "\n",
        "X_val = X.iloc[train_end_idx:val_end_idx]\n",
        "y_val = y.iloc[train_end_idx:val_end_idx]\n",
        "is_holiday_val = is_holiday_flags.iloc[train_end_idx:val_end_idx]\n",
        "\n",
        "X_local_test = X.iloc[val_end_idx:]\n",
        "y_local_test = y.iloc[val_end_idx:]\n",
        "is_holiday_local_test = is_holiday_flags.iloc[val_end_idx:]"
      ],
      "metadata": {
        "id": "PcFKzaeitfkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nData split into Training ({len(X_train)} rows), Validation ({len(X_val)} rows), Local Test ({len(X_local_test)} rows).\")\n",
        "print(f\"Train dates: {train_merged['Date'].iloc[0].date()} to {train_merged['Date'].iloc[train_end_idx-1].date()}\")\n",
        "print(f\"Validation dates: {train_merged['Date'].iloc[train_end_idx].date()} to {train_merged['Date'].iloc[val_end_idx-1].date()}\")\n",
        "print(f\"Local Test dates: {train_merged['Date'].iloc[val_end_idx].date()} to {train_merged['Date'].iloc[-1].date()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGIWbuCYt4Ar",
        "outputId": "1ffce6b9-abed-4dfe-c78e-51db192e3b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data split into Training (252942 rows), Validation (84314 rows), Local Test (84314 rows).\n",
            "Train dates: 2010-02-05 to 2011-09-30\n",
            "Validation dates: 2011-09-30 to 2012-04-13\n",
            "Local Test dates: 2012-04-13 to 2012-10-26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- RandomForest_Training_&_Evaluation (Conceptual MLflow Run) ---\n",
        "print(\"\\n--- Model Training & Evaluation (Random Forest) ---\")\n",
        "\n",
        "# Create the Random Forest Regressor model within a pipeline\n",
        "rf_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "                          ])\n",
        "\n",
        "print(\"Training Random Forest model on training set...\")\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGSoF-0kt7em",
        "outputId": "6e709c61-af6f-46d3-fcf5-559781aa52df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Training & Evaluation (Random Forest) ---\n",
            "Training Random Forest model on training set...\n",
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Make predictions and evaluate on the Validation Set\n",
        "print(\"\\nEvaluating on Validation Set...\")\n",
        "val_predictions = rf_model.predict(X_val)\n",
        "val_wmae = weighted_mean_absolute_error(y_val, val_predictions, is_holiday_val)\n",
        "print(f\"Validation WMAE: {val_wmae:.4f}\")\n",
        "val_mae = mean_absolute_error(y_val, val_predictions)\n",
        "print(f\"Validation MAE: {val_mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W-uynoBvhcU",
        "outputId": "386b0a49-21d6-47f8-e06c-700ff4b79164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on Validation Set...\n",
            "Validation WMAE: 3035.2597\n",
            "Validation MAE: 2816.7839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Make predictions and evaluate on the Local Test Set\n",
        "print(\"\\nEvaluating on Local Test Set...\")\n",
        "local_test_predictions = rf_model.predict(X_local_test)\n",
        "local_test_wmae = weighted_mean_absolute_error(y_local_test, local_test_predictions, is_holiday_local_test)\n",
        "print(f\"Local Test WMAE: {local_test_wmae:.4f}\")\n",
        "local_test_mae = mean_absolute_error(y_local_test, local_test_predictions)\n",
        "print(f\"Local Test MAE: {local_test_mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2WFxbOuvsBr",
        "outputId": "35863b30-3028-4204-f3e8-ef89ec99b3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on Local Test Set...\n",
            "Local Test WMAE: 2564.8268\n",
            "Local Test MAE: 2543.5857\n"
          ]
        }
      ]
    }
  ]
}